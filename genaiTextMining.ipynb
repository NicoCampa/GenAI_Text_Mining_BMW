{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [0]\n",
    "# ======================================\n",
    "# 1. Install/Import Required Libraries\n",
    "# ======================================\n",
    "\n",
    "import pandas as pd\n",
    "from google_play_scraper import Sort, reviews\n",
    "import subprocess\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell [1]\n",
    "# ======================================\n",
    "# 2. Define Parameters\n",
    "# ======================================\n",
    "\n",
    "# Package name of the BMW app on Google Play:\n",
    "app_id = \"de.bmw.connected.mobile20.row\"\n",
    "\n",
    "# Ollama model\n",
    "ollama_model_name = \"gemma3:12b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review Statistics:\n",
      "==================================================\n",
      "Total number of reviews collected: 18350\n",
      "\n",
      "Breakdown by language:\n",
      "--------------------------------------------------\n",
      "language\n",
      "German        4914\n",
      "English       4617\n",
      "French        1711\n",
      "Italian       1315\n",
      "Dutch          974\n",
      "Spanish        967\n",
      "Polish         641\n",
      "Portuguese     576\n",
      "Russian        473\n",
      "Romanian       286\n",
      "Swedish        261\n",
      "Norwegian      205\n",
      "Japanese       201\n",
      "Finnish        175\n",
      "Czech          158\n",
      "Greek          117\n",
      "Hungarian      114\n",
      "Danish         102\n",
      "Thai            99\n",
      "Turkish         65\n",
      "Croatian        65\n",
      "Slovak          58\n",
      "Slovenian       53\n",
      "Chinese         47\n",
      "Bulgarian       43\n",
      "Arabic          32\n",
      "Serbian         21\n",
      "Ukrainian       14\n",
      "Lithuanian      12\n",
      "Estonian         9\n",
      "Indonesian       7\n",
      "Latvian          7\n",
      "Korean           4\n",
      "Hebrew           4\n",
      "Malay            2\n",
      "Persian          1\n",
      "Name: count, dtype: int64\n",
      "--------------------------------------------------\n",
      "Number of languages with reviews: 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d3f785ff-3bf8-49da-9313-6763ffeacf2a</td>\n",
       "      <td>ALEX TEO</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>BEWARE!! absolutely useless. Everytime i locke...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3.4</td>\n",
       "      <td>2025-04-09 15:13:37</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5.3.4</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2bedd865-d385-45e2-83f8-bbb3317587ba</td>\n",
       "      <td>Jean Richards</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>my bmw is just best super to drive so comforta...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2025-04-09 14:54:20</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>None</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54d14726-aa2d-4587-8647-b50b3bb316e9</td>\n",
       "      <td>Imran Ali Jamal</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>Great app for keeping track of your BMW.</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3.3</td>\n",
       "      <td>2025-04-09 13:32:29</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5.3.3</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73532596-6628-4b66-ab82-14af6d3f29ab</td>\n",
       "      <td>KENNETH ORJI</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>I love the fact that it is free to download an...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3.3</td>\n",
       "      <td>2025-04-09 11:24:57</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5.3.3</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3d7d6de6-1f01-42f2-865c-49124326b268</td>\n",
       "      <td>tihomir jarnjevic</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>no limit for charging, or timer</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3.3</td>\n",
       "      <td>2025-04-09 07:46:06</td>\n",
       "      <td>None</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5.3.3</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId           userName  \\\n",
       "0  d3f785ff-3bf8-49da-9313-6763ffeacf2a           ALEX TEO   \n",
       "1  2bedd865-d385-45e2-83f8-bbb3317587ba      Jean Richards   \n",
       "2  54d14726-aa2d-4587-8647-b50b3bb316e9    Imran Ali Jamal   \n",
       "3  73532596-6628-4b66-ab82-14af6d3f29ab       KENNETH ORJI   \n",
       "4  3d7d6de6-1f01-42f2-865c-49124326b268  tihomir jarnjevic   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
       "1  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "2  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "3  https://play-lh.googleusercontent.com/a-/ALV-U...   \n",
       "4  https://play-lh.googleusercontent.com/a/ACg8oc...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  BEWARE!! absolutely useless. Everytime i locke...      1              0   \n",
       "1  my bmw is just best super to drive so comforta...      5              0   \n",
       "2           Great app for keeping track of your BMW.      4              0   \n",
       "3  I love the fact that it is free to download an...      5              0   \n",
       "4                    no limit for charging, or timer      4              0   \n",
       "\n",
       "  reviewCreatedVersion                  at replyContent repliedAt appVersion  \\\n",
       "0                5.3.4 2025-04-09 15:13:37         None       NaT      5.3.4   \n",
       "1                 None 2025-04-09 14:54:20         None       NaT       None   \n",
       "2                5.3.3 2025-04-09 13:32:29         None       NaT      5.3.3   \n",
       "3                5.3.3 2025-04-09 11:24:57         None       NaT      5.3.3   \n",
       "4                5.3.3 2025-04-09 07:46:06         None       NaT      5.3.3   \n",
       "\n",
       "  language  \n",
       "0  English  \n",
       "1  English  \n",
       "2  English  \n",
       "3  English  \n",
       "4  English  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell [2]\n",
    "# ======================================\n",
    "# 3. Fetch Reviews from Google Play Store\n",
    "# ======================================\n",
    "\n",
    "# Define languages to fetch (just language codes and labels)\n",
    "languages = [\n",
    "    ('en', 'English'),\n",
    "    ('de', 'German'),\n",
    "    ('fr', 'French'),\n",
    "    ('it', 'Italian'),\n",
    "    ('es', 'Spanish'),\n",
    "    ('nl', 'Dutch'),\n",
    "    ('sv', 'Swedish'),\n",
    "    ('da', 'Danish'),\n",
    "    ('no', 'Norwegian'),\n",
    "    ('fi', 'Finnish'),\n",
    "    ('pl', 'Polish'),\n",
    "    ('cs', 'Czech'),\n",
    "    ('pt', 'Portuguese'),\n",
    "    ('zh', 'Chinese'),\n",
    "    ('ja', 'Japanese'),\n",
    "    ('ko', 'Korean'),\n",
    "    ('ar', 'Arabic'),\n",
    "    ('tr', 'Turkish'),\n",
    "    ('ru', 'Russian'),\n",
    "    ('he', 'Hebrew'),\n",
    "    ('th', 'Thai'),\n",
    "    ('vi', 'Vietnamese'),\n",
    "    ('hi', 'Hindi'),\n",
    "    ('el', 'Greek'),\n",
    "    ('hu', 'Hungarian'),\n",
    "    ('ro', 'Romanian'),\n",
    "    ('sk', 'Slovak'),\n",
    "    ('bg', 'Bulgarian'),\n",
    "    ('hr', 'Croatian'),\n",
    "    ('sr', 'Serbian'),\n",
    "    ('uk', 'Ukrainian'),\n",
    "    ('id', 'Indonesian'),\n",
    "    ('ms', 'Malay'),\n",
    "    ('fa', 'Persian'),\n",
    "    ('ur', 'Urdu'),\n",
    "    ('bn', 'Bengali'),\n",
    "    ('ta', 'Tamil'),\n",
    "    ('te', 'Telugu'),\n",
    "    ('ml', 'Malayalam'),\n",
    "    ('et', 'Estonian'),\n",
    "    ('lv', 'Latvian'),\n",
    "    ('lt', 'Lithuanian'),\n",
    "    ('sl', 'Slovenian')\n",
    "]\n",
    "\n",
    "# Initialize empty list to store all reviews\n",
    "all_reviews = []\n",
    "\n",
    "# Fetch reviews for each language\n",
    "for lang_code, lang_label in languages:\n",
    "    continuation_token = None\n",
    "    prev_length = len(all_reviews)\n",
    "    \n",
    "    while True:\n",
    "        result, continuation_token = reviews(\n",
    "            app_id,\n",
    "            lang=lang_code,\n",
    "            sort=Sort.NEWEST,\n",
    "            count=100,\n",
    "            continuation_token=continuation_token\n",
    "        )\n",
    "        \n",
    "        # Add language label to each review\n",
    "        for review in result:\n",
    "            review['language'] = lang_label\n",
    "        \n",
    "        all_reviews.extend(result)\n",
    "        \n",
    "        # Break if no more reviews or if number of reviews isn't increasing\n",
    "        current_length = len(all_reviews)\n",
    "        if not continuation_token or current_length - prev_length < 100:\n",
    "            break\n",
    "            \n",
    "        prev_length = current_length\n",
    "\n",
    "# Convert all reviews into a pandas DataFrame\n",
    "df = pd.DataFrame(all_reviews)\n",
    "\n",
    "print(\"\\nReview Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total number of reviews collected: {len(df)}\")\n",
    "print(\"\\nBreakdown by language:\")\n",
    "print(\"-\" * 50)\n",
    "language_counts = df['language'].value_counts()\n",
    "print(language_counts)\n",
    "print(\"-\" * 50)\n",
    "print(f\"Number of languages with reviews: {len(language_counts)}\")\n",
    "# Inspect the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "import atexit\n",
    "import signal\n",
    "import warnings\n",
    "\n",
    "# Suppress the pandas FutureWarning about concatenation\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "def translate_text(text, source_lang, model_name):\n",
    "    \"\"\"\n",
    "    Translate text to English using Ollama with an enhanced prompt.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a professional translator specialized in automotive app reviews. Translate the following review written in {source_lang} into English.\n",
    "\n",
    "TASK: Translate this BMW app review accurately while preserving:\n",
    "- The original tone and sentiment\n",
    "- Technical terminology (e.g., Connected Drive, MyBMW App, iDrive, Digital Key)\n",
    "- App-specific or BMW-specific expressions and informal language\n",
    "\n",
    "Please observe the following guidelines:\n",
    "1. Preserve technical terms as given.\n",
    "2. Use consistent terminology (e.g., \"Ladestation/Borne de recharge\" → \"charging station\").\n",
    "3. If text is unclear, translate literally rather than interpreting.\n",
    "4. Keep numbers, percentages, units, error codes, emojis, and model numbers intact.\n",
    "\n",
    "IMPORTANT:\n",
    "- Return only the translated text, do not add any additional information, explanations, or comments.\n",
    "- Maintain the original paragraph structure and tone.\n",
    "- Do not extend or elaborate beyond what is in the original text.\n",
    "\n",
    "Review:\n",
    "\"{text}\"\n",
    "\n",
    "Translation:\"\"\"\n",
    "    \n",
    "    process = subprocess.run(\n",
    "        [\"ollama\", \"run\", model_name],\n",
    "        input=prompt,\n",
    "        text=True,\n",
    "        capture_output=True\n",
    "    )\n",
    "    \n",
    "    return process.stdout.strip()\n",
    "\n",
    "def translate_all_reviews(df, model_name, base_dir=\"bmw_app_analysis\", checkpoint_interval=100):\n",
    "    \"\"\"\n",
    "    Translate all non-English reviews in a DataFrame to English with robust checkpointing.\n",
    "    Saves English reviews as batch000.csv, then each batch of 100 translations as separate files.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing reviews with 'content' and 'language' columns\n",
    "        model_name: Name of the Ollama model to use\n",
    "        base_dir: Base directory for saving files\n",
    "        checkpoint_interval: Save intermediate results after this many translations\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all reviews and added 'content_english' column\n",
    "    \"\"\"\n",
    "    # Create a single translations directory for all files\n",
    "    translations_dir = os.path.join(base_dir, \"translations\")\n",
    "    os.makedirs(translations_dir, exist_ok=True)\n",
    "    \n",
    "    # Set up logging\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_id = f\"run_{timestamp}\"  # Keep a run ID for the progress file\n",
    "    progress_file = os.path.join(translations_dir, \"progress.json\")\n",
    "    \n",
    "    # Variables to track state for autosave\n",
    "    _current_batch_df = pd.DataFrame()\n",
    "    _combined_df = None  # For emergency saves only\n",
    "    _translated_indices = []\n",
    "    _last_checkpoint_num = 0\n",
    "    _progress_pct = 0\n",
    "    \n",
    "    # Function to save current progress (for emergency saves)\n",
    "    def save_current_progress(signal_received=None, frame=None):\n",
    "        nonlocal _current_batch_df, _combined_df, _translated_indices, _last_checkpoint_num, _progress_pct\n",
    "        \n",
    "        if len(_translated_indices) == 0:\n",
    "            print(\"\\nNo progress to save.\")\n",
    "            return\n",
    "            \n",
    "        # If we have unsaved translations in the current batch, save them\n",
    "        if not _current_batch_df.empty:\n",
    "            emergency_file = os.path.join(translations_dir, f\"emergency_{_last_checkpoint_num+1:03d}.csv\")\n",
    "            _current_batch_df.to_csv(emergency_file, index=False)\n",
    "            \n",
    "            # Also save a combined file for recovery\n",
    "            if _combined_df is not None:\n",
    "                full_emergency = os.path.join(translations_dir, \"emergency_all.csv\")\n",
    "                _combined_df.to_csv(full_emergency, index=False)\n",
    "                print(f\"Full emergency backup saved to: {full_emergency}\")\n",
    "            \n",
    "        # Update progress file\n",
    "        progress_data = {\n",
    "            'run_id': run_id,\n",
    "            'model_name': model_name,\n",
    "            'total_reviews': len(df),\n",
    "            'english_reviews': len(english_df) if 'english_df' in locals() else 0,\n",
    "            'non_english_reviews': len(non_english_df) if 'non_english_df' in locals() else 0,\n",
    "            'translated_reviews': len(_translated_indices),\n",
    "            'progress_percent': _progress_pct,\n",
    "            'checkpoint_number': _last_checkpoint_num + 1,\n",
    "            'last_checkpoint': emergency_file if '_current_batch_df' in locals() and not _current_batch_df.empty else None,\n",
    "            'translated_indices': [str(i) for i in _translated_indices],\n",
    "            'status': 'paused'\n",
    "        }\n",
    "        \n",
    "        with open(progress_file, 'w') as f:\n",
    "            json.dump(progress_data, f, indent=4)\n",
    "        \n",
    "        print(f\"\\nEmergency progress saved.\")\n",
    "        print(f\"Progress: {len(_translated_indices)} reviews translated ({_progress_pct}%)\")\n",
    "        print(\"You can resume translation later by running the function again.\")\n",
    "        \n",
    "        if signal_received:\n",
    "            exit(0)\n",
    "    \n",
    "    # Register handlers for various exit scenarios\n",
    "    atexit.register(save_current_progress)\n",
    "    signal.signal(signal.SIGINT, save_current_progress)  # Ctrl+C\n",
    "    signal.signal(signal.SIGTERM, save_current_progress)  # Termination signal\n",
    "    \n",
    "    # Create a working copy of the DataFrame\n",
    "    working_df = df.copy()\n",
    "    \n",
    "    # Ensure 'content_english' column exists\n",
    "    if 'content_english' not in working_df.columns:\n",
    "        working_df['content_english'] = working_df['content']\n",
    "    \n",
    "    # Separate English and non-English reviews\n",
    "    english_df = working_df[working_df['language'] == 'English'].copy()\n",
    "    non_english_df = working_df[working_df['language'] != 'English'].copy()\n",
    "    \n",
    "    print(f\"Total reviews: {len(working_df)}\")\n",
    "    print(f\"English reviews: {len(english_df)}\")\n",
    "    print(f\"Non-English reviews: {len(non_english_df)}\")\n",
    "    \n",
    "    # Save English-only reviews with simple name: batch000.csv\n",
    "    english_checkpoint = os.path.join(translations_dir, \"batch000.csv\")\n",
    "    english_df.to_csv(english_checkpoint, index=False)\n",
    "    print(f\"Saved English-only reviews as: {english_checkpoint}\")\n",
    "    \n",
    "    # Create a combined DataFrame for tracking progress\n",
    "    combined_df = english_df.copy()  # Start with English reviews\n",
    "    _combined_df = combined_df  # Copy for emergency saves\n",
    "    \n",
    "    # Check for existing progress\n",
    "    last_checkpoint_num = 0\n",
    "    translated_indices = []\n",
    "    \n",
    "    if os.path.exists(progress_file):\n",
    "        try:\n",
    "            with open(progress_file, 'r') as f:\n",
    "                progress_data = json.load(f)\n",
    "                last_checkpoint_num = progress_data.get('checkpoint_number', 0)\n",
    "                translated_indices = [int(idx) for idx in progress_data.get('translated_indices', [])]\n",
    "                \n",
    "                if translated_indices:\n",
    "                    print(f\"Found previous progress: {len(translated_indices)}/{len(non_english_df)} reviews translated\")\n",
    "                    print(f\"Last checkpoint: {last_checkpoint_num}\")\n",
    "                    \n",
    "                    resume = input(\"Resume from last checkpoint? (y/n): \")\n",
    "                    if resume.lower() == 'y':\n",
    "                        # Load all existing batch files and reconstruct the combined DataFrame\n",
    "                        print(\"Loading existing batches...\")\n",
    "                        combined_df = english_df.copy()  # Start with English reviews\n",
    "                        \n",
    "                        # Load each numbered batch\n",
    "                        for i in range(1, last_checkpoint_num + 1):\n",
    "                            batch_file = os.path.join(translations_dir, f\"batch{i:03d}.csv\")\n",
    "                            if os.path.exists(batch_file):\n",
    "                                batch = pd.read_csv(batch_file)\n",
    "                                print(f\"Loading batch{i:03d}.csv ({len(batch)} reviews)\")\n",
    "                                combined_df = pd.concat([combined_df, batch])\n",
    "                        \n",
    "                        _combined_df = combined_df  # Copy for emergency saves\n",
    "                        print(f\"Loaded {len(combined_df) - len(english_df)} translated reviews from checkpoints\")\n",
    "                    else:\n",
    "                        print(\"Starting fresh, but keeping English-only checkpoint\")\n",
    "                        translated_indices = []\n",
    "                        last_checkpoint_num = 0\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading progress file: {e}\")\n",
    "            translated_indices = []\n",
    "    \n",
    "    # Update global variables for emergency saves\n",
    "    _translated_indices = translated_indices\n",
    "    _last_checkpoint_num = last_checkpoint_num\n",
    "    \n",
    "    # Get remaining reviews to translate\n",
    "    remaining_indices = [idx for idx in non_english_df.index if idx not in translated_indices]\n",
    "    print(f\"Translating {len(remaining_indices)} remaining reviews...\")\n",
    "    \n",
    "    # Option to stop before starting (in case they loaded the wrong checkpoint)\n",
    "    if remaining_indices:\n",
    "        proceed = input(\"Proceed with translation? (y/n): \")\n",
    "        if proceed.lower() != 'y':\n",
    "            print(\"Translation canceled. All loaded data is preserved.\")\n",
    "            return combined_df\n",
    "    \n",
    "    # Main translation loop\n",
    "    try:\n",
    "        # Process reviews in batches\n",
    "        total_batches = (len(remaining_indices) + checkpoint_interval - 1) // checkpoint_interval\n",
    "        \n",
    "        for batch_idx in range(total_batches):\n",
    "            next_checkpoint_num = last_checkpoint_num + 1\n",
    "            \n",
    "            print(f\"\\n========== BATCH {next_checkpoint_num:03d} ==========\")\n",
    "            print(f\"Processing reviews {batch_idx * checkpoint_interval + 1} to {min((batch_idx + 1) * checkpoint_interval, len(remaining_indices))}\")\n",
    "            \n",
    "            # Get the indices for this batch\n",
    "            start_idx = batch_idx * checkpoint_interval\n",
    "            end_idx = min((batch_idx + 1) * checkpoint_interval, len(remaining_indices))\n",
    "            batch_size = end_idx - start_idx\n",
    "            batch_indices = remaining_indices[start_idx:end_idx]\n",
    "            \n",
    "            # Create batch DataFrame\n",
    "            batch_df = pd.DataFrame(columns=working_df.columns)\n",
    "            _current_batch_df = batch_df  # Copy for emergency saves\n",
    "            \n",
    "            # Process reviews in this batch\n",
    "            progress_bar = tqdm(\n",
    "                total=batch_size,\n",
    "                desc=f\"Batch {next_checkpoint_num:03d}\",\n",
    "                ncols=100,\n",
    "                bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'\n",
    "            )\n",
    "            \n",
    "            batch_translated = 0\n",
    "            \n",
    "            for idx in batch_indices:\n",
    "                # Get review text and language\n",
    "                original_text = working_df.loc[idx, 'content']\n",
    "                source_lang = working_df.loc[idx, 'language']\n",
    "                \n",
    "                # Skip if empty\n",
    "                if pd.isna(original_text) or not original_text.strip():\n",
    "                    progress_bar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                # Translate the text\n",
    "                translated_text = translate_text(original_text, source_lang, model_name)\n",
    "                \n",
    "                # Create a row to add \n",
    "                row = working_df.loc[[idx]].copy()\n",
    "                row['content_english'] = translated_text\n",
    "                \n",
    "                # Add row to the batch DataFrame (using a method that avoids the warning)\n",
    "                if batch_df.empty:\n",
    "                    batch_df = row.copy()\n",
    "                else:\n",
    "                    batch_df = pd.concat([batch_df, row], ignore_index=False)\n",
    "                \n",
    "                # Update for emergency saves\n",
    "                _current_batch_df = batch_df\n",
    "                \n",
    "                # Add to translated indices\n",
    "                translated_indices.append(idx)\n",
    "                _translated_indices = translated_indices\n",
    "                batch_translated += 1\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.update(1)\n",
    "                \n",
    "                # Show occasional status updates within the batch\n",
    "                if batch_translated % 10 == 0:\n",
    "                    progress_pct = round(len(translated_indices) / len(non_english_df) * 100, 1)\n",
    "                    _progress_pct = progress_pct\n",
    "                    progress_bar.set_postfix({\"Total\": f\"{len(translated_indices)}/{len(non_english_df)}\", \"Progress\": f\"{progress_pct}%\"})\n",
    "            \n",
    "            # Close progress bar for this batch\n",
    "            progress_bar.close()\n",
    "            \n",
    "            # Add batch to combined DataFrame (for tracking only)\n",
    "            combined_df = pd.concat([combined_df, batch_df])\n",
    "            _combined_df = combined_df  # Copy for emergency saves\n",
    "            \n",
    "            # Calculate progress percentage\n",
    "            progress_pct = round(len(translated_indices) / len(non_english_df) * 100, 1)\n",
    "            _progress_pct = progress_pct  # Update for emergency saves\n",
    "            \n",
    "            # Save ONLY THIS BATCH with simple name: batch001.csv, batch002.csv, etc.\n",
    "            checkpoint_file = os.path.join(translations_dir, f\"batch{next_checkpoint_num:03d}.csv\")\n",
    "            batch_df.to_csv(checkpoint_file, index=False)\n",
    "            \n",
    "            # Update progress file\n",
    "            progress_data = {\n",
    "                'run_id': run_id,\n",
    "                'model_name': model_name,\n",
    "                'total_reviews': len(working_df),\n",
    "                'english_reviews': len(english_df),\n",
    "                'non_english_reviews': len(non_english_df),\n",
    "                'translated_reviews': len(translated_indices),\n",
    "                'progress_percent': progress_pct,\n",
    "                'checkpoint_number': next_checkpoint_num,\n",
    "                'last_checkpoint': checkpoint_file,\n",
    "                'translated_indices': [str(i) for i in translated_indices],\n",
    "                'status': 'in_progress'\n",
    "            }\n",
    "            \n",
    "            with open(progress_file, 'w') as f:\n",
    "                json.dump(progress_data, f, indent=4)\n",
    "            \n",
    "            # Print batch summary\n",
    "            print(f\"\\nBatch {next_checkpoint_num:03d} complete!\")\n",
    "            print(f\"Saved batch with {len(batch_df)} translations: {checkpoint_file}\")\n",
    "            print(f\"Overall progress: {len(translated_indices)}/{len(non_english_df)} reviews ({progress_pct}%)\")\n",
    "            \n",
    "            # Show sample translations\n",
    "            if not batch_df.empty:\n",
    "                print(\"\\nSample translations from this batch:\")\n",
    "                sample_count = min(3, len(batch_df))\n",
    "                sample_indices = batch_df.index[-sample_count:]\n",
    "                \n",
    "                for idx in sample_indices:\n",
    "                    lang = batch_df.loc[idx, 'language']\n",
    "                    orig = batch_df.loc[idx, 'content']\n",
    "                    trans = batch_df.loc[idx, 'content_english']\n",
    "                    print(f\"\\n[{lang}] Original: {orig[:100]}...\" if len(orig) > 100 else f\"\\n[{lang}] Original: {orig}\")\n",
    "                    print(f\"[English] Translation: {trans[:100]}...\" if len(trans) > 100 else f\"[English] Translation: {trans}\")\n",
    "                    print(\"---\")\n",
    "            \n",
    "            # Update tracking variables for next batch\n",
    "            last_checkpoint_num = next_checkpoint_num\n",
    "            _last_checkpoint_num = last_checkpoint_num  # Update for emergency saves\n",
    "            \n",
    "            # Ask to continue if not the last batch\n",
    "            if batch_idx < total_batches - 1:\n",
    "                continue_translation = input(\"\\nContinue to next batch? (y/n): \")\n",
    "                if continue_translation.lower() != 'y':\n",
    "                    # Update progress status to paused\n",
    "                    progress_data['status'] = 'paused'\n",
    "                    with open(progress_file, 'w') as f:\n",
    "                        json.dump(progress_data, f, indent=4)\n",
    "                    \n",
    "                    print(f\"\\nTranslation paused at {progress_pct}% complete.\")\n",
    "                    print(f\"To resume later, run the function again and select 'y' when prompted to resume.\")\n",
    "                    return combined_df\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTranslation interrupted by user\")\n",
    "        if 'progress_bar' in locals() and progress_bar is not None:\n",
    "            progress_bar.close()\n",
    "        # The autosave handler will take care of saving progress\n",
    "        return combined_df\n",
    "    \n",
    "    # Translation complete - save final merged result\n",
    "    print(\"\\nMerging all batches into final file...\")\n",
    "    \n",
    "    # Start with just English reviews\n",
    "    final_df = english_df.copy()\n",
    "    \n",
    "    # Load and merge all batch files\n",
    "    for i in range(1, last_checkpoint_num + 1):\n",
    "        batch_file = os.path.join(translations_dir, f\"batch{i:03d}.csv\")\n",
    "        if os.path.exists(batch_file):\n",
    "            batch = pd.read_csv(batch_file)\n",
    "            print(f\"Adding batch{i:03d}.csv ({len(batch)} reviews)\")\n",
    "            final_df = pd.concat([final_df, batch])\n",
    "    \n",
    "    final_file = os.path.join(translations_dir, \"final_translated.csv\")\n",
    "    final_df.to_csv(final_file, index=False)\n",
    "    \n",
    "    # Update progress file\n",
    "    progress_data = {\n",
    "        'run_id': run_id,\n",
    "        'model_name': model_name,\n",
    "        'total_reviews': len(working_df),\n",
    "        'english_reviews': len(english_df),\n",
    "        'non_english_reviews': len(non_english_df),\n",
    "        'translated_reviews': len(translated_indices),\n",
    "        'progress_percent': 100,\n",
    "        'status': 'completed',\n",
    "        'checkpoint_number': last_checkpoint_num,\n",
    "        'batch_count': last_checkpoint_num,\n",
    "        'final_output': final_file,\n",
    "        'translated_indices': [str(i) for i in translated_indices]\n",
    "    }\n",
    "    \n",
    "    with open(progress_file, 'w') as f:\n",
    "        json.dump(progress_data, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nTranslation complete! All {len(translated_indices)} non-English reviews translated\")\n",
    "    print(f\"Final merged output saved to: {final_file}\")\n",
    "    print(f\"Final file contains {len(final_df)} total reviews (English + translated)\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Helper function to merge all checkpoint files\n",
    "def merge_translation_batches(base_dir=\"bmw_app_analysis\"):\n",
    "    \"\"\"\n",
    "    Merge all translation batch files into a single DataFrame.\n",
    "    \"\"\"\n",
    "    translations_dir = os.path.join(base_dir, \"translations\")\n",
    "    \n",
    "    # Ensure the directory exists\n",
    "    if not os.path.exists(translations_dir):\n",
    "        print(f\"Error: Translations directory {translations_dir} not found!\")\n",
    "        return None\n",
    "        \n",
    "    # Start with English reviews\n",
    "    english_file = os.path.join(translations_dir, \"batch000.csv\")\n",
    "    if not os.path.exists(english_file):\n",
    "        print(f\"Error: English file {english_file} not found!\")\n",
    "        return None\n",
    "        \n",
    "    merged_df = pd.read_csv(english_file)\n",
    "    print(f\"Loaded English reviews: {len(merged_df)}\")\n",
    "    \n",
    "    # Find all batch files and sort them numerically\n",
    "    batch_files = [f for f in os.listdir(translations_dir) if f.startswith(\"batch\") and f != \"batch000.csv\"]\n",
    "    batch_files.sort(key=lambda x: int(x.replace(\"batch\", \"\").replace(\".csv\", \"\")))\n",
    "    \n",
    "    # Merge each batch\n",
    "    for batch_file in batch_files:\n",
    "        file_path = os.path.join(translations_dir, batch_file)\n",
    "        batch_df = pd.read_csv(file_path)\n",
    "        print(f\"Adding {batch_file} ({len(batch_df)} reviews)\")\n",
    "        merged_df = pd.concat([merged_df, batch_df])\n",
    "    \n",
    "    # Save the merged result\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    merged_file = os.path.join(translations_dir, f\"merged_translations_{timestamp}.csv\")\n",
    "    merged_df.to_csv(merged_file, index=False)\n",
    "    \n",
    "    print(f\"Merged all batches successfully!\")\n",
    "    print(f\"Total reviews: {len(merged_df)}\")\n",
    "    print(f\"Saved to: {merged_file}\")\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 18350\n",
      "English reviews: 4617\n",
      "Non-English reviews: 13733\n",
      "Saved English-only reviews as: bmw_app_analysis/translations/batch000.csv\n",
      "Found previous progress: 7000/13733 reviews translated\n",
      "Last checkpoint: 7\n",
      "Loading existing batches...\n",
      "Loading batch001.csv (1000 reviews)\n",
      "Loading batch002.csv (1000 reviews)\n",
      "Loading batch003.csv (1000 reviews)\n",
      "Loading batch004.csv (1000 reviews)\n",
      "Loading batch005.csv (1000 reviews)\n",
      "Loading batch006.csv (1000 reviews)\n",
      "Loading batch007.csv (1000 reviews)\n",
      "Loaded 7000 translated reviews from checkpoints\n",
      "Translating 6733 remaining reviews...\n",
      "\n",
      "========== BATCH 008 ==========\n",
      "Processing reviews 1 to 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 008: 100%|███████████████████████████████████████████████████████████| 1000/1000 [31:46<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch 008 complete!\n",
      "Saved batch with 1000 translations: bmw_app_analysis/translations/batch008.csv\n",
      "Overall progress: 8000/13733 reviews (58.3%)\n",
      "\n",
      "Sample translations from this batch:\n",
      "\n",
      "[Spanish] Original: buena app para saber cómo está tu vehículo\n",
      "[English] Translation: \"Good app for knowing how your vehicle is.\"\n",
      "---\n",
      "\n",
      "[Spanish] Original: Fácil de manejar, intuitiva, controlas muchos aspectos del automóvil desde el celular\n",
      "[English] Translation: Easy to use, intuitive, you control many aspects of the car from your cell phone.\n",
      "---\n",
      "\n",
      "[Spanish] Original: esta muy bien, tienes información de tu bmw todo el tiempo\n",
      "[English] Translation: This is very good, you have information about your BMW all the time.\n",
      "---\n",
      "\n",
      "========== BATCH 009 ==========\n",
      "Processing reviews 1001 to 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 009:  14%|████████▍                                                   | 141/1000 [03:22<19:35]"
     ]
    }
   ],
   "source": [
    "# Execute the translation\n",
    "df_translated = translate_all_reviews(df, ollama_model_name, checkpoint_interval=1000)\n",
    "\n",
    "# Print dimensions of the dataframe before and after translation\n",
    "print(f\"Original DataFrame dimensions: {df.shape} (rows, columns)\")\n",
    "print(f\"Translated DataFrame dimensions: {df_translated.shape} (rows, columns)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# BMW App Review Analysis - Single-Task Classification\n",
    "# ======================================\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Optional, Union\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "\n",
    "# Create organized folder structure\n",
    "BASE_DIR = \"bmw_app_analysis\"\n",
    "CHECKPOINT_DIR = os.path.join(BASE_DIR, \"checkpoints\")\n",
    "RESULTS_DIR = os.path.join(BASE_DIR, \"results\")\n",
    "LOGS_DIR = os.path.join(BASE_DIR, \"logs\")\n",
    "\n",
    "# Create all directories\n",
    "for directory in [BASE_DIR, CHECKPOINT_DIR, RESULTS_DIR, LOGS_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# File to track progress\n",
    "PROGRESS_FILE = os.path.join(BASE_DIR, \"analysis_progress.json\")\n",
    "\n",
    "# Ensure display is imported for notebooks\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except ImportError:\n",
    "    display = print  # Fallback for non-notebook environments\n",
    "\n",
    "# Set up logging\n",
    "log_file = os.path.join(LOGS_DIR, f\"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_file),\n",
    "        logging.StreamHandler()  # Also log to console\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Utility function to run Ollama (reused from original code)\n",
    "def run_ollama(prompt: str, model_name: str) -> str:\n",
    "    \"\"\"Execute Ollama model with the provided prompt.\"\"\"\n",
    "    try:\n",
    "        process = subprocess.run(\n",
    "            [\"ollama\", \"run\", model_name],\n",
    "            input=prompt,\n",
    "            text=True,\n",
    "            capture_output=True,\n",
    "            check=True,\n",
    "            encoding='utf-8'\n",
    "        )\n",
    "        return process.stdout.strip()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        stderr_output = e.stderr.strip() if e.stderr else \"No stderr output.\"\n",
    "        logging.error(f\"Ollama command failed with exit code {e.returncode}. Stderr: {stderr_output}\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred running Ollama: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# ======================================\n",
    "# Individual Classification Functions\n",
    "# ======================================\n",
    "\n",
    "def classify_sentiment(review_text: str, model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify the sentiment of a review text as positive, negative, or neutral.\n",
    "    \n",
    "    Args:\n",
    "        review_text: The text of the review\n",
    "        model_name: Name of the Ollama model to use\n",
    "        \n",
    "    Returns:\n",
    "        str: \"positive\", \"negative\", or \"neutral\" (lowercase)\n",
    "    \"\"\"\n",
    "    if not review_text or not isinstance(review_text, str):\n",
    "        return \"neutral\"\n",
    "        \n",
    "    prompt = f\"\"\"You are an expert at analyzing BMW app reviews. Classify the sentiment of this review:\n",
    "\n",
    "\"{review_text}\"\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "Determine if the sentiment is positive, negative, or neutral.\n",
    "\n",
    "DETAILED GUIDELINES:\n",
    "- Positive: \n",
    "  * User explicitly expresses satisfaction, appreciation, praise\n",
    "  * Uses positive adjectives (great, excellent, amazing, love)\n",
    "  * Shows enthusiasm about features or performance\n",
    "  * Reports problems being fixed or improvements made\n",
    "  * Explicitly recommends the app to others\n",
    "  * Contains predominantly positive language despite minor issues\n",
    "\n",
    "- Negative:\n",
    "  * User explicitly expresses dissatisfaction, frustration, anger\n",
    "  * Reports bugs, crashes, failures, or malfunctions\n",
    "  * Uses negative adjectives (terrible, awful, useless, poor)\n",
    "  * States the app doesn't work as expected or advertised\n",
    "  * User had to find workarounds for basic functionality\n",
    "  * Contains predominantly critical language despite minor praise\n",
    "\n",
    "- Neutral:\n",
    "  * Balance of positive and negative points with neither dominating\n",
    "  * Factual descriptions without emotional language\n",
    "  * Questions about functionality without clear satisfaction/dissatisfaction\n",
    "  * Suggestions for improvements without expressing frustration\n",
    "  * Simple factual statements about the app's functions\n",
    "  * Too vague to determine sentiment clearly\n",
    " \n",
    "IMPORTANT DECISION RULES:\n",
    "- If review mentions both positives and negatives, focus on:\n",
    "  1. The strongest emotional language (which sentiment has stronger expressions?)\n",
    "  2. The most recent experience (latest update/version)\n",
    "  3. Core functionality issues outweigh minor aesthetic praise\n",
    "  4. Essential features working outweighs minor inconveniences\n",
    "- Very short reviews with just \"good\" = positive, \"bad\" = negative, \"ok\" = neutral\n",
    "- Sarcasm should be interpreted for the underlying sentiment (\"Great, another crash\" = negative)\n",
    "- If review is exceptionally ambiguous, default to \"neutral\"\n",
    "\n",
    "EXAMPLES:\n",
    "1. \"Great app, works perfectly every time!\" → positive\n",
    "2. \"App keeps crashing when I try to check my car status.\" → negative\n",
    "3. \"The app is okay but could use some improvements.\" → neutral\n",
    "4. \"Used to crash constantly but recent update fixed most issues.\" → positive (most recent experience)\n",
    "5. \"Nice design but completely useless as it fails to connect to my car.\" → negative (core functionality issue)\n",
    "6. \"The app has some bugs but generally works well enough for what I need.\" → neutral (balanced)\n",
    "7. \"I'm impressed with the range of features, though it occasionally lags.\" → positive (stronger positive than negative)\n",
    "8. \"Loading times are frustratingly slow but at least it doesn't crash anymore.\" → neutral (balanced positives/negatives)\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Respond with ONLY ONE WORD: positive, negative, or neutral (lowercase, no punctuation).\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = run_ollama(prompt, model_name).strip().lower()\n",
    "        \n",
    "        # Validate response\n",
    "        valid_sentiments = [\"positive\", \"negative\", \"neutral\"]\n",
    "        if response in valid_sentiments:\n",
    "            return response\n",
    "        \n",
    "        # Handle potential extra text by checking for valid sentiment words\n",
    "        for sentiment in valid_sentiments:\n",
    "            if sentiment in response:\n",
    "                logging.warning(f\"Extracted '{sentiment}' from response: '{response}'\")\n",
    "                return sentiment\n",
    "                \n",
    "        # Default if response is invalid\n",
    "        logging.warning(f\"Invalid sentiment response: '{response}'. Defaulting to 'neutral'\")\n",
    "        return \"neutral\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Sentiment classification failed: {str(e)}\")\n",
    "        return \"neutral\"\n",
    "\n",
    "\n",
    "def classify_topics(review_text: str, model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Identify the relevant topics in a review from a predefined list.\n",
    "    \n",
    "    Args:\n",
    "        review_text: The text of the review\n",
    "        model_name: Name of the Ollama model to use\n",
    "        \n",
    "    Returns:\n",
    "        str: Comma-separated topic list, or \"other\"\n",
    "    \"\"\"\n",
    "    if not review_text or not isinstance(review_text, str):\n",
    "        return \"other\"\n",
    "    \n",
    "    # Valid topics list - used for verification\n",
    "    valid_topics = [\n",
    "        \"ui/ux\", \"performance\", \"connectivity\", \"authentication\", \n",
    "        \"vehicle status\", \"remote controls\", \"trip planning\", \n",
    "        \"charging management\", \"map/navigation\", \"mobile features\", \n",
    "        \"data & privacy\", \"updates\", \"customer support\",\n",
    "        \"connected store\", \"bmw digital premium\", \"digital key/mobile key\",\n",
    "        \"vehicle configuration & personalization\", \"multimedia integration\",\n",
    "        \"smartphone integration\", \"service & maintenance\", \"parking solutions\",\n",
    "        \"voice assistant\", \"my garage/vehicle management\", \"localization & language\",\n",
    "        \"bmw connected ecosystem\", \"ev-specific features\", \"notification management\",\n",
    "        \"usage statistics\", \"tutorial/help section\", \"other\"\n",
    "    ]\n",
    "    \n",
    "    # BMW review topics list (abbreviated for prompt space)\n",
    "    topics_list = \"\"\"\n",
    "    1. ui/ux - design, usability, navigation, visual appeal\n",
    "    2. performance - speed, crashes, bugs, stability, battery drain\n",
    "    3. connectivity - connection issues, bluetooth, server integration\n",
    "    4. authentication - login, account issues, multi-factor\n",
    "    5. vehicle status - battery/fuel level, location, diagnostics\n",
    "    6. remote controls - lock/unlock, climate, remote start\n",
    "    7. trip planning - route optimization, scheduling\n",
    "    8. charging management - status, stations, scheduling\n",
    "    9. map/navigation - maps, route planning, gps accuracy\n",
    "    10. mobile features - widgets, notifications, interactions\n",
    "    11. data & privacy - data handling, security concerns\n",
    "    12. updates - app updates, version issues, bugs\n",
    "    13. customer support - support experience, response time\n",
    "    14. connected store - in-app store, purchases, products\n",
    "    15. bmw digital premium - subscription services, premium features\n",
    "    16. digital key/mobile key - phone as key, sharing, access\n",
    "    17. vehicle configuration & personalization - profiles, settings\n",
    "    18. multimedia integration - music control, media streaming\n",
    "    19. smartphone integration - carplay, android auto\n",
    "    20. service & maintenance - scheduling, alerts, history\n",
    "    21. parking solutions - location, payments, availability\n",
    "    22. voice assistant - voice commands, assistant functionality\n",
    "    23. my garage/vehicle management - multiple vehicles, profiles\n",
    "    24. localization & language - translations, regional features\n",
    "    25. bmw connected ecosystem - integration with other bmw services\n",
    "    26. ev-specific features - range, charging, battery features\n",
    "    27. notification management - app alerts, push notifications, alert settings\n",
    "    28. usage statistics - mileage tracking, fuel/energy consumption, driving history\n",
    "    29. tutorial/help section - in-app guidance, manuals, feature explanations\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are an expert at analyzing BMW app reviews. Identify the main topics discussed in this review:\n",
    "\n",
    "\"{review_text}\"\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "Identify 1-5 most relevant topics from this list:\n",
    "{topics_list}\n",
    "\n",
    "STRICT RESPONSE RULES:\n",
    "1. RESPOND ONLY with topic names from the list, separated by commas\n",
    "2. DO NOT write any explanations, introductions, or reasoning\n",
    "3. DO NOT write complete sentences\n",
    "4. USE ONLY the exact topic names listed above\n",
    "5. If no topics apply, just respond with \"other\"\n",
    "6. Use lowercase only\n",
    "\n",
    "EXAMPLES:\n",
    "Review: \"The app crashes every time I try to check my battery level\"\n",
    "Valid response: performance, vehicle status\n",
    "\n",
    "Review: \"Love the new design! Very easy to use.\"\n",
    "Valid response: ui/ux\n",
    "\n",
    "Review: \"Can't connect to my car. Bluetooth always fails.\"\n",
    "Valid response: connectivity\n",
    "\n",
    "Review: \"ok\"\n",
    "Valid response: other\n",
    "\n",
    "Review: \"Would be nice if it had a way to schedule charging on my i4\"\n",
    "Valid response: feature requests, charging management, ev-specific features\n",
    "\n",
    "IMPORTANT: Your entire response must be ONLY the topic names, nothing else. No explanations or additional text allowed.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = run_ollama(prompt, model_name).strip().lower()\n",
    "        \n",
    "        # Clean basic things like quotes and periods\n",
    "        response = response.replace('\"', '').replace(\"'\", '').replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "        \n",
    "        # VALIDATION: Split by commas and validate each topic\n",
    "        if not response or len(response) > 200:  # Avoid extremely long responses\n",
    "            return \"other\"\n",
    "            \n",
    "        # Split the response\n",
    "        topics = [t.strip() for t in response.split(',')]\n",
    "        \n",
    "        # Filter to keep only valid topics\n",
    "        valid_results = []\n",
    "        for topic in topics:\n",
    "            if topic in valid_topics:\n",
    "                valid_results.append(topic)\n",
    "            # Skip invalid topics\n",
    "        \n",
    "        # If no valid topics remain, return \"other\"\n",
    "        if not valid_results:\n",
    "            return \"other\"\n",
    "            \n",
    "        # Return validated topics\n",
    "        return \", \".join(valid_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Topic classification failed: {str(e)}\")\n",
    "        return \"other\"\n",
    "\n",
    "def classify_vehicle_type(review_text: str, model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Determine if the review refers to an electric/hybrid vehicle, combustion engine, or is unclear.\n",
    "    \n",
    "    Args:\n",
    "        review_text: The text of the review\n",
    "        model_name: Name of the Ollama model to use\n",
    "        \n",
    "    Returns:\n",
    "        str: \"ev_hybrid\", \"combustion\", or \"unclear\"\n",
    "    \"\"\"\n",
    "    if not review_text or not isinstance(review_text, str):\n",
    "        return \"unclear\"\n",
    "        \n",
    "    prompt = f\"\"\"You are an expert at analyzing BMW app reviews. Determine what type of vehicle the user has based on this review:\n",
    "\n",
    "\"{review_text}\"\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "Determine if the user has an electric/hybrid vehicle (BMW EV or PHEV), a combustion engine vehicle, or if it's unclear.\n",
    "\n",
    "GUIDELINES:\n",
    "- Classify as \"ev_hybrid\" if the review mentions:\n",
    "  * Charging or battery level (in %, kWh)\n",
    "  * Electric range or range anxiety\n",
    "  * Charging stations or charging schedule\n",
    "  * Preconditioning related to battery (warming up the battery)\n",
    "  * Regenerative braking\n",
    "  * Any BMW EV or hybrid model names (i3, i4, i5, i7, iX, 330e, 530e, X5 45e/50e)\n",
    "  * Explicitly says \"electric\" or \"EV\" or \"plug-in hybrid\"\n",
    "\n",
    "- Classify as \"combustion\" if the review mentions:\n",
    "  * Fuel level, gas, petrol, diesel explicitly\n",
    "  * Engine sounds or non-electric engine characteristics\n",
    "  * MPG, l/100km in context of fuel\n",
    "  * Explicitly mentions combustion-only models (e.g., \"my M3\", \"my 330i\")\n",
    "  * Refers to refueling or gas stations\n",
    "\n",
    "- Classify as \"unclear\" if:\n",
    "  * No specific vehicle type indicators are present\n",
    "  * Only mentions general features that apply to both types\n",
    "  * Only mentions \"my BMW\" with no specific model\n",
    "  * Cannot determine confidently from the text\n",
    "\n",
    "EXAMPLES:\n",
    "1. \"App shows my battery at 80% but my actual i4 shows 75%\" → ev_hybrid\n",
    "2. \"I can't find where to set up my charging schedule\" → ev_hybrid\n",
    "3. \"Fuel gauge is incorrect, shows half tank when I just filled up my X3\" → combustion\n",
    "4. \"Can't connect to my car at all\" → unclear\n",
    "5. \"Love that I can precondition the cabin\" → unclear (both vehicle types have this)\n",
    "6. \"Shows range but not how much gas is left\" → combustion\n",
    "7. \"The range estimation is way off on my 330e\" → ev_hybrid\n",
    "8. \"Where is the button to lock my car?\" → unclear\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Respond with ONLY ONE WORD: ev_hybrid, combustion, or unclear (lowercase, no punctuation).\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = run_ollama(prompt, model_name).strip().lower()\n",
    "        \n",
    "        # Validate response\n",
    "        valid_types = [\"ev_hybrid\", \"combustion\", \"unclear\"]\n",
    "        if response in valid_types:\n",
    "            return response\n",
    "        \n",
    "        # Handle potential extra text by checking for valid vehicle type words\n",
    "        for vehicle_type in valid_types:\n",
    "            if vehicle_type in response:\n",
    "                logging.warning(f\"Extracted '{vehicle_type}' from response: '{response}'\")\n",
    "                return vehicle_type\n",
    "                \n",
    "        # Default if response is invalid\n",
    "        logging.warning(f\"Invalid vehicle type response: '{response}'. Defaulting to 'unclear'\")\n",
    "        return \"unclear\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Vehicle type classification failed: {str(e)}\")\n",
    "        return \"unclear\"\n",
    "\n",
    "\n",
    "def classify_user_experience(review_text: str, model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Determine if the user is new to the app, an experienced user, or if it's unclear.\n",
    "    \n",
    "    Args:\n",
    "        review_text: The text of the review\n",
    "        model_name: Name of the Ollama model to use\n",
    "        \n",
    "    Returns:\n",
    "        str: \"new_user\", \"experienced_user\", or \"unclear\"\n",
    "    \"\"\"\n",
    "    if not review_text or not isinstance(review_text, str):\n",
    "        return \"unclear\"\n",
    "        \n",
    "    prompt = f\"\"\"You are an expert at analyzing BMW app reviews. Determine how experienced the user is with the BMW app based on this review:\n",
    "\n",
    "\"{review_text}\"\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "Classify whether the user is new to the app, experienced with it, or if it's unclear.\n",
    "\n",
    "GUIDELINES:\n",
    "- Classify as \"new_user\" if the review mentions:\n",
    "  * Just downloaded or installed\n",
    "  * First impressions\n",
    "  * Just got the car\n",
    "  * Recently purchased\n",
    "  * Setting up for the first time\n",
    "  * Initial experience\n",
    "  * New to BMW or the app\n",
    "\n",
    "- Classify as \"experienced_user\" if the review mentions:\n",
    "  * Using the app for a period of time (months/years)\n",
    "  * References to previous versions of the app\n",
    "  * Comparisons to how the app used to work\n",
    "  * Updates changing functionality they're familiar with\n",
    "  * Being a long-time BMW owner\n",
    "  * Historical perspective on app changes\n",
    "\n",
    "- Classify as \"unclear\" if:\n",
    "  * No time references or experience level indicators\n",
    "  * Cannot determine confidently from the text\n",
    "  * Only gives current impression without historical context\n",
    "\n",
    "EXAMPLES:\n",
    "1. \"Just got my new BMW and can't figure out how to set up the app\" → new_user\n",
    "2. \"Been using this app for 3 years and the latest update broke everything\" → experienced_user\n",
    "3. \"The app keeps crashing when I check vehicle status\" → unclear\n",
    "4. \"The old version was much better, this redesign is terrible\" → experienced_user\n",
    "5. \"First day using it and I'm already impressed with the features\" → new_user\n",
    "6. \"This app sucks\" → unclear\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Respond with ONLY ONE WORD: new_user, experienced_user, or unclear (lowercase, no punctuation).\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = run_ollama(prompt, model_name).strip().lower()\n",
    "        \n",
    "        # Validate response\n",
    "        valid_types = [\"new_user\", \"experienced_user\", \"unclear\"]\n",
    "        if response in valid_types:\n",
    "            return response\n",
    "        \n",
    "        # Handle common variations\n",
    "        if \"new\" in response:\n",
    "            return \"new_user\"\n",
    "        if \"experienced\" in response or \"experience\" in response:\n",
    "            return \"experienced_user\"\n",
    "                \n",
    "        # Default if response is invalid\n",
    "        logging.warning(f\"Invalid user experience response: '{response}'. Defaulting to 'unclear'\")\n",
    "        return \"unclear\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"User experience classification failed: {str(e)}\")\n",
    "        return \"unclear\"\n",
    "\n",
    "\n",
    "def classify_usage_profile(review_text: str, model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Determine if the user is a power user, casual user, or if it's unclear.\n",
    "    \n",
    "    Args:\n",
    "        review_text: The text of the review\n",
    "        model_name: Name of the Ollama model to use\n",
    "        \n",
    "    Returns:\n",
    "        str: \"power_user\", \"casual_user\", or \"unclear\"\n",
    "    \"\"\"\n",
    "    if not review_text or not isinstance(review_text, str):\n",
    "        return \"unclear\"\n",
    "        \n",
    "    prompt = f\"\"\"You are an expert at analyzing BMW app reviews. Determine the user's usage pattern based on this review:\n",
    "\n",
    "\"{review_text}\"\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "Classify whether the user is a power user who uses advanced features, a casual user who uses basic features, or if it's unclear.\n",
    "\n",
    "GUIDELINES:\n",
    "- Classify as \"power_user\" if the review mentions:\n",
    "  * Multiple advanced features (trip planning, automation, custom settings)\n",
    "  * Integration with smart home or other services\n",
    "  * Technical details about functionality\n",
    "  * Complex use cases beyond basic car controls\n",
    "  * Digital key plus or advanced features\n",
    "  * Detailed technical feedback suggesting deep engagement\n",
    "  * Regular/daily use of multiple features\n",
    "\n",
    "- Classify as \"casual_user\" if the review mentions:\n",
    "  * Only basic features (lock/unlock, climate control, basic status)\n",
    "  * Simple use cases like checking fuel/charge or location\n",
    "  * General non-technical feedback\n",
    "  * Occasional or infrequent use\n",
    "  * Focuses on core simple functions only\n",
    "\n",
    "- Classify as \"unclear\" if:\n",
    "  * No specific features or usage patterns mentioned\n",
    "  * Cannot determine usage depth from the text\n",
    "  * General comments that don't indicate how they use the app\n",
    "\n",
    "EXAMPLES:\n",
    "1. \"Can't get the digital key to work with my smart home automation\" → power_user\n",
    "2. \"I just use it to check my fuel level and lock the doors occasionally\" → casual_user\n",
    "3. \"App keeps crashing\" → unclear\n",
    "4. \"Love how I can set up charging schedules and have the climate start automatically based on my calendar\" → power_user\n",
    "5. \"It's annoying that I have to restart it every time I want to check where I parked\" → casual_user\n",
    "6. \"Decent app but needs improvement\" → unclear\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Respond with ONLY ONE WORD: power_user, casual_user, or unclear (lowercase, no punctuation).\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = run_ollama(prompt, model_name).strip().lower()\n",
    "        \n",
    "        # Validate response\n",
    "        valid_types = [\"power_user\", \"casual_user\", \"unclear\"]\n",
    "        if response in valid_types:\n",
    "            return response\n",
    "        \n",
    "        # Handle common variations\n",
    "        if \"power\" in response:\n",
    "            return \"power_user\"\n",
    "        if \"casual\" in response:\n",
    "            return \"casual_user\"\n",
    "                \n",
    "        # Default if response is invalid\n",
    "        logging.warning(f\"Invalid usage profile response: '{response}'. Defaulting to 'unclear'\")\n",
    "        return \"unclear\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Usage profile classification failed: {str(e)}\")\n",
    "        return \"unclear\"\n",
    "\n",
    "\n",
    "def classify_pain_point(review_text: str, model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Determine if the review mentions a pain point (yes/no).\n",
    "    \n",
    "    Args:\n",
    "        review_text: The text of the review\n",
    "        model_name: Name of the Ollama model to use\n",
    "        \n",
    "    Returns:\n",
    "        str: \"yes\" or \"no\"\n",
    "    \"\"\"\n",
    "    if not review_text or not isinstance(review_text, str):\n",
    "        return \"no\"\n",
    "        \n",
    "    prompt = f\"\"\"You are an expert at analyzing BMW app reviews. Determine if this review mentions any pain points:\n",
    "\n",
    "\"{review_text}\"\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "Determine if the user mentions any pain points, issues, or problems with the app.\n",
    "\n",
    "GUIDELINES:\n",
    "Classify as \"yes\" if the review mentions:\n",
    "- Crashes, bugs, glitches, or technical issues\n",
    "- Features not working as expected\n",
    "- Frustration or difficulty using the app\n",
    "- Complaints about design or performance\n",
    "- Connection failures or syncing problems\n",
    "- Missing expected functionality\n",
    "- Errors or unexpected behavior\n",
    "- Battery drain or other resource issues\n",
    "- Anything the user clearly finds problematic\n",
    "\n",
    "Classify as \"no\" if:\n",
    "- The review is generally positive\n",
    "- No specific issues or problems are mentioned\n",
    "- The user is only making general comments or asking questions\n",
    "- The review only contains feature requests without complaints\n",
    "\n",
    "EXAMPLES:\n",
    "1. \"App keeps crashing when I try to check status\" → yes\n",
    "2. \"Works great every time!\" → no\n",
    "3. \"Why is it so hard to find the charging settings?\" → yes\n",
    "4. \"Would be nice if you could add a widget\" → no (feature request without complaint)\n",
    "5. \"Can't connect to my car half the time. Very frustrating!\" → yes\n",
    "6. \"Just got the app. Looking forward to using it.\" → no\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Respond with ONLY ONE WORD: yes or no (lowercase, no punctuation).\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = run_ollama(prompt, model_name).strip().lower()\n",
    "        \n",
    "        # Validate response\n",
    "        if response in [\"yes\", \"no\"]:\n",
    "            return response\n",
    "            \n",
    "        # Handle potential extra text\n",
    "        if \"yes\" in response:\n",
    "            return \"yes\"\n",
    "        if \"no\" in response:\n",
    "            return \"no\"\n",
    "                \n",
    "        # Default if response is invalid\n",
    "        logging.warning(f\"Invalid pain point response: '{response}'. Defaulting to 'no'\")\n",
    "        return \"no\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Pain point classification failed: {str(e)}\")\n",
    "        return \"no\"\n",
    "\n",
    "\n",
    "def classify_feature_request(review_text: str, model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Determine if the review contains a feature request (yes/no).\n",
    "    \n",
    "    Args:\n",
    "        review_text: The text of the review\n",
    "        model_name: Name of the Ollama model to use\n",
    "        \n",
    "    Returns:\n",
    "        str: \"yes\" or \"no\"\n",
    "    \"\"\"\n",
    "    if not review_text or not isinstance(review_text, str):\n",
    "        return \"no\"\n",
    "        \n",
    "    prompt = f\"\"\"You are an expert at analyzing BMW app reviews. Determine if this review contains a feature request:\n",
    "\n",
    "\"{review_text}\"\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "Determine if the user is explicitly asking for or suggesting new features or improvements.\n",
    "\n",
    "GUIDELINES:\n",
    "Classify as \"yes\" if the review:\n",
    "- Explicitly asks for a new feature to be added\n",
    "- Suggests improvements to existing functionality\n",
    "- Uses phrases like \"would be nice if\", \"wish it had\", \"please add\"\n",
    "- Compares to missing features in other apps they want implemented\n",
    "- Describes functionality they want but that doesn't exist yet\n",
    "- Makes specific suggestions for changes or additions\n",
    "- Expresses desire for missing capabilities\n",
    "\n",
    "Classify as \"no\" if:\n",
    "- The review doesn't suggest any improvements or new features\n",
    "- The user is only reporting bugs or issues with existing features\n",
    "- The user is only describing current functionality\n",
    "- The review only contains complaints without suggesting solutions\n",
    "\n",
    "EXAMPLES:\n",
    "1. \"Would be great if you could add Apple Watch support\" → yes\n",
    "2. \"The app keeps crashing\" → no\n",
    "3. \"Please add the ability to schedule charging\" → yes\n",
    "4. \"Why can't I see my trip history like in the Mercedes app?\" → yes\n",
    "5. \"The UI is terrible and confusing\" → no (complaint without suggestion)\n",
    "6. \"You should include a way to share my location with family members\" → yes\n",
    "7. \"I wish there was a widget for quick access\" → yes\n",
    "8. \"Works great\" → no\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Respond with ONLY ONE WORD: yes or no (lowercase, no punctuation).\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = run_ollama(prompt, model_name).strip().lower()\n",
    "        \n",
    "        # Validate response\n",
    "        if response in [\"yes\", \"no\"]:\n",
    "            return response\n",
    "            \n",
    "        # Handle potential extra text\n",
    "        if \"yes\" in response:\n",
    "            return \"yes\"\n",
    "        if \"no\" in response:\n",
    "            return \"no\"\n",
    "                \n",
    "        # Default if response is invalid\n",
    "        logging.warning(f\"Invalid feature request response: '{response}'. Defaulting to 'no'\")\n",
    "        return \"no\"\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Feature request classification failed: {str(e)}\")\n",
    "        return \"no\"\n",
    "\n",
    "\n",
    "def extract_competitor(review_text: str, model_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract which competitor brands are mentioned in the review.\n",
    "    \"\"\"\n",
    "    if not review_text or not isinstance(review_text, str):\n",
    "        return \"none\"\n",
    "        \n",
    "    prompt = f\"\"\"You are an expert at analyzing BMW app reviews. Identify any competitor car brands mentioned in this review:\n",
    "\n",
    "\"{review_text}\"\n",
    "\n",
    "CLASSIFICATION TASK:\n",
    "Determine if the user mentions any BMW competitors and extract the specific competitor brand name(s).\n",
    "\n",
    "DETAILED GUIDELINES:\n",
    "- Extract ONLY car manufacturer brands EXPLICITLY mentioned in the review\n",
    "- DO NOT infer or guess competitors that aren't directly mentioned\n",
    "- If NO competitor is mentioned, return \"none\"\n",
    "- [additional guidelines remain the same]\n",
    "\n",
    "CRITICAL INSTRUCTION:\n",
    "Only return a competitor name if it EXPLICITLY appears in the review text. Do not hallucinate brands.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = run_ollama(prompt, model_name).strip().lower()\n",
    "        \n",
    "        # Clean response - remove any punctuation except commas\n",
    "        response = response.replace('\"', '').replace(\"'\", '').replace(\".\", \"\").replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "        \n",
    "        if \"none\" in response or not response:\n",
    "            return \"none\"\n",
    "        \n",
    "        # VERIFICATION: Check if the response actually appears in the original text\n",
    "        review_lower = review_text.lower()\n",
    "        \n",
    "        # Check each competitor name in the response\n",
    "        competitors = response.split(',')\n",
    "        verified_competitors = []\n",
    "        \n",
    "        for competitor in competitors:\n",
    "            # Common name variations\n",
    "            variations = {\n",
    "                \"mercedes\": [\"mercedes\", \"merc\", \"mercedes-benz\", \"mercedes benz\"],\n",
    "                \"volkswagen\": [\"volkswagen\", \"vw\", \"volkswagon\"],\n",
    "                \"chevrolet\": [\"chevrolet\", \"chevy\"]\n",
    "            }\n",
    "            \n",
    "            # Check if this competitor or its variations appear in the text\n",
    "            if competitor in review_lower:\n",
    "                verified_competitors.append(competitor)\n",
    "                continue\n",
    "                \n",
    "            # Check variations if available\n",
    "            if competitor in variations:\n",
    "                for variation in variations[competitor]:\n",
    "                    if variation in review_lower:\n",
    "                        verified_competitors.append(competitor)\n",
    "                        break\n",
    "        \n",
    "        if verified_competitors:\n",
    "            return \",\".join(verified_competitors)\n",
    "        else:\n",
    "            return \"none\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Competitor extraction failed: {str(e)}\")\n",
    "        return \"none\"\n",
    "\n",
    "\n",
    "def analyze_review_step_by_step(review_text: str, model_name: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze a review by performing each classification task separately.\n",
    "    \n",
    "    Args:\n",
    "        review_text: The text of the review\n",
    "        model_name: Name of the Ollama model to use\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Dictionary with all classification results\n",
    "    \"\"\"\n",
    "    # Ensure the review text is a string\n",
    "    if not isinstance(review_text, str):\n",
    "        review_text = str(review_text) if review_text is not None else \"\"\n",
    "    \n",
    "    # Process each classification in sequence\n",
    "    sentiment = classify_sentiment(review_text, model_name)\n",
    "    topics = classify_topics(review_text, model_name)\n",
    "    vehicle_type = classify_vehicle_type(review_text, model_name)\n",
    "    user_experience = classify_user_experience(review_text, model_name)\n",
    "    usage_profile = classify_usage_profile(review_text, model_name)\n",
    "    is_pain_point = classify_pain_point(review_text, model_name)\n",
    "    is_feature_request = classify_feature_request(review_text, model_name)\n",
    "    competitor_mentioned = extract_competitor(review_text, model_name)\n",
    "    \n",
    "    # Return all results in a dictionary\n",
    "    return {\n",
    "        \"sentiment\": sentiment,\n",
    "        \"topics\": topics,\n",
    "        \"vehicle_type\": vehicle_type,\n",
    "        \"user_experience\": user_experience,\n",
    "        \"usage_profile\": usage_profile,\n",
    "        \"is_pain_point\": is_pain_point,\n",
    "        \"is_feature_request\": is_feature_request,\n",
    "        \"competitor_mentioned\": competitor_mentioned\n",
    "    }\n",
    "\n",
    "\n",
    "def process_reviews_step_by_step(df: pd.DataFrame, model_name: str, batch_size: int = 10, \n",
    "                                start_batch: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process all reviews with step-by-step individual classifications.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with reviews in 'content_english' column\n",
    "        model_name: Name of the Ollama model to use\n",
    "        batch_size: Number of reviews to process per batch\n",
    "        start_batch: Which batch to start processing from (for resuming)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all classification results added\n",
    "    \"\"\"\n",
    "    if 'content_english' not in df.columns:\n",
    "        raise ValueError(\"Input DataFrame must contain 'content_english' column\")\n",
    "    \n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    result_df = df.copy()\n",
    "    total_reviews = len(result_df)\n",
    "    total_batches = (total_reviews + batch_size - 1) // batch_size\n",
    "    \n",
    "    # Initialize columns with default values (only if starting from the beginning)\n",
    "    if start_batch == 1:\n",
    "        result_df['sentiment'] = 'neutral'\n",
    "        result_df['topics'] = 'other'\n",
    "        result_df['vehicle_type'] = 'unclear'\n",
    "        result_df['user_experience'] = 'unclear' \n",
    "        result_df['usage_profile'] = 'unclear'\n",
    "        result_df['is_pain_point'] = 'no'\n",
    "        result_df['is_feature_request'] = 'no'\n",
    "        result_df['competitor_mentioned'] = 'none'\n",
    "    \n",
    "    logging.info(f\"Starting step-by-step analysis from batch {start_batch}/{total_batches}\")\n",
    "    \n",
    "    # Keep track of checkpoint filenames\n",
    "    checkpoint_files = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for batch_num in range(start_batch, total_batches + 1):\n",
    "        start_idx = (batch_num - 1) * batch_size\n",
    "        end_idx = min(start_idx + batch_size, total_reviews)\n",
    "        batch_indices = result_df.index[start_idx:end_idx]\n",
    "        \n",
    "        logging.info(f\"Processing batch {batch_num}/{total_batches} (reviews {start_idx+1}-{end_idx})\")\n",
    "        \n",
    "        # Process each review in the batch\n",
    "        for idx in tqdm(batch_indices, desc=f\"Batch {batch_num}\", unit=\"review\"):\n",
    "            review_text = result_df.loc[idx, 'content_english']\n",
    "            \n",
    "            # Skip empty reviews\n",
    "            if pd.isna(review_text) or not str(review_text).strip():\n",
    "                logging.warning(f\"Skipping empty review at index {idx}\")\n",
    "                continue\n",
    "            \n",
    "            # Run all classifications\n",
    "            try:\n",
    "                results = analyze_review_step_by_step(str(review_text), model_name)\n",
    "                \n",
    "                # Update the DataFrame with results\n",
    "                result_df.loc[idx, 'sentiment'] = results.get('sentiment', 'neutral')\n",
    "                result_df.loc[idx, 'topics'] = results.get('topics', 'other')\n",
    "                result_df.loc[idx, 'vehicle_type'] = results.get('vehicle_type', 'unclear')\n",
    "                result_df.loc[idx, 'user_experience'] = results.get('user_experience', 'unclear')\n",
    "                result_df.loc[idx, 'usage_profile'] = results.get('usage_profile', 'unclear')\n",
    "                result_df.loc[idx, 'is_pain_point'] = results.get('is_pain_point', 'no')\n",
    "                result_df.loc[idx, 'is_feature_request'] = results.get('is_feature_request', 'no')\n",
    "                result_df.loc[idx, 'competitor_mentioned'] = results.get('competitor_mentioned', 'none')\n",
    "                \n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error processing review at index {idx}: {e}\")\n",
    "                # Keep default values for this review\n",
    "        \n",
    "        # Save checkpoint after each batch\n",
    "        checkpoint_filename = os.path.join(CHECKPOINT_DIR, f\"batch_{batch_num}_of_{total_batches}.csv\")\n",
    "        batch_df = result_df.iloc[start_idx:end_idx].copy()\n",
    "        batch_df.to_csv(checkpoint_filename, index=False)\n",
    "        checkpoint_files.append(checkpoint_filename)\n",
    "        logging.info(f\"Saved checkpoint to {checkpoint_filename}\")\n",
    "        \n",
    "        # Save progress information\n",
    "        progress = {\n",
    "            \"last_completed_batch\": batch_num,\n",
    "            \"total_batches\": total_batches,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"total_reviews\": total_reviews,\n",
    "            \"model_name\": model_name,\n",
    "            \"last_processed_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        with open(PROGRESS_FILE, 'w') as f:\n",
    "            json.dump(progress, f, indent=4)\n",
    "        \n",
    "        # Ask user if they want to continue\n",
    "        if batch_num < total_batches:\n",
    "            continue_processing = input(f\"\\nBatch {batch_num}/{total_batches} completed. Continue to next batch? (y/n): \")\n",
    "            if continue_processing.lower() != 'y':\n",
    "                logging.info(f\"Processing paused after batch {batch_num}. Run again to continue from batch {batch_num + 1}.\")\n",
    "                return result_df  # Return the partially processed DataFrame\n",
    "    \n",
    "    # All batches completed, merge results\n",
    "    logging.info(\"All batches completed. Merging results...\")\n",
    "    merge_checkpoints()\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def merge_checkpoints():\n",
    "    \"\"\"Merge all checkpoint files into one consolidated file\"\"\"\n",
    "    checkpoint_files = sorted(glob.glob(os.path.join(CHECKPOINT_DIR, \"batch_*.csv\")))\n",
    "    \n",
    "    if not checkpoint_files:\n",
    "        logging.warning(\"No checkpoint files found to merge\")\n",
    "        return\n",
    "    \n",
    "    # Read and combine all checkpoint files\n",
    "    dfs = []\n",
    "    for file in checkpoint_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            dfs.append(df)\n",
    "            logging.info(f\"Added {file} to merge list ({len(df)} rows)\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading {file}: {e}\")\n",
    "    \n",
    "    if not dfs:\n",
    "        logging.error(\"No valid checkpoint files could be read\")\n",
    "        return\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Save consolidated file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    consolidated_filename = os.path.join(RESULTS_DIR, f\"bmw_reviews_consolidated_{timestamp}.csv\")\n",
    "    \n",
    "    # Save full results\n",
    "    merged_df.to_csv(consolidated_filename, index=False)\n",
    "    logging.info(f\"Saved consolidated results with {len(merged_df)} reviews to {consolidated_filename}\")\n",
    "    \n",
    "    # Print quick summary\n",
    "    print(f\"\\n=== Classification Summary ({len(merged_df)} reviews) ===\")\n",
    "    for col in ['sentiment', 'vehicle_type', 'user_experience', 'usage_profile', \n",
    "               'is_pain_point', 'is_feature_request', 'competitor_mentioned']:\n",
    "        print(f\"\\n{col.replace('_', ' ').title()} distribution:\")\n",
    "        print(merged_df[col].value_counts())\n",
    "\n",
    "def run_analysis(df, model_name, batch_size=50):\n",
    "    \"\"\"Main function to run or resume analysis\"\"\"\n",
    "    start_batch = 1\n",
    "    total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "    \n",
    "    # Check if we have a progress file to resume from\n",
    "    if os.path.exists(PROGRESS_FILE):\n",
    "        try:\n",
    "            with open(PROGRESS_FILE, 'r') as f:\n",
    "                progress = json.load(f)\n",
    "            \n",
    "            last_batch = progress.get(\"last_completed_batch\", 0)\n",
    "            saved_total_batches = progress.get(\"total_batches\", 0)\n",
    "            prev_model = progress.get(\"model_name\", \"\")\n",
    "            last_time = progress.get(\"last_processed_time\", \"unknown time\")\n",
    "            \n",
    "            if last_batch < total_batches:\n",
    "                print(f\"Previous run found (completed {last_batch}/{saved_total_batches} batches at {last_time}).\")\n",
    "                \n",
    "                # Let user choose which batch to start from\n",
    "                print(f\"\\nBatch information:\")\n",
    "                print(f\"- Total batches: {total_batches}\")\n",
    "                print(f\"- Completed batches: 1 to {last_batch}\")\n",
    "                print(f\"- Remaining batches: {last_batch + 1} to {total_batches}\")\n",
    "                \n",
    "                while True:\n",
    "                    batch_input = input(f\"\\nEnter the batch number to start from (1-{total_batches}) or 'q' to quit: \")\n",
    "                    \n",
    "                    if batch_input.lower() == 'q':\n",
    "                        logging.info(\"Analysis cancelled by user\")\n",
    "                        return None\n",
    "                    \n",
    "                    try:\n",
    "                        selected_batch = int(batch_input)\n",
    "                        if 1 <= selected_batch <= total_batches:\n",
    "                            start_batch = selected_batch\n",
    "                            logging.info(f\"Starting from user-selected batch {start_batch}\")\n",
    "                            \n",
    "                            # Warn if starting from an incomplete batch\n",
    "                            if selected_batch <= last_batch:\n",
    "                                overwrite = input(f\"Batch {selected_batch} was already completed. Reprocess this batch? (y/n): \")\n",
    "                                if overwrite.lower() != 'y':\n",
    "                                    # User changed their mind - ask again\n",
    "                                    continue\n",
    "                            \n",
    "                            # Warn if model changed\n",
    "                            if prev_model and prev_model != model_name:\n",
    "                                logging.warning(f\"Using a different model ({model_name}) than previous run ({prev_model})\")\n",
    "                            \n",
    "                            break\n",
    "                        else:\n",
    "                            print(f\"Invalid batch number. Please enter a number between 1 and {total_batches}.\")\n",
    "                    except ValueError:\n",
    "                        print(\"Please enter a valid number.\")\n",
    "            else:\n",
    "                print(\"Previous run completed all batches. Starting over.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading progress file: {e}\")\n",
    "            print(f\"Error reading progress file: {e}\")\n",
    "    else:\n",
    "        print(\"No previous run found. Starting from the beginning.\")\n",
    "    \n",
    "    # Start or resume processing\n",
    "    print(f\"Starting classification from batch {start_batch}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df_classified = process_reviews_step_by_step(\n",
    "        df=df,\n",
    "        model_name=model_name,\n",
    "        batch_size=batch_size,\n",
    "        start_batch=start_batch\n",
    "    )\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    total_time = time.time() - start_time\n",
    "    hours, remainder = divmod(total_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"Classification complete! Time taken: {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
    "    \n",
    "    return df_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translated = pd.read_csv(\"bmw_app_analysis/translations/final_translated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run found (completed 3/19 batches at 2025-04-14 01:26:44).\n",
      "\n",
      "Batch information:\n",
      "- Total batches: 19\n",
      "- Completed batches: 1 to 3\n",
      "- Remaining batches: 4 to 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 01:31:52,291 - INFO - Starting from user-selected batch 4\n",
      "2025-04-14 01:31:52,308 - INFO - Starting step-by-step analysis from batch 4/19\n",
      "2025-04-14 01:31:52,308 - INFO - Processing batch 4/19 (reviews 3001-4000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting classification from batch 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 4: 100%|██████████| 1000/1000 [6:41:22<00:00, 24.08s/review] \n",
      "2025-04-14 08:13:14,718 - INFO - Saved checkpoint to bmw_app_analysis/checkpoints/batch_4_of_19.csv\n",
      "2025-04-14 11:17:15,986 - INFO - Processing paused after batch 4. Run again to continue from batch 5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complete! Time taken: 9h 45m 23s\n",
      "Classification complete!\n"
     ]
    }
   ],
   "source": [
    "# Run the full analysis (with resume capability)\n",
    "df_classified = run_analysis(\n",
    "    df=df_translated,\n",
    "    model_name=ollama_model_name,\n",
    "    batch_size=1000 # Process in batches of 5\n",
    ")\n",
    "\n",
    "# Final output is already saved as part of run_analysis\n",
    "print(\"Classification complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 batch files:\n",
      "  - batch_1_of_19.csv\n",
      "  - batch_2_of_19.csv\n",
      "  - batch_3_of_19.csv\n",
      "  - batch_4_of_19.csv\n",
      "  - batch_5_of_19.csv\n",
      "  - batch_6_of_19.csv\n",
      "  - batch_7_of_19.csv\n",
      "  - batch_8_of_19.csv\n",
      "  - batch_9_of_19.csv\n",
      "  - batch_10_of_19.csv\n",
      "  - batch_11_of_19.csv\n",
      "  - batch_12_of_19.csv\n",
      "  - batch_13_of_19.csv\n",
      "  - batch_14_of_19.csv\n",
      "Added batch 1 (1000 reviews)\n",
      "Added batch 2 (1000 reviews)\n",
      "Added batch 3 (1000 reviews)\n",
      "Added batch 4 (1000 reviews)\n",
      "Added batch 5 (1000 reviews)\n",
      "Added batch 6 (1000 reviews)\n",
      "Added batch 7 (1000 reviews)\n",
      "Added batch 8 (1000 reviews)\n",
      "Added batch 9 (1000 reviews)\n",
      "Added batch 10 (1000 reviews)\n",
      "Added batch 11 (1000 reviews)\n",
      "Added batch 12 (1000 reviews)\n",
      "Added batch 13 (1000 reviews)\n",
      "Added batch 14 (1000 reviews)\n",
      "Successfully merged 14000 total reviews\n",
      "Saved merged results to: bmw_app_analysis/results/merged_classification.csv\n",
      "\n",
      "=== Classification Summary ===\n",
      "\n",
      "Sentiment distribution:\n",
      "sentiment\n",
      "positive    6422\n",
      "negative    6398\n",
      "neutral     1179\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Vehicle Type distribution:\n",
      "vehicle_type\n",
      "unclear       11965\n",
      "ev_hybrid      1589\n",
      "combustion      445\n",
      "Name: count, dtype: int64\n",
      "\n",
      "User Experience distribution:\n",
      "user_experience\n",
      "unclear             8817\n",
      "experienced_user    4918\n",
      "new_user             264\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Usage Profile distribution:\n",
      "usage_profile\n",
      "casual_user    7945\n",
      "unclear        3577\n",
      "power_user     2477\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Is Pain Point distribution:\n",
      "is_pain_point\n",
      "yes    7806\n",
      "no     6193\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Is Feature Request distribution:\n",
      "is_feature_request\n",
      "no     10680\n",
      "yes     3319\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Competitor Mentioned distribution:\n",
      "competitor_mentioned\n",
      "none                    13423\n",
      "bmw                       104\n",
      "tesla                      45\n",
      "mercedes                   42\n",
      "samsung                    40\n",
      "                        ...  \n",
      "korean manufacturers        1\n",
      "ios                         1\n",
      "tomtom                      1\n",
      "chevy                       1\n",
      "x5                          1\n",
      "Name: count, Length: 143, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "def merge_checkpoint_batches(checkpoint_dir=\"bmw_app_analysis/checkpoints\"):\n",
    "    \"\"\"\n",
    "    Merge all checkpoint batch files into a single DataFrame.\n",
    "    \"\"\"\n",
    "    # Get all batch files, sorted numerically\n",
    "    pattern = os.path.join(checkpoint_dir, \"batch_*_of_*.csv\")\n",
    "    checkpoint_files = glob.glob(pattern)\n",
    "    \n",
    "    # Sort by batch number\n",
    "    def get_batch_num(filename):\n",
    "        # Extract number between \"batch_\" and \"_of\"\n",
    "        match = re.search(r'batch_(\\d+)_of', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        return 0\n",
    "        \n",
    "    checkpoint_files = sorted(checkpoint_files, key=get_batch_num)\n",
    "    \n",
    "    if not checkpoint_files:\n",
    "        print(f\"No batch files found in {checkpoint_dir}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Found {len(checkpoint_files)} batch files:\")\n",
    "    for file in checkpoint_files:\n",
    "        print(f\"  - {os.path.basename(file)}\")\n",
    "    \n",
    "    # Read and combine all batch files\n",
    "    dfs = []\n",
    "    for file in checkpoint_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            batch_num = get_batch_num(file)\n",
    "            print(f\"Added batch {batch_num} ({len(df)} reviews)\")\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    \n",
    "    if not dfs:\n",
    "        print(\"No valid checkpoint files could be read\")\n",
    "        return None\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f\"Successfully merged {len(merged_df)} total reviews\")\n",
    "    \n",
    "    # Save the merged result\n",
    "    merged_file = \"bmw_app_analysis/results/merged_classification.csv\"\n",
    "    os.makedirs(os.path.dirname(merged_file), exist_ok=True)\n",
    "    merged_df.to_csv(merged_file, index=False)\n",
    "    print(f\"Saved merged results to: {merged_file}\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Run the function\n",
    "if __name__ == \"__main__\":\n",
    "    df_merged = merge_checkpoint_batches()\n",
    "    \n",
    "    # Print some basic statistics\n",
    "    if df_merged is not None:\n",
    "        print(\"\\n=== Classification Summary ===\")\n",
    "        for col in ['sentiment', 'vehicle_type', 'user_experience', 'usage_profile', \n",
    "                  'is_pain_point', 'is_feature_request', 'competitor_mentioned']:\n",
    "            if col in df_merged.columns:\n",
    "                print(f\"\\n{col.replace('_', ' ').title()} distribution:\")\n",
    "                print(df_merged[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classified = pd.read_csv(\"bmw_app_analysis/results/merged_classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to bmw_app_analysis/results/bmw_reviews_classified.csv\n",
      "\n",
      "=== Sample Classified Reviews ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_english</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>topics</th>\n",
       "      <th>is_pain_point</th>\n",
       "      <th>is_feature_request</th>\n",
       "      <th>competitor_mentioned</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>user_experience</th>\n",
       "      <th>usage_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEWARE!! absolutely useless. Everytime i locke...</td>\n",
       "      <td>negative</td>\n",
       "      <td>connectivity, remote controls</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>unclear</td>\n",
       "      <td>unclear</td>\n",
       "      <td>casual_user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my bmw is just best super to drive so comforta...</td>\n",
       "      <td>positive</td>\n",
       "      <td>performance, mobile features</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>unclear</td>\n",
       "      <td>unclear</td>\n",
       "      <td>casual_user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great app for keeping track of your BMW.</td>\n",
       "      <td>positive</td>\n",
       "      <td>vehicle status</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>unclear</td>\n",
       "      <td>unclear</td>\n",
       "      <td>casual_user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love the fact that it is free to download an...</td>\n",
       "      <td>positive</td>\n",
       "      <td>charging management, remote controls, vehicle ...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>ev_hybrid</td>\n",
       "      <td>unclear</td>\n",
       "      <td>casual_user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no limit for charging, or timer</td>\n",
       "      <td>negative</td>\n",
       "      <td>charging management, ev-specific features</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>none</td>\n",
       "      <td>ev_hybrid</td>\n",
       "      <td>unclear</td>\n",
       "      <td>casual_user</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     content_english sentiment  \\\n",
       "0  BEWARE!! absolutely useless. Everytime i locke...  negative   \n",
       "1  my bmw is just best super to drive so comforta...  positive   \n",
       "2           Great app for keeping track of your BMW.  positive   \n",
       "3  I love the fact that it is free to download an...  positive   \n",
       "4                    no limit for charging, or timer  negative   \n",
       "\n",
       "                                              topics is_pain_point  \\\n",
       "0                      connectivity, remote controls           yes   \n",
       "1                       performance, mobile features            no   \n",
       "2                                     vehicle status            no   \n",
       "3  charging management, remote controls, vehicle ...            no   \n",
       "4          charging management, ev-specific features           yes   \n",
       "\n",
       "  is_feature_request competitor_mentioned vehicle_type user_experience  \\\n",
       "0                 no                 none      unclear         unclear   \n",
       "1                 no                 none      unclear         unclear   \n",
       "2                 no                 none      unclear         unclear   \n",
       "3                 no                 none    ev_hybrid         unclear   \n",
       "4                yes                 none    ev_hybrid         unclear   \n",
       "\n",
       "  usage_profile  \n",
       "0   casual_user  \n",
       "1   casual_user  \n",
       "2   casual_user  \n",
       "3   casual_user  \n",
       "4   casual_user  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification Summary (14000 reviews) ===\n",
      "\n",
      "--- Sentiment Distribution ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>6422</td>\n",
       "      <td>45.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>6398</td>\n",
       "      <td>45.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>1179</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count  Percentage\n",
       "sentiment                   \n",
       "positive    6422        45.9\n",
       "negative    6398        45.7\n",
       "neutral     1179         8.4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Vehicle Type Distribution ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicle_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unclear</th>\n",
       "      <td>11965</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ev_hybrid</th>\n",
       "      <td>1589</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>combustion</th>\n",
       "      <td>445</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count  Percentage\n",
       "vehicle_type                   \n",
       "unclear       11965        85.5\n",
       "ev_hybrid      1589        11.4\n",
       "combustion      445         3.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- User Experience Distribution ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_experience</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unclear</th>\n",
       "      <td>8817</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experienced_user</th>\n",
       "      <td>4918</td>\n",
       "      <td>35.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new_user</th>\n",
       "      <td>264</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Count  Percentage\n",
       "user_experience                    \n",
       "unclear            8817        63.0\n",
       "experienced_user   4918        35.1\n",
       "new_user            264         1.9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Usage Profile Distribution ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usage_profile</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>casual_user</th>\n",
       "      <td>7945</td>\n",
       "      <td>56.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unclear</th>\n",
       "      <td>3577</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power_user</th>\n",
       "      <td>2477</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count  Percentage\n",
       "usage_profile                   \n",
       "casual_user     7945        56.8\n",
       "unclear         3577        25.6\n",
       "power_user      2477        17.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Is Pain Point Distribution ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_pain_point</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>7806</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>6193</td>\n",
       "      <td>44.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count  Percentage\n",
       "is_pain_point                   \n",
       "yes             7806        55.8\n",
       "no              6193        44.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Is Feature Request Distribution ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_feature_request</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>10680</td>\n",
       "      <td>76.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>3319</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Count  Percentage\n",
       "is_feature_request                   \n",
       "no                  10680        76.3\n",
       "yes                  3319        23.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Competitor Mentioned Distribution ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>competitor_mentioned</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>13423</td>\n",
       "      <td>95.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>104</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tesla</th>\n",
       "      <td>45</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercedes</th>\n",
       "      <td>42</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>40</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean manufacturers</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ios</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomtom</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chevy</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Count  Percentage\n",
       "competitor_mentioned                   \n",
       "none                  13423        95.9\n",
       "bmw                     104         0.7\n",
       "tesla                    45         0.3\n",
       "mercedes                 42         0.3\n",
       "samsung                  40         0.3\n",
       "...                     ...         ...\n",
       "korean manufacturers      1         0.0\n",
       "ios                       1         0.0\n",
       "tomtom                    1         0.0\n",
       "chevy                     1         0.0\n",
       "x5                        1         0.0\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Topics Distribution ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "performance                                4211\n",
       "vehicle status                             3601\n",
       "ui/ux                                      3579\n",
       "connectivity                               2713\n",
       "other                                      2211\n",
       "updates                                    1880\n",
       "authentication                             1641\n",
       "remote controls                            1612\n",
       "mobile features                            1227\n",
       "ev-specific features                        876\n",
       "bmw connected ecosystem                     874\n",
       "charging management                         761\n",
       "map/navigation                              648\n",
       "customer support                            464\n",
       "trip planning                               456\n",
       "usage statistics                            372\n",
       "bmw digital premium                         320\n",
       "service & maintenance                       320\n",
       "notification management                     278\n",
       "digital key/mobile key                      254\n",
       "localization & language                     217\n",
       "connected store                             153\n",
       "data & privacy                              139\n",
       "my garage/vehicle management                135\n",
       "multimedia integration                      124\n",
       "voice assistant                             114\n",
       "smartphone integration                      105\n",
       "tutorial/help section                        76\n",
       "vehicle configuration & personalization      58\n",
       "parking solutions                            18\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Review Lookup ===\n",
      "To view a specific review, run: analyze_classification_results(df_classified, review_index)\n",
      "Where review_index is the index of the review you want to see (0 to 13999 )\n"
     ]
    }
   ],
   "source": [
    "RESULTS_DIR = \"bmw_app_analysis/results\"\n",
    "\n",
    "def analyze_classification_results(df_classified, display_specific_review=None):\n",
    "    \"\"\"\n",
    "    Analyze and display classification results with summary statistics \n",
    "    and optionally show specific reviews.\n",
    "    \n",
    "    Args:\n",
    "        df_classified: DataFrame with classified reviews\n",
    "        display_specific_review: Index of specific review to display (optional)\n",
    "    \"\"\"\n",
    "    # Import display from IPython if available, otherwise use print as fallback\n",
    "    try:\n",
    "        from IPython.display import display, HTML\n",
    "    except ImportError:\n",
    "        # Define a simple display function if not in a notebook environment\n",
    "        def display(obj):\n",
    "            print(obj)\n",
    "    \n",
    "    if df_classified is None or len(df_classified) == 0:\n",
    "        print(\"No classification results to analyze.\")\n",
    "        return\n",
    "    \n",
    "    # Define the display columns for consistency\n",
    "    display_columns = [\n",
    "        'content_english', 'sentiment', 'topics', \n",
    "        'is_pain_point', 'is_feature_request', 'competitor_mentioned',\n",
    "        'vehicle_type', 'user_experience', 'usage_profile'\n",
    "    ]\n",
    "    \n",
    "    # If a specific review is requested, display it first\n",
    "    if display_specific_review is not None:\n",
    "        try:\n",
    "            review_idx = int(display_specific_review)\n",
    "            if 0 <= review_idx < len(df_classified):\n",
    "                print(f\"\\n=== Review #{review_idx+1} (Index {review_idx}) ===\")\n",
    "                selected_review = df_classified.iloc[review_idx]\n",
    "                display(selected_review[display_columns])\n",
    "                \n",
    "                print(f\"\\n=== Review #{review_idx+1} (Detailed) ===\")\n",
    "                for col in display_columns:\n",
    "                    print(f\"{col}: {selected_review[col]}\")\n",
    "            else:\n",
    "                print(f\"Review index {review_idx} is out of range (0-{len(df_classified)-1}).\")\n",
    "        except ValueError:\n",
    "            print(\"Please provide a valid review index (number).\")\n",
    "    \n",
    "    # Display sample of classified reviews (first 5 by default)\n",
    "    print(\"\\n=== Sample Classified Reviews ===\")\n",
    "    display(df_classified[display_columns].head())\n",
    "    \n",
    "    # Display classification summary statistics\n",
    "    print(f\"\\n=== Classification Summary ({len(df_classified)} reviews) ===\")\n",
    "    \n",
    "    # Helper function to show value distributions with percentages\n",
    "    def show_distribution(df, column):\n",
    "        counts = df[column].value_counts()\n",
    "        percentages = df[column].value_counts(normalize=True) * 100\n",
    "        distribution = pd.DataFrame({\n",
    "            'Count': counts,\n",
    "            'Percentage': percentages.round(1)\n",
    "        })\n",
    "        print(f\"\\n--- {column.replace('_', ' ').title()} Distribution ---\")\n",
    "        display(distribution)\n",
    "    \n",
    "    # Show distributions for each classification\n",
    "    show_distribution(df_classified, 'sentiment')\n",
    "    show_distribution(df_classified, 'vehicle_type')\n",
    "    show_distribution(df_classified, 'user_experience')\n",
    "    show_distribution(df_classified, 'usage_profile')\n",
    "    show_distribution(df_classified, 'is_pain_point')\n",
    "    show_distribution(df_classified, 'is_feature_request')\n",
    "    show_distribution(df_classified, 'competitor_mentioned')\n",
    "    \n",
    "    # For topics, we need to split and count individually\n",
    "    print(\"\\n--- Topics Distribution ---\")\n",
    "    all_topics = [topic.strip() for topics_str in df_classified['topics'].dropna() \n",
    "                  for topic in topics_str.split(',') if topic.strip()]\n",
    "    topic_counts = pd.Series(all_topics).value_counts()\n",
    "    display(topic_counts)\n",
    "    \n",
    "    print(\"\\n=== Review Lookup ===\")\n",
    "    print(\"To view a specific review, run: analyze_classification_results(df_classified, review_index)\")\n",
    "    print(\"Where review_index is the index of the review you want to see (0 to\", len(df_classified)-1, \")\")\n",
    "\n",
    "# When doing the full analysis:\n",
    "if df_classified is not None:\n",
    "    # Save results to CSV\n",
    "    output_file = os.path.join(RESULTS_DIR, \"bmw_reviews_classified.csv\")\n",
    "    df_classified.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    # Show initial summary statistics\n",
    "    analyze_classification_results(df_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmw_topic_cards.py  –  v6  (2025‑05‑02)\n",
    "# ================================================================\n",
    "# • Stratified random sampling (mirrors topic sentiment mix)\n",
    "# • One paragraph summary  +  “‑ ” negative bullets  +  “+ ” positive bullets\n",
    "# • Prompts stored inside TopicSummary.prompts  (audit / debugging)\n",
    "# • No JSON parsing, so Ollama chatter can’t break the pipeline\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import html\n",
    "import logging\n",
    "import subprocess\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  CONFIGURATION\n",
    "# -------------------------------------------------------------------\n",
    "TOP_N_TOPICS        = 15          # how many topics to visualise\n",
    "PROMPT_SAMPLE_SIZE  = 300         # reviews fed to each LLM prompt\n",
    "N_KEYWORDS          = 8\n",
    "N_PHRASES           = 5\n",
    "MAX_BULLETS         = 7           # issues / positives\n",
    "BMW_BLUE            = \"#0066B1\"\n",
    "\n",
    "STAR_SVG = (\n",
    "    \"<svg width='14' height='14' viewBox='0 0 24 24' \"\n",
    "    \"xmlns='http://www.w3.org/2000/svg' style='vertical-align:-2px'>\"\n",
    "    \"<polygon fill='#FFD700' \"\n",
    "    \"points='12 2 15.09 8.26 22 9.27 17 14.14 \"\n",
    "    \"18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26'/></svg>\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  NLTK – bootstrap stop‑words\n",
    "# -------------------------------------------------------------------\n",
    "for res in (\"stopwords\", \"punkt\"):\n",
    "    try:\n",
    "        nltk.data.find(f\"corpora/{res}\")\n",
    "    except LookupError:\n",
    "        nltk.download(res, quiet=True)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\")) | {\n",
    "    \"bmw\", \"app\", \"car\", \"please\", \"would\", \"also\", \"get\", \"use\", \"using\"\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  OLLAMA RUNNER  (temperature 0 for determinism)\n",
    "# -------------------------------------------------------------------\n",
    "def _subprocess_runner(prompt: str, model: str) -> str:\n",
    "    proc = subprocess.run(\n",
    "        [\"ollama\", \"run\", model, \"-t\", \"0\"],\n",
    "        input=prompt,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        check=False,\n",
    "    )\n",
    "    return proc.stdout\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  STRATIFIED SAMPLING  (mirror sentiment mix)\n",
    "# -------------------------------------------------------------------\n",
    "def _stratified_sample(df: pd.DataFrame, size: int, seed: int = 0) -> List[str]:\n",
    "    dist = df[\"sentiment\"].value_counts(normalize=True)\n",
    "    quota = {s: int(round(dist.get(s, 0) * size)) for s in (\"negative\", \"positive\", \"neutral\")}\n",
    "    diff = size - sum(quota.values())\n",
    "    if diff:\n",
    "        quota[max(dist, key=dist.get, default=\"negative\")] += diff\n",
    "\n",
    "    col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "    texts: List[str] = []\n",
    "\n",
    "    for sentiment, n in quota.items():\n",
    "        if n <= 0:\n",
    "            continue\n",
    "        bucket = df[df[\"sentiment\"] == sentiment]\n",
    "        sample_n = min(n, len(bucket))\n",
    "        texts.extend(bucket.sample(sample_n, random_state=seed)[col].tolist())\n",
    "\n",
    "    # top‑up if any bucket ran short\n",
    "    if len(texts) < size:\n",
    "        short = size - len(texts)\n",
    "        remainder = df.drop(df.index[df[col].isin(texts)]).sample(short, random_state=seed)\n",
    "        texts.extend(remainder[col].tolist())\n",
    "\n",
    "    return texts\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  BULLET‑PARSER\n",
    "# -------------------------------------------------------------------\n",
    "def _parse_bullets(text: str, prefix: str) -> List[str]:\n",
    "    \"\"\"Return list of lines starting with the prefix (‘- ’ or ‘+ ’).\"\"\"\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    bullets = [ln[len(prefix):].strip() for ln in lines if ln.startswith(prefix)]\n",
    "    # fallback to comma‑sep if model ignored prefixes\n",
    "    if not bullets and \",\" in text:\n",
    "        bullets = [part.strip() for part in text.split(\",\") if part.strip()]\n",
    "    return bullets[:MAX_BULLETS]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  DATACLASS\n",
    "# -------------------------------------------------------------------\n",
    "@dataclass\n",
    "class TopicSummary:\n",
    "    summary: str\n",
    "    issues: List[str]\n",
    "    positives: List[str]\n",
    "    avg_rating: float\n",
    "    review_count: int\n",
    "    sentiment_dist: Dict[str, float]\n",
    "    top_keywords: List[str]\n",
    "    top_phrases: List[str]\n",
    "    prompts: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "    @property\n",
    "    def stars(self) -> str:\n",
    "        full, half = int(self.avg_rating), self.avg_rating - int(self.avg_rating) >= 0.5\n",
    "        return STAR_SVG * full + (STAR_SVG if half else \"\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MAIN ENTRY\n",
    "# -------------------------------------------------------------------\n",
    "def create_topic_cards_from_classified(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    ollama_model_name: str = \"gemma3:12b\",\n",
    "    ollama_runner: Callable[[str, str], str] = _subprocess_runner,\n",
    ") -> Dict[str, TopicSummary]:\n",
    "    \"\"\"\n",
    "    Render topic cards & a rating chart; return dict[topic] -> TopicSummary.\n",
    "    Prompts are stored in `TopicSummary.prompts`.\n",
    "    \"\"\"\n",
    "    log = _setup_logger()\n",
    "\n",
    "    # -------- sanity checks -----------------------------------------\n",
    "    if {\"topics\", \"sentiment\"} - set(df.columns):\n",
    "        raise ValueError(\"DataFrame must include 'topics' & 'sentiment'.\")\n",
    "\n",
    "    text_col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "\n",
    "    if \"score\" not in df.columns:\n",
    "        df[\"score\"] = (\n",
    "            df[\"sentiment\"]\n",
    "            .map({\"positive\": 4.5, \"neutral\": 3.0, \"negative\": 1.5})\n",
    "            .fillna(3.0)\n",
    "        )\n",
    "\n",
    "    # -------- pick top topics --------------------------------------\n",
    "    topics_freq = df[\"topics\"].str.get_dummies(sep=\",\").sum()\n",
    "    top_topics = (\n",
    "        topics_freq.sort_values(ascending=False).head(TOP_N_TOPICS).index\n",
    "    )\n",
    "\n",
    "    results: Dict[str, TopicSummary] = {}\n",
    "\n",
    "    for topic in tqdm(top_topics, desc=\"Topics\"):\n",
    "        sub = df[df[\"topics\"].str.contains(fr\"\\b{topic}\\b\", case=False, na=False)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        avg = sub[\"score\"].mean()\n",
    "        mix = sub[\"sentiment\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "        tokens = word_tokenize(\" \".join(sub[text_col].fillna(\"\").str.lower()))\n",
    "        tokens = [t for t in tokens if t.isalpha() and t not in STOPWORDS and len(t) > 2]\n",
    "        keywords = [w for w, _ in Counter(tokens).most_common(N_KEYWORDS)]\n",
    "        bigrams = [f\"{a} {b}\" for a, b in zip(tokens, tokens[1:])]\n",
    "        phrases = [p for p, _ in Counter(bigrams).most_common(N_PHRASES)]\n",
    "\n",
    "        sample_n = min(PROMPT_SAMPLE_SIZE, len(sub))\n",
    "        sample_texts = _stratified_sample(sub, sample_n)\n",
    "        sample_blob = \"\\n\".join(f\"[{i}] {txt}\" for i, txt in enumerate(sample_texts))\n",
    "\n",
    "        ctx_block = (\n",
    "            f\"Average score {avg:.2f} (n={len(sub)}). \"\n",
    "            f\"Sentiment mix: neg {mix.get('negative',0):.0%}, \"\n",
    "            f\"pos {mix.get('positive',0):.0%}, \"\n",
    "            f\"neu {mix.get('neutral',0):.0%}.\\n\"\n",
    "            f\"Top keywords: {', '.join(keywords)}.\\n\"\n",
    "            f\"Top phrases: {', '.join(phrases)}.\"\n",
    "        )\n",
    "\n",
    "        prompts: Dict[str, str] = {}\n",
    "\n",
    "        def build(kind: str) -> str:\n",
    "            \"\"\"Return fully‑formed prompt & store it\"\"\"\n",
    "            header = (\n",
    "                \"You are an analytical assistant. Follow ALL rules:\\n\"\n",
    "                f\"• Focus **only** on the topic '{topic}'.\\n\"\n",
    "                \"• Ignore unrelated features.\\n\"\n",
    "                \"• Use English even if reviews were translated.\\n\"\n",
    "                \"• Be factual, concise (temperature 0).\\n\"\n",
    "            )\n",
    "            if kind == \"summary\":\n",
    "                body = (\n",
    "                    \"Write one concise paragraph (3‑5 sentences) that \"\n",
    "                    \"summarises what users say about this topic, covering \"\n",
    "                    \"both pain points and praise.\"\n",
    "                )\n",
    "            else:\n",
    "                label = \"negative issues\" if kind == \"issues\" else \"positive aspects\"\n",
    "                prefix = \"-\" if kind == \"issues\" else \"+\"\n",
    "                body = (\n",
    "                    f\"List up to {MAX_BULLETS} main {label}. \"\n",
    "                    f\"Each line MUST start with '{prefix} '. \"\n",
    "                    \"Use short noun phrases, no duplication, no periods.\"\n",
    "                )\n",
    "\n",
    "            prompt = (\n",
    "                f\"{header}\\n\\nCONTEXT:\\n{ctx_block}\\n\\nSAMPLES:\\n{sample_blob}\\n\\nTASK:\\n{body}\"\n",
    "            )\n",
    "            prompts[kind] = prompt\n",
    "            return prompt\n",
    "\n",
    "        # ----- call Ollama (three prompts in parallel) ----------------\n",
    "        with ThreadPoolExecutor(max_workers=3) as pool:\n",
    "            futures = {\n",
    "                pool.submit(ollama_runner, build(k), ollama_model_name): k\n",
    "                for k in (\"summary\", \"issues\", \"positives\")\n",
    "            }\n",
    "            raw = {k: f.result().strip() for f, k in futures.items()}\n",
    "\n",
    "        summary_text = raw[\"summary\"]\n",
    "        issues_list  = _parse_bullets(raw[\"issues\"], \"-\")\n",
    "        pos_list     = _parse_bullets(raw[\"positives\"], \"+\")\n",
    "\n",
    "        results[topic] = TopicSummary(\n",
    "            summary=summary_text,\n",
    "            issues=issues_list,\n",
    "            positives=pos_list,\n",
    "            avg_rating=avg,\n",
    "            review_count=len(sub),\n",
    "            sentiment_dist=mix,\n",
    "            top_keywords=keywords,\n",
    "            top_phrases=phrases,\n",
    "            prompts=prompts,\n",
    "        )\n",
    "\n",
    "    # ------------- render & plot -------------------------------------\n",
    "    _render_cards(results)\n",
    "    _plot_chart(results, df)\n",
    "    return {k: v.__dict__ for k, v in results.items()}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – HTML CARDS\n",
    "# -------------------------------------------------------------------\n",
    "def _render_cards(data: Dict[str, TopicSummary]) -> None:\n",
    "    css = textwrap.dedent(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "          :root {{--blue:{blue};--neg:#E53935;--pos:#43A047;--neu:#FFA000;\n",
    "                 --bg:#fff;--text:#1a1a1a;}}\n",
    "          @media (prefers-color-scheme: dark) {{\n",
    "              :root {{--bg:#121212;--text:#e0e0e0;}}\n",
    "          }}\n",
    "          body {{background:var(--bg);color:var(--text);}}\n",
    "\n",
    "/* container */\n",
    "          .cards {{max-width:1200px;margin:0 auto;font-family:'Helvetica Neue',Arial,sans-serif;}}\n",
    "\n",
    "/* card */\n",
    "          .card {{\n",
    "              display:grid;grid-template-columns:220px 1fr;\n",
    "              border:1px solid #bbb;border-radius:8px;margin:18px 0;\n",
    "              overflow:hidden;box-shadow:0 4px 10px rgba(0,0,0,.12);\n",
    "              animation:fadeIn .4s ease;\n",
    "          }}\n",
    "          @keyframes fadeIn {{from {{opacity:0;transform:translateY(8px);}}\n",
    "                              to   {{opacity:1;transform:translateY(0);}}}}\n",
    "          header {{\n",
    "              grid-column:1/-1;background:linear-gradient(135deg,var(--blue) 0%,#0088cc 100%);\n",
    "              color:#fff;padding:12px 18px;font-size:20px;font-weight:600;\n",
    "          }}\n",
    "\n",
    "/* sidebar */\n",
    "          .side {{\n",
    "              background:#f5f7fa;border-right:1px solid #ddd;\n",
    "              padding:14px;display:flex;flex-direction:column;gap:14px;\n",
    "          }}\n",
    "          .stat .num {{font-weight:700;font-size:19px;line-height:1;color:var(--text);}}\n",
    "          .stat .label{{font-size:11px;text-transform:uppercase;font-weight:600;\n",
    "                       letter-spacing:.4px;color:var(--text);}}\n",
    "          .bar {{display:flex;height:10px;border-radius:4px;overflow:hidden;margin-top:4px;}}\n",
    "          .seg {{flex-shrink:0;transition:opacity .2s;}} .seg:hover {{opacity:.75;}}\n",
    "          .neg{{background:var(--neg);}} .pos{{background:var(--pos);}} .neu{{background:var(--neu);}}\n",
    "\n",
    "/* main */\n",
    "          .main {{padding:18px;line-height:1.6;}}\n",
    "          .summary {{\n",
    "              background:rgba(0,102,177,.07);border-left:3px solid var(--blue);\n",
    "              padding:10px;margin-bottom:16px;line-height:1.6;\n",
    "          }}\n",
    "          .cols {{display:flex;flex-wrap:wrap;gap:24px;margin-bottom:16px;}}\n",
    "          h4 {{margin:0 0 6px;color:var(--blue);font-weight:600;}}\n",
    "          ul {{margin:0;padding-left:18px;}}\n",
    "          li {{margin:4px 0;}}\n",
    "\n",
    "/* chips */\n",
    "          .chips {{margin-bottom:10px;}}\n",
    "          .chip {{\n",
    "              display:inline-block;padding:4px 10px;border-radius:20px;\n",
    "              font-size:11px;font-weight:700;margin:2px;cursor:pointer;\n",
    "              transition:opacity .2s;\n",
    "          }}\n",
    "          .chip:hover {{opacity:.8;}}\n",
    "          .kw{{background:#e3f2fd;color:var(--blue);}}\n",
    "          .ph{{background:#e8f5e9;color:#2e7d32;border:1px solid #c8e6c9;}}\n",
    "\n",
    "/* responsive */\n",
    "          @media (max-width:768px){{\n",
    "              .card{{grid-template-columns:1fr}}\n",
    "              .side{{order:2;border:none;border-top:1px solid #ddd;\n",
    "                    flex-direction:row;justify-content:space-around}}\n",
    "          }}\n",
    "        </style>\n",
    "        \"\"\"\n",
    "    ).format(blue=BMW_BLUE)\n",
    "\n",
    "    output: List[str] = [css, \"<div class='cards'>\"]\n",
    "\n",
    "    # sort by review count\n",
    "    for topic, info in sorted(data.items(), key=lambda x: x[1].review_count, reverse=True):\n",
    "        if topic.lower() == \"other\":\n",
    "            continue\n",
    "\n",
    "        bar = \"\".join(_bar_seg(name, frac) for name, frac in info.sentiment_dist.items())\n",
    "        kw_html = \"\".join(f\"<span class='chip kw'>{html.escape(k)}</span>\" for k in info.top_keywords)\n",
    "        ph_html = \"\".join(f\"<span class='chip ph'>{html.escape(p)}</span>\" for p in info.top_phrases)\n",
    "        issues_html = \"\".join(f\"<li>{html.escape(i)}</li>\" for i in info.issues) or \"<li>No major issues</li>\"\n",
    "        pos_html = \"\".join(f\"<li>{html.escape(p)}</li>\" for p in info.positives) or \"<li>No specific positives</li>\"\n",
    "\n",
    "        output.append(\n",
    "            f\"<div class='card'>\"\n",
    "            f\"<header>{html.escape(topic)}</header>\"\n",
    "\n",
    "            f\"<section class='side'>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.review_count}</span><span class='label'>Reviews</span></div>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.avg_rating:.2f}/5 {info.stars}</span>\"\n",
    "            f\"<span class='label'>Average</span></div>\"\n",
    "            f\"<div class='stat'><span class='label'>Sentiment</span><div class='bar'>{bar}</div></div>\"\n",
    "            \"</section>\"\n",
    "\n",
    "            \"<section class='main'>\"\n",
    "            f\"<p class='summary'>{html.escape(info.summary)}</p>\"\n",
    "            \"<div class='cols'>\"\n",
    "            f\"<div><h4>Issues</h4><ul>{issues_html}</ul></div>\"\n",
    "            f\"<div><h4>Positives</h4><ul>{pos_html}</ul></div>\"\n",
    "            \"</div>\"\n",
    "            f\"<div class='chips'><h4>Keywords</h4>{kw_html}</div>\"\n",
    "            f\"<div class='chips'><h4>Phrases</h4>{ph_html}</div>\"\n",
    "            \"</section>\"\n",
    "            \"</div>\"\n",
    "        )\n",
    "\n",
    "    output.append(\"</div>\")\n",
    "    display(HTML(\"\\n\".join(output)))\n",
    "\n",
    "def _bar_seg(name: str, frac: float) -> str:\n",
    "    cls = \"pos\" if name == \"positive\" else \"neg\" if name == \"negative\" else \"neu\"\n",
    "    pct = max(frac * 100, 1)\n",
    "    return f\"<span class='seg {cls}' style='width:{pct}%' title='{name}: {frac:.1%}'></span>\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – MATPLOTLIB CHART\n",
    "# -------------------------------------------------------------------\n",
    "def _plot_chart(data: Dict[str, TopicSummary], df: pd.DataFrame) -> None:\n",
    "    rows = [(t, d.avg_rating, d.review_count) for t, d in data.items() if t.lower() != \"other\"]\n",
    "    if not rows:\n",
    "        return\n",
    "    topics, ratings, counts = zip(*rows)\n",
    "    order = sorted(range(len(topics)), key=lambda i: ratings[i])\n",
    "    topics = [topics[i] for i in order]\n",
    "    ratings = [ratings[i] for i in order]\n",
    "    counts = [counts[i] for i in order]\n",
    "\n",
    "    cmap = mpl.colormaps.get_cmap(\"viridis\").resampled(len(topics))\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    bars = plt.barh(topics, ratings, color=[cmap(i) for i in range(len(topics))])\n",
    "\n",
    "    for bar, cnt, rating in zip(bars, counts, ratings):\n",
    "        x = rating + 0.05 if rating < 2.5 else rating - 0.6\n",
    "        clr = \"black\" if rating < 2.5 else \"white\"\n",
    "        plt.text(x, bar.get_y() + bar.get_height() / 2, f\"n={cnt}\", va=\"center\",\n",
    "                 color=clr, fontweight=\"bold\")\n",
    "\n",
    "    mean = df[\"score\"].mean()\n",
    "    plt.axvline(mean, linestyle=\"--\", linewidth=2, label=f\"Overall {mean:.2f}\")\n",
    "    plt.xticks(range(1, 6), [\"★\" * i for i in range(1, 6)])\n",
    "    plt.xlim(0, 5.2)\n",
    "    plt.xlabel(\"Star Rating\")\n",
    "    plt.ylabel(\"Topic\")\n",
    "    plt.title(\"BMW App – Average Rating by Topic\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MISC HELPERS\n",
    "# -------------------------------------------------------------------\n",
    "def _setup_logger() -> logging.Logger:\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "    return logging.getLogger(\"bmw_topic_cards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a2bda367524d80b4eada2871b3891d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Topics:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create visual topic cards\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m topic_summaries \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_topic_cards_from_classified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_classified\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 184\u001b[0m, in \u001b[0;36mcreate_topic_cards_from_classified\u001b[0;34m(df, ollama_model_name, ollama_runner)\u001b[0m\n\u001b[1;32m    181\u001b[0m phrases \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p, _ \u001b[38;5;129;01min\u001b[39;00m Counter(bigrams)\u001b[38;5;241m.\u001b[39mmost_common(N_PHRASES)]\n\u001b[1;32m    183\u001b[0m sample_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(PROMPT_SAMPLE_SIZE, \u001b[38;5;28mlen\u001b[39m(sub))\n\u001b[0;32m--> 184\u001b[0m sample_texts \u001b[38;5;241m=\u001b[39m \u001b[43m_stratified_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_n\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m sample_blob \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, txt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample_texts))\n\u001b[1;32m    187\u001b[0m ctx_block \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage score \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (n=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sub)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment mix: neg \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmix\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.0%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop phrases: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(phrases)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    194\u001b[0m )\n",
      "Cell \u001b[0;32mIn[26], line 81\u001b[0m, in \u001b[0;36m_stratified_sample\u001b[0;34m(df, size, seed)\u001b[0m\n\u001b[1;32m     79\u001b[0m diff \u001b[38;5;241m=\u001b[39m size \u001b[38;5;241m-\u001b[39m \u001b[38;5;28msum\u001b[39m(quota\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[0;32m---> 81\u001b[0m     quota[\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnegative\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m diff\n\u001b[1;32m     83\u001b[0m col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_english\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_english\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m texts: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Create visual topic cards\n",
    "topic_summaries = create_topic_cards_from_classified(df_classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentiNext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
