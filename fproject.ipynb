{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmw_topic_cards.py  –  v6  (2025‑05‑02)\n",
    "# ================================================================\n",
    "# • Stratified random sampling (mirrors topic sentiment mix)\n",
    "# • One paragraph summary  +  “‑ ” negative bullets  +  “+ ” positive bullets\n",
    "# • Prompts stored inside TopicSummary.prompts  (audit / debugging)\n",
    "# • No JSON parsing, so Ollama chatter can’t break the pipeline\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import html\n",
    "import logging\n",
    "import subprocess\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  CONFIGURATION\n",
    "# -------------------------------------------------------------------\n",
    "TOP_N_TOPICS        = 15          # how many topics to visualise\n",
    "PROMPT_SAMPLE_SIZE  = 300         # reviews fed to each LLM prompt\n",
    "N_KEYWORDS          = 8\n",
    "N_PHRASES           = 5\n",
    "MAX_BULLETS         = 7           # issues / positives\n",
    "BMW_BLUE            = \"#0066B1\"\n",
    "\n",
    "STAR_SVG = (\n",
    "    \"<svg width='14' height='14' viewBox='0 0 24 24' \"\n",
    "    \"xmlns='http://www.w3.org/2000/svg' style='vertical-align:-2px'>\"\n",
    "    \"<polygon fill='#FFD700' \"\n",
    "    \"points='12 2 15.09 8.26 22 9.27 17 14.14 \"\n",
    "    \"18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26'/></svg>\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  NLTK – bootstrap stop‑words\n",
    "# -------------------------------------------------------------------\n",
    "for res in (\"stopwords\", \"punkt\"):\n",
    "    try:\n",
    "        nltk.data.find(f\"corpora/{res}\")\n",
    "    except LookupError:\n",
    "        nltk.download(res, quiet=True)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\")) | {\n",
    "    \"bmw\", \"app\", \"car\", \"please\", \"would\", \"also\", \"get\", \"use\", \"using\"\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  OLLAMA RUNNER  (temperature 0 for determinism)\n",
    "# -------------------------------------------------------------------\n",
    "def _subprocess_runner(prompt: str, model: str) -> str:\n",
    "    proc = subprocess.run(\n",
    "        [\"ollama\", \"run\", model, \"-t\", \"0\"],\n",
    "        input=prompt,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        check=False,\n",
    "    )\n",
    "    return proc.stdout\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  STRATIFIED SAMPLING  (mirror sentiment mix)\n",
    "# -------------------------------------------------------------------\n",
    "def _stratified_sample(df: pd.DataFrame, size: int, seed: int = 0) -> List[str]:\n",
    "    dist = df[\"sentiment\"].value_counts(normalize=True)\n",
    "    quota = {s: int(round(dist.get(s, 0) * size)) for s in (\"negative\", \"positive\", \"neutral\")}\n",
    "    diff = size - sum(quota.values())\n",
    "    if diff:\n",
    "        quota[max(dist, key=dist.get, default=\"negative\")] += diff\n",
    "\n",
    "    col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "    texts: List[str] = []\n",
    "\n",
    "    for sentiment, n in quota.items():\n",
    "        if n <= 0:\n",
    "            continue\n",
    "        bucket = df[df[\"sentiment\"] == sentiment]\n",
    "        sample_n = min(n, len(bucket))\n",
    "        texts.extend(bucket.sample(sample_n, random_state=seed)[col].tolist())\n",
    "\n",
    "    # top‑up if any bucket ran short\n",
    "    if len(texts) < size:\n",
    "        short = size - len(texts)\n",
    "        remainder = df.drop(df.index[df[col].isin(texts)]).sample(short, random_state=seed)\n",
    "        texts.extend(remainder[col].tolist())\n",
    "\n",
    "    return texts\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  BULLET‑PARSER\n",
    "# -------------------------------------------------------------------\n",
    "def _parse_bullets(text: str, prefix: str) -> List[str]:\n",
    "    \"\"\"Return list of lines starting with the prefix (‘- ’ or ‘+ ’).\"\"\"\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    bullets = [ln[len(prefix):].strip() for ln in lines if ln.startswith(prefix)]\n",
    "    # fallback to comma‑sep if model ignored prefixes\n",
    "    if not bullets and \",\" in text:\n",
    "        bullets = [part.strip() for part in text.split(\",\") if part.strip()]\n",
    "    return bullets[:MAX_BULLETS]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  DATACLASS\n",
    "# -------------------------------------------------------------------\n",
    "@dataclass\n",
    "class TopicSummary:\n",
    "    summary: str\n",
    "    issues: List[str]\n",
    "    positives: List[str]\n",
    "    avg_rating: float\n",
    "    review_count: int\n",
    "    sentiment_dist: Dict[str, float]\n",
    "    top_keywords: List[str]\n",
    "    top_phrases: List[str]\n",
    "    prompts: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "    @property\n",
    "    def stars(self) -> str:\n",
    "        full, half = int(self.avg_rating), self.avg_rating - int(self.avg_rating) >= 0.5\n",
    "        return STAR_SVG * full + (STAR_SVG if half else \"\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MAIN ENTRY\n",
    "# -------------------------------------------------------------------\n",
    "def create_topic_cards_from_classified(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    ollama_model_name: str = \"gemma3:12b\",\n",
    "    ollama_runner: Callable[[str, str], str] = _subprocess_runner,\n",
    ") -> Dict[str, TopicSummary]:\n",
    "    \"\"\"\n",
    "    Render topic cards & a rating chart; return dict[topic] -> TopicSummary.\n",
    "    Prompts are stored in `TopicSummary.prompts`.\n",
    "    \"\"\"\n",
    "    log = _setup_logger()\n",
    "\n",
    "    # -------- sanity checks -----------------------------------------\n",
    "    if {\"topics\", \"sentiment\"} - set(df.columns):\n",
    "        raise ValueError(\"DataFrame must include 'topics' & 'sentiment'.\")\n",
    "\n",
    "    text_col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "\n",
    "    if \"score\" not in df.columns:\n",
    "        df[\"score\"] = (\n",
    "            df[\"sentiment\"]\n",
    "            .map({\"positive\": 4.5, \"neutral\": 3.0, \"negative\": 1.5})\n",
    "            .fillna(3.0)\n",
    "        )\n",
    "\n",
    "    # -------- pick top topics --------------------------------------\n",
    "    topics_freq = df[\"topics\"].str.get_dummies(sep=\",\").sum()\n",
    "    top_topics = (\n",
    "        topics_freq.sort_values(ascending=False).head(TOP_N_TOPICS).index\n",
    "    )\n",
    "\n",
    "    results: Dict[str, TopicSummary] = {}\n",
    "\n",
    "    for topic in tqdm(top_topics, desc=\"Topics\"):\n",
    "        sub = df[df[\"topics\"].str.contains(fr\"\\b{topic}\\b\", case=False, na=False)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        avg = sub[\"score\"].mean()\n",
    "        mix = sub[\"sentiment\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "        tokens = word_tokenize(\" \".join(sub[text_col].fillna(\"\").str.lower()))\n",
    "        tokens = [t for t in tokens if t.isalpha() and t not in STOPWORDS and len(t) > 2]\n",
    "        keywords = [w for w, _ in Counter(tokens).most_common(N_KEYWORDS)]\n",
    "        bigrams = [f\"{a} {b}\" for a, b in zip(tokens, tokens[1:])]\n",
    "        phrases = [p for p, _ in Counter(bigrams).most_common(N_PHRASES)]\n",
    "\n",
    "        sample_n = min(PROMPT_SAMPLE_SIZE, len(sub))\n",
    "        sample_texts = _stratified_sample(sub, sample_n)\n",
    "        sample_blob = \"\\n\".join(f\"[{i}] {txt}\" for i, txt in enumerate(sample_texts))\n",
    "\n",
    "        ctx_block = (\n",
    "            f\"Average score {avg:.2f} (n={len(sub)}). \"\n",
    "            f\"Sentiment mix: neg {mix.get('negative',0):.0%}, \"\n",
    "            f\"pos {mix.get('positive',0):.0%}, \"\n",
    "            f\"neu {mix.get('neutral',0):.0%}.\\n\"\n",
    "            f\"Top keywords: {', '.join(keywords)}.\\n\"\n",
    "            f\"Top phrases: {', '.join(phrases)}.\"\n",
    "        )\n",
    "\n",
    "        prompts: Dict[str, str] = {}\n",
    "\n",
    "        def build(kind: str) -> str:\n",
    "            \"\"\"Return fully‑formed prompt & store it\"\"\"\n",
    "            header = (\n",
    "                \"You are an analytical assistant. Follow ALL rules:\\n\"\n",
    "                f\"• Focus **only** on the topic '{topic}'.\\n\"\n",
    "                \"• Ignore unrelated features.\\n\"\n",
    "                \"• Use English even if reviews were translated.\\n\"\n",
    "                \"• Be factual, concise (temperature 0).\\n\"\n",
    "            )\n",
    "            if kind == \"summary\":\n",
    "                body = (\n",
    "                    \"Write one concise paragraph (3‑5 sentences) that \"\n",
    "                    \"summarises what users say about this topic, covering \"\n",
    "                    \"both pain points and praise.\"\n",
    "                )\n",
    "            else:\n",
    "                label = \"negative issues\" if kind == \"issues\" else \"positive aspects\"\n",
    "                prefix = \"-\" if kind == \"issues\" else \"+\"\n",
    "                body = (\n",
    "                    f\"List up to {MAX_BULLETS} main {label}. \"\n",
    "                    f\"Each line MUST start with '{prefix} '. \"\n",
    "                    \"Use short noun phrases, no duplication, no periods.\"\n",
    "                )\n",
    "\n",
    "            prompt = (\n",
    "                f\"{header}\\n\\nCONTEXT:\\n{ctx_block}\\n\\nSAMPLES:\\n{sample_blob}\\n\\nTASK:\\n{body}\"\n",
    "            )\n",
    "            prompts[kind] = prompt\n",
    "            return prompt\n",
    "\n",
    "        # ----- call Ollama (three prompts in parallel) ----------------\n",
    "        with ThreadPoolExecutor(max_workers=3) as pool:\n",
    "            futures = {\n",
    "                pool.submit(ollama_runner, build(k), ollama_model_name): k\n",
    "                for k in (\"summary\", \"issues\", \"positives\")\n",
    "            }\n",
    "            raw = {k: f.result().strip() for f, k in futures.items()}\n",
    "\n",
    "        summary_text = raw[\"summary\"]\n",
    "        issues_list  = _parse_bullets(raw[\"issues\"], \"-\")\n",
    "        pos_list     = _parse_bullets(raw[\"positives\"], \"+\")\n",
    "\n",
    "        results[topic] = TopicSummary(\n",
    "            summary=summary_text,\n",
    "            issues=issues_list,\n",
    "            positives=pos_list,\n",
    "            avg_rating=avg,\n",
    "            review_count=len(sub),\n",
    "            sentiment_dist=mix,\n",
    "            top_keywords=keywords,\n",
    "            top_phrases=phrases,\n",
    "            prompts=prompts,\n",
    "        )\n",
    "\n",
    "    # ------------- render & plot -------------------------------------\n",
    "    _render_cards(results)\n",
    "    _plot_chart(results, df)\n",
    "    return {k: v.__dict__ for k, v in results.items()}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – HTML CARDS\n",
    "# -------------------------------------------------------------------\n",
    "def _render_cards(data: Dict[str, TopicSummary]) -> None:\n",
    "    css = textwrap.dedent(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "          :root {{--blue:{blue};--neg:#E53935;--pos:#43A047;--neu:#FFA000;\n",
    "                 --bg:#fff;--text:#1a1a1a;}}\n",
    "          @media (prefers-color-scheme: dark) {{\n",
    "              :root {{--bg:#121212;--text:#e0e0e0;}}\n",
    "          }}\n",
    "          body {{background:var(--bg);color:var(--text);}}\n",
    "\n",
    "/* container */\n",
    "          .cards {{max-width:1200px;margin:0 auto;font-family:'Helvetica Neue',Arial,sans-serif;}}\n",
    "\n",
    "/* card */\n",
    "          .card {{\n",
    "              display:grid;grid-template-columns:220px 1fr;\n",
    "              border:1px solid #bbb;border-radius:8px;margin:18px 0;\n",
    "              overflow:hidden;box-shadow:0 4px 10px rgba(0,0,0,.12);\n",
    "              animation:fadeIn .4s ease;\n",
    "          }}\n",
    "          @keyframes fadeIn {{from {{opacity:0;transform:translateY(8px);}}\n",
    "                              to   {{opacity:1;transform:translateY(0);}}}}\n",
    "          header {{\n",
    "              grid-column:1/-1;background:linear-gradient(135deg,var(--blue) 0%,#0088cc 100%);\n",
    "              color:#fff;padding:12px 18px;font-size:20px;font-weight:600;\n",
    "          }}\n",
    "\n",
    "/* sidebar */\n",
    "          .side {{\n",
    "              background:#f5f7fa;border-right:1px solid #ddd;\n",
    "              padding:14px;display:flex;flex-direction:column;gap:14px;\n",
    "          }}\n",
    "          .stat .num {{font-weight:700;font-size:19px;line-height:1;color:var(--text);}}\n",
    "          .stat .label{{font-size:11px;text-transform:uppercase;font-weight:600;\n",
    "                       letter-spacing:.4px;color:var(--text);}}\n",
    "          .bar {{display:flex;height:10px;border-radius:4px;overflow:hidden;margin-top:4px;}}\n",
    "          .seg {{flex-shrink:0;transition:opacity .2s;}} .seg:hover {{opacity:.75;}}\n",
    "          .neg{{background:var(--neg);}} .pos{{background:var(--pos);}} .neu{{background:var(--neu);}}\n",
    "\n",
    "/* main */\n",
    "          .main {{padding:18px;line-height:1.6;}}\n",
    "          .summary {{\n",
    "              background:rgba(0,102,177,.07);border-left:3px solid var(--blue);\n",
    "              padding:10px;margin-bottom:16px;line-height:1.6;\n",
    "          }}\n",
    "          .cols {{display:flex;flex-wrap:wrap;gap:24px;margin-bottom:16px;}}\n",
    "          h4 {{margin:0 0 6px;color:var(--blue);font-weight:600;}}\n",
    "          ul {{margin:0;padding-left:18px;}}\n",
    "          li {{margin:4px 0;}}\n",
    "\n",
    "/* chips */\n",
    "          .chips {{margin-bottom:10px;}}\n",
    "          .chip {{\n",
    "              display:inline-block;padding:4px 10px;border-radius:20px;\n",
    "              font-size:11px;font-weight:700;margin:2px;cursor:pointer;\n",
    "              transition:opacity .2s;\n",
    "          }}\n",
    "          .chip:hover {{opacity:.8;}}\n",
    "          .kw{{background:#e3f2fd;color:var(--blue);}}\n",
    "          .ph{{background:#e8f5e9;color:#2e7d32;border:1px solid #c8e6c9;}}\n",
    "\n",
    "/* responsive */\n",
    "          @media (max-width:768px){{\n",
    "              .card{{grid-template-columns:1fr}}\n",
    "              .side{{order:2;border:none;border-top:1px solid #ddd;\n",
    "                    flex-direction:row;justify-content:space-around}}\n",
    "          }}\n",
    "        </style>\n",
    "        \"\"\"\n",
    "    ).format(blue=BMW_BLUE)\n",
    "\n",
    "    output: List[str] = [css, \"<div class='cards'>\"]\n",
    "\n",
    "    # sort by review count\n",
    "    for topic, info in sorted(data.items(), key=lambda x: x[1].review_count, reverse=True):\n",
    "        if topic.lower() == \"other\":\n",
    "            continue\n",
    "\n",
    "        bar = \"\".join(_bar_seg(name, frac) for name, frac in info.sentiment_dist.items())\n",
    "        kw_html = \"\".join(f\"<span class='chip kw'>{html.escape(k)}</span>\" for k in info.top_keywords)\n",
    "        ph_html = \"\".join(f\"<span class='chip ph'>{html.escape(p)}</span>\" for p in info.top_phrases)\n",
    "        issues_html = \"\".join(f\"<li>{html.escape(i)}</li>\" for i in info.issues) or \"<li>No major issues</li>\"\n",
    "        pos_html = \"\".join(f\"<li>{html.escape(p)}</li>\" for p in info.positives) or \"<li>No specific positives</li>\"\n",
    "\n",
    "        output.append(\n",
    "            f\"<div class='card'>\"\n",
    "            f\"<header>{html.escape(topic)}</header>\"\n",
    "\n",
    "            f\"<section class='side'>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.review_count}</span><span class='label'>Reviews</span></div>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.avg_rating:.2f}/5 {info.stars}</span>\"\n",
    "            f\"<span class='label'>Average</span></div>\"\n",
    "            f\"<div class='stat'><span class='label'>Sentiment</span><div class='bar'>{bar}</div></div>\"\n",
    "            \"</section>\"\n",
    "\n",
    "            \"<section class='main'>\"\n",
    "            f\"<p class='summary'>{html.escape(info.summary)}</p>\"\n",
    "            \"<div class='cols'>\"\n",
    "            f\"<div><h4>Issues</h4><ul>{issues_html}</ul></div>\"\n",
    "            f\"<div><h4>Positives</h4><ul>{pos_html}</ul></div>\"\n",
    "            \"</div>\"\n",
    "            f\"<div class='chips'><h4>Keywords</h4>{kw_html}</div>\"\n",
    "            f\"<div class='chips'><h4>Phrases</h4>{ph_html}</div>\"\n",
    "            \"</section>\"\n",
    "            \"</div>\"\n",
    "        )\n",
    "\n",
    "    output.append(\"</div>\")\n",
    "    display(HTML(\"\\n\".join(output)))\n",
    "\n",
    "def _bar_seg(name: str, frac: float) -> str:\n",
    "    cls = \"pos\" if name == \"positive\" else \"neg\" if name == \"negative\" else \"neu\"\n",
    "    pct = max(frac * 100, 1)\n",
    "    return f\"<span class='seg {cls}' style='width:{pct}%' title='{name}: {frac:.1%}'></span>\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – MATPLOTLIB CHART\n",
    "# -------------------------------------------------------------------\n",
    "def _plot_chart(data: Dict[str, TopicSummary], df: pd.DataFrame) -> None:\n",
    "    rows = [(t, d.avg_rating, d.review_count) for t, d in data.items() if t.lower() != \"other\"]\n",
    "    if not rows:\n",
    "        return\n",
    "    topics, ratings, counts = zip(*rows)\n",
    "    order = sorted(range(len(topics)), key=lambda i: ratings[i])\n",
    "    topics = [topics[i] for i in order]\n",
    "    ratings = [ratings[i] for i in order]\n",
    "    counts = [counts[i] for i in order]\n",
    "\n",
    "    cmap = mpl.colormaps.get_cmap(\"viridis\").resampled(len(topics))\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    bars = plt.barh(topics, ratings, color=[cmap(i) for i in range(len(topics))])\n",
    "\n",
    "    for bar, cnt, rating in zip(bars, counts, ratings):\n",
    "        x = rating + 0.05 if rating < 2.5 else rating - 0.6\n",
    "        clr = \"black\" if rating < 2.5 else \"white\"\n",
    "        plt.text(x, bar.get_y() + bar.get_height() / 2, f\"n={cnt}\", va=\"center\",\n",
    "                 color=clr, fontweight=\"bold\")\n",
    "\n",
    "    mean = df[\"score\"].mean()\n",
    "    plt.axvline(mean, linestyle=\"--\", linewidth=2, label=f\"Overall {mean:.2f}\")\n",
    "    plt.xticks(range(1, 6), [\"★\" * i for i in range(1, 6)])\n",
    "    plt.xlim(0, 5.2)\n",
    "    plt.xlabel(\"Star Rating\")\n",
    "    plt.ylabel(\"Topic\")\n",
    "    plt.title(\"BMW App – Average Rating by Topic\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MISC HELPERS\n",
    "# -------------------------------------------------------------------\n",
    "def _setup_logger() -> logging.Logger:\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "    return logging.getLogger(\"bmw_topic_cards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmw_topic_cards.py  –  v6  (2025‑05‑02)\n",
    "# ================================================================\n",
    "# • Stratified random sampling (mirrors topic sentiment mix)\n",
    "# • One paragraph summary  +  “‑ ” negative bullets  +  “+ ” positive bullets\n",
    "# • Prompts stored inside TopicSummary.prompts  (audit / debugging)\n",
    "# • No JSON parsing, so Ollama chatter can’t break the pipeline\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import html\n",
    "import logging\n",
    "import subprocess\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  CONFIGURATION\n",
    "# -------------------------------------------------------------------\n",
    "TOP_N_TOPICS        = 15          # how many topics to visualise\n",
    "PROMPT_SAMPLE_SIZE  = 300         # reviews fed to each LLM prompt\n",
    "N_KEYWORDS          = 8\n",
    "N_PHRASES           = 5\n",
    "MAX_BULLETS         = 7           # issues / positives\n",
    "BMW_BLUE            = \"#0066B1\"\n",
    "\n",
    "STAR_SVG = (\n",
    "    \"<svg width='14' height='14' viewBox='0 0 24 24' \"\n",
    "    \"xmlns='http://www.w3.org/2000/svg' style='vertical-align:-2px'>\"\n",
    "    \"<polygon fill='#FFD700' \"\n",
    "    \"points='12 2 15.09 8.26 22 9.27 17 14.14 \"\n",
    "    \"18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26'/></svg>\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  NLTK – bootstrap stop‑words\n",
    "# -------------------------------------------------------------------\n",
    "for res in (\"stopwords\", \"punkt\"):\n",
    "    try:\n",
    "        nltk.data.find(f\"corpora/{res}\")\n",
    "    except LookupError:\n",
    "        nltk.download(res, quiet=True)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\")) | {\n",
    "    \"bmw\", \"app\", \"car\", \"please\", \"would\", \"also\", \"get\", \"use\", \"using\"\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  OLLAMA RUNNER  (temperature 0 for determinism)\n",
    "# -------------------------------------------------------------------\n",
    "def _subprocess_runner(prompt: str, model: str) -> str:\n",
    "    proc = subprocess.run(\n",
    "        [\"ollama\", \"run\", model, \"-t\", \"0\"],\n",
    "        input=prompt,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        check=False,\n",
    "    )\n",
    "    return proc.stdout\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  STRATIFIED SAMPLING  (mirror sentiment mix)\n",
    "# -------------------------------------------------------------------\n",
    "def _stratified_sample(df: pd.DataFrame, size: int, seed: int = 0) -> List[str]:\n",
    "    dist = df[\"sentiment\"].value_counts(normalize=True)\n",
    "    quota = {s: int(round(dist.get(s, 0) * size)) for s in (\"negative\", \"positive\", \"neutral\")}\n",
    "    diff = size - sum(quota.values())\n",
    "    if diff:\n",
    "        quota[max(dist, key=dist.get, default=\"negative\")] += diff\n",
    "\n",
    "    col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "    texts: List[str] = []\n",
    "\n",
    "    for sentiment, n in quota.items():\n",
    "        if n <= 0:\n",
    "            continue\n",
    "        bucket = df[df[\"sentiment\"] == sentiment]\n",
    "        sample_n = min(n, len(bucket))\n",
    "        texts.extend(bucket.sample(sample_n, random_state=seed)[col].tolist())\n",
    "\n",
    "    # top‑up if any bucket ran short\n",
    "    if len(texts) < size:\n",
    "        short = size - len(texts)\n",
    "        remainder = df.drop(df.index[df[col].isin(texts)]).sample(short, random_state=seed)\n",
    "        texts.extend(remainder[col].tolist())\n",
    "\n",
    "    return texts\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  BULLET‑PARSER\n",
    "# -------------------------------------------------------------------\n",
    "def _parse_bullets(text: str, prefix: str) -> List[str]:\n",
    "    \"\"\"Return list of lines starting with the prefix (‘- ’ or ‘+ ’).\"\"\"\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    bullets = [ln[len(prefix):].strip() for ln in lines if ln.startswith(prefix)]\n",
    "    # fallback to comma‑sep if model ignored prefixes\n",
    "    if not bullets and \",\" in text:\n",
    "        bullets = [part.strip() for part in text.split(\",\") if part.strip()]\n",
    "    return bullets[:MAX_BULLETS]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  DATACLASS\n",
    "# -------------------------------------------------------------------\n",
    "@dataclass\n",
    "class TopicSummary:\n",
    "    summary: str\n",
    "    issues: List[str]\n",
    "    positives: List[str]\n",
    "    avg_rating: float\n",
    "    review_count: int\n",
    "    sentiment_dist: Dict[str, float]\n",
    "    top_keywords: List[str]\n",
    "    top_phrases: List[str]\n",
    "    prompts: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "    @property\n",
    "    def stars(self) -> str:\n",
    "        full, half = int(self.avg_rating), self.avg_rating - int(self.avg_rating) >= 0.5\n",
    "        return STAR_SVG * full + (STAR_SVG if half else \"\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MAIN ENTRY\n",
    "# -------------------------------------------------------------------\n",
    "def create_topic_cards_from_classified(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    ollama_model_name: str = \"gemma3:12b\",\n",
    "    ollama_runner: Callable[[str, str], str] = _subprocess_runner,\n",
    ") -> Dict[str, TopicSummary]:\n",
    "    \"\"\"\n",
    "    Render topic cards & a rating chart; return dict[topic] -> TopicSummary.\n",
    "    Prompts are stored in `TopicSummary.prompts`.\n",
    "    \"\"\"\n",
    "    log = _setup_logger()\n",
    "\n",
    "    # -------- sanity checks -----------------------------------------\n",
    "    if {\"topics\", \"sentiment\"} - set(df.columns):\n",
    "        raise ValueError(\"DataFrame must include 'topics' & 'sentiment'.\")\n",
    "\n",
    "    text_col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "\n",
    "    if \"score\" not in df.columns:\n",
    "        df[\"score\"] = (\n",
    "            df[\"sentiment\"]\n",
    "            .map({\"positive\": 4.5, \"neutral\": 3.0, \"negative\": 1.5})\n",
    "            .fillna(3.0)\n",
    "        )\n",
    "\n",
    "    # -------- pick top topics --------------------------------------\n",
    "    topics_freq = df[\"topics\"].str.get_dummies(sep=\",\").sum()\n",
    "    top_topics = (\n",
    "        topics_freq.sort_values(ascending=False).head(TOP_N_TOPICS).index\n",
    "    )\n",
    "\n",
    "    results: Dict[str, TopicSummary] = {}\n",
    "\n",
    "    for topic in tqdm(top_topics, desc=\"Topics\"):\n",
    "        sub = df[df[\"topics\"].str.contains(fr\"\\b{topic}\\b\", case=False, na=False)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        avg = sub[\"score\"].mean()\n",
    "        mix = sub[\"sentiment\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "        tokens = word_tokenize(\" \".join(sub[text_col].fillna(\"\").str.lower()))\n",
    "        tokens = [t for t in tokens if t.isalpha() and t not in STOPWORDS and len(t) > 2]\n",
    "        keywords = [w for w, _ in Counter(tokens).most_common(N_KEYWORDS)]\n",
    "        bigrams = [f\"{a} {b}\" for a, b in zip(tokens, tokens[1:])]\n",
    "        phrases = [p for p, _ in Counter(bigrams).most_common(N_PHRASES)]\n",
    "\n",
    "        sample_n = min(PROMPT_SAMPLE_SIZE, len(sub))\n",
    "        sample_texts = _stratified_sample(sub, sample_n)\n",
    "        sample_blob = \"\\n\".join(f\"[{i}] {txt}\" for i, txt in enumerate(sample_texts))\n",
    "\n",
    "        ctx_block = (\n",
    "            f\"Average score {avg:.2f} (n={len(sub)}). \"\n",
    "            f\"Sentiment mix: neg {mix.get('negative',0):.0%}, \"\n",
    "            f\"pos {mix.get('positive',0):.0%}, \"\n",
    "            f\"neu {mix.get('neutral',0):.0%}.\\n\"\n",
    "            f\"Top keywords: {', '.join(keywords)}.\\n\"\n",
    "            f\"Top phrases: {', '.join(phrases)}.\"\n",
    "        )\n",
    "\n",
    "        prompts: Dict[str, str] = {}\n",
    "\n",
    "        def build(kind: str) -> str:\n",
    "            \"\"\"Return fully‑formed prompt & store it\"\"\"\n",
    "            header = (\n",
    "                \"You are an analytical assistant. Follow ALL rules:\\n\"\n",
    "                f\"• Focus **only** on the topic '{topic}'.\\n\"\n",
    "                \"• Ignore unrelated features.\\n\"\n",
    "                \"• Use English even if reviews were translated.\\n\"\n",
    "                \"• Be factual, concise (temperature 0).\\n\"\n",
    "            )\n",
    "            if kind == \"summary\":\n",
    "                body = (\n",
    "                    \"Write one concise paragraph (3‑5 sentences) that \"\n",
    "                    \"summarises what users say about this topic, covering \"\n",
    "                    \"both pain points and praise.\"\n",
    "                )\n",
    "            else:\n",
    "                label = \"negative issues\" if kind == \"issues\" else \"positive aspects\"\n",
    "                prefix = \"-\" if kind == \"issues\" else \"+\"\n",
    "                body = (\n",
    "                    f\"List up to {MAX_BULLETS} main {label}. \"\n",
    "                    f\"Each line MUST start with '{prefix} '. \"\n",
    "                    \"Use short noun phrases, no duplication, no periods.\"\n",
    "                )\n",
    "\n",
    "            prompt = (\n",
    "                f\"{header}\\n\\nCONTEXT:\\n{ctx_block}\\n\\nSAMPLES:\\n{sample_blob}\\n\\nTASK:\\n{body}\"\n",
    "            )\n",
    "            prompts[kind] = prompt\n",
    "            return prompt\n",
    "\n",
    "        # ----- call Ollama (three prompts in parallel) ----------------\n",
    "        with ThreadPoolExecutor(max_workers=3) as pool:\n",
    "            futures = {\n",
    "                pool.submit(ollama_runner, build(k), ollama_model_name): k\n",
    "                for k in (\"summary\", \"issues\", \"positives\")\n",
    "            }\n",
    "            raw = {k: f.result().strip() for f, k in futures.items()}\n",
    "\n",
    "        summary_text = raw[\"summary\"]\n",
    "        issues_list  = _parse_bullets(raw[\"issues\"], \"-\")\n",
    "        pos_list     = _parse_bullets(raw[\"positives\"], \"+\")\n",
    "\n",
    "        results[topic] = TopicSummary(\n",
    "            summary=summary_text,\n",
    "            issues=issues_list,\n",
    "            positives=pos_list,\n",
    "            avg_rating=avg,\n",
    "            review_count=len(sub),\n",
    "            sentiment_dist=mix,\n",
    "            top_keywords=keywords,\n",
    "            top_phrases=phrases,\n",
    "            prompts=prompts,\n",
    "        )\n",
    "\n",
    "    # ------------- render & plot -------------------------------------\n",
    "    _render_cards(results)\n",
    "    _plot_chart(results, df)\n",
    "    return {k: v.__dict__ for k, v in results.items()}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – HTML CARDS\n",
    "# -------------------------------------------------------------------\n",
    "def _render_cards(data: Dict[str, TopicSummary]) -> None:\n",
    "    css = textwrap.dedent(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "          :root {{--blue:{blue};--neg:#E53935;--pos:#43A047;--neu:#FFA000;\n",
    "                 --bg:#fff;--text:#1a1a1a;}}\n",
    "          @media (prefers-color-scheme: dark) {{\n",
    "              :root {{--bg:#121212;--text:#e0e0e0;}}\n",
    "          }}\n",
    "          body {{background:var(--bg);color:var(--text);}}\n",
    "\n",
    "/* container */\n",
    "          .cards {{max-width:1200px;margin:0 auto;font-family:'Helvetica Neue',Arial,sans-serif;}}\n",
    "\n",
    "/* card */\n",
    "          .card {{\n",
    "              display:grid;grid-template-columns:220px 1fr;\n",
    "              border:1px solid #bbb;border-radius:8px;margin:18px 0;\n",
    "              overflow:hidden;box-shadow:0 4px 10px rgba(0,0,0,.12);\n",
    "              animation:fadeIn .4s ease;\n",
    "          }}\n",
    "          @keyframes fadeIn {{from {{opacity:0;transform:translateY(8px);}}\n",
    "                              to   {{opacity:1;transform:translateY(0);}}}}\n",
    "          header {{\n",
    "              grid-column:1/-1;background:linear-gradient(135deg,var(--blue) 0%,#0088cc 100%);\n",
    "              color:#fff;padding:12px 18px;font-size:20px;font-weight:600;\n",
    "          }}\n",
    "\n",
    "/* sidebar */\n",
    "          .side {{\n",
    "              background:#f5f7fa;border-right:1px solid #ddd;\n",
    "              padding:14px;display:flex;flex-direction:column;gap:14px;\n",
    "          }}\n",
    "          .stat .num {{font-weight:700;font-size:19px;line-height:1;color:var(--text);}}\n",
    "          .stat .label{{font-size:11px;text-transform:uppercase;font-weight:600;\n",
    "                       letter-spacing:.4px;color:var(--text);}}\n",
    "          .bar {{display:flex;height:10px;border-radius:4px;overflow:hidden;margin-top:4px;}}\n",
    "          .seg {{flex-shrink:0;transition:opacity .2s;}} .seg:hover {{opacity:.75;}}\n",
    "          .neg{{background:var(--neg);}} .pos{{background:var(--pos);}} .neu{{background:var(--neu);}}\n",
    "\n",
    "/* main */\n",
    "          .main {{padding:18px;line-height:1.6;}}\n",
    "          .summary {{\n",
    "              background:rgba(0,102,177,.07);border-left:3px solid var(--blue);\n",
    "              padding:10px;margin-bottom:16px;line-height:1.6;\n",
    "          }}\n",
    "          .cols {{display:flex;flex-wrap:wrap;gap:24px;margin-bottom:16px;}}\n",
    "          h4 {{margin:0 0 6px;color:var(--blue);font-weight:600;}}\n",
    "          ul {{margin:0;padding-left:18px;}}\n",
    "          li {{margin:4px 0;}}\n",
    "\n",
    "/* chips */\n",
    "          .chips {{margin-bottom:10px;}}\n",
    "          .chip {{\n",
    "              display:inline-block;padding:4px 10px;border-radius:20px;\n",
    "              font-size:11px;font-weight:700;margin:2px;cursor:pointer;\n",
    "              transition:opacity .2s;\n",
    "          }}\n",
    "          .chip:hover {{opacity:.8;}}\n",
    "          .kw{{background:#e3f2fd;color:var(--blue);}}\n",
    "          .ph{{background:#e8f5e9;color:#2e7d32;border:1px solid #c8e6c9;}}\n",
    "\n",
    "/* responsive */\n",
    "          @media (max-width:768px){{\n",
    "              .card{{grid-template-columns:1fr}}\n",
    "              .side{{order:2;border:none;border-top:1px solid #ddd;\n",
    "                    flex-direction:row;justify-content:space-around}}\n",
    "          }}\n",
    "        </style>\n",
    "        \"\"\"\n",
    "    ).format(blue=BMW_BLUE)\n",
    "\n",
    "    output: List[str] = [css, \"<div class='cards'>\"]\n",
    "\n",
    "    # sort by review count\n",
    "    for topic, info in sorted(data.items(), key=lambda x: x[1].review_count, reverse=True):\n",
    "        if topic.lower() == \"other\":\n",
    "            continue\n",
    "\n",
    "        bar = \"\".join(_bar_seg(name, frac) for name, frac in info.sentiment_dist.items())\n",
    "        kw_html = \"\".join(f\"<span class='chip kw'>{html.escape(k)}</span>\" for k in info.top_keywords)\n",
    "        ph_html = \"\".join(f\"<span class='chip ph'>{html.escape(p)}</span>\" for p in info.top_phrases)\n",
    "        issues_html = \"\".join(f\"<li>{html.escape(i)}</li>\" for i in info.issues) or \"<li>No major issues</li>\"\n",
    "        pos_html = \"\".join(f\"<li>{html.escape(p)}</li>\" for p in info.positives) or \"<li>No specific positives</li>\"\n",
    "\n",
    "        output.append(\n",
    "            f\"<div class='card'>\"\n",
    "            f\"<header>{html.escape(topic)}</header>\"\n",
    "\n",
    "            f\"<section class='side'>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.review_count}</span><span class='label'>Reviews</span></div>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.avg_rating:.2f}/5 {info.stars}</span>\"\n",
    "            f\"<span class='label'>Average</span></div>\"\n",
    "            f\"<div class='stat'><span class='label'>Sentiment</span><div class='bar'>{bar}</div></div>\"\n",
    "            \"</section>\"\n",
    "\n",
    "            \"<section class='main'>\"\n",
    "            f\"<p class='summary'>{html.escape(info.summary)}</p>\"\n",
    "            \"<div class='cols'>\"\n",
    "            f\"<div><h4>Issues</h4><ul>{issues_html}</ul></div>\"\n",
    "            f\"<div><h4>Positives</h4><ul>{pos_html}</ul></div>\"\n",
    "            \"</div>\"\n",
    "            f\"<div class='chips'><h4>Keywords</h4>{kw_html}</div>\"\n",
    "            f\"<div class='chips'><h4>Phrases</h4>{ph_html}</div>\"\n",
    "            \"</section>\"\n",
    "            \"</div>\"\n",
    "        )\n",
    "\n",
    "    output.append(\"</div>\")\n",
    "    display(HTML(\"\\n\".join(output)))\n",
    "\n",
    "def _bar_seg(name: str, frac: float) -> str:\n",
    "    cls = \"pos\" if name == \"positive\" else \"neg\" if name == \"negative\" else \"neu\"\n",
    "    pct = max(frac * 100, 1)\n",
    "    return f\"<span class='seg {cls}' style='width:{pct}%' title='{name}: {frac:.1%}'></span>\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – MATPLOTLIB CHART\n",
    "# -------------------------------------------------------------------\n",
    "def _plot_chart(data: Dict[str, TopicSummary], df: pd.DataFrame) -> None:\n",
    "    rows = [(t, d.avg_rating, d.review_count) for t, d in data.items() if t.lower() != \"other\"]\n",
    "    if not rows:\n",
    "        return\n",
    "    topics, ratings, counts = zip(*rows)\n",
    "    order = sorted(range(len(topics)), key=lambda i: ratings[i])\n",
    "    topics = [topics[i] for i in order]\n",
    "    ratings = [ratings[i] for i in order]\n",
    "    counts = [counts[i] for i in order]\n",
    "\n",
    "    cmap = mpl.colormaps.get_cmap(\"viridis\").resampled(len(topics))\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    bars = plt.barh(topics, ratings, color=[cmap(i) for i in range(len(topics))])\n",
    "\n",
    "    for bar, cnt, rating in zip(bars, counts, ratings):\n",
    "        x = rating + 0.05 if rating < 2.5 else rating - 0.6\n",
    "        clr = \"black\" if rating < 2.5 else \"white\"\n",
    "        plt.text(x, bar.get_y() + bar.get_height() / 2, f\"n={cnt}\", va=\"center\",\n",
    "                 color=clr, fontweight=\"bold\")\n",
    "\n",
    "    mean = df[\"score\"].mean()\n",
    "    plt.axvline(mean, linestyle=\"--\", linewidth=2, label=f\"Overall {mean:.2f}\")\n",
    "    plt.xticks(range(1, 6), [\"★\" * i for i in range(1, 6)])\n",
    "    plt.xlim(0, 5.2)\n",
    "    plt.xlabel(\"Star Rating\")\n",
    "    plt.ylabel(\"Topic\")\n",
    "    plt.title(\"BMW App – Average Rating by Topic\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MISC HELPERS\n",
    "# -------------------------------------------------------------------\n",
    "def _setup_logger() -> logging.Logger:\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "    return logging.getLogger(\"bmw_topic_cards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmw_topic_cards.py  –  v6  (2025‑05‑02)\n",
    "# ================================================================\n",
    "# • Stratified random sampling (mirrors topic sentiment mix)\n",
    "# • One paragraph summary  +  “‑ ” negative bullets  +  “+ ” positive bullets\n",
    "# • Prompts stored inside TopicSummary.prompts  (audit / debugging)\n",
    "# • No JSON parsing, so Ollama chatter can’t break the pipeline\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import html\n",
    "import logging\n",
    "import subprocess\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  CONFIGURATION\n",
    "# -------------------------------------------------------------------\n",
    "TOP_N_TOPICS        = 15          # how many topics to visualise\n",
    "PROMPT_SAMPLE_SIZE  = 300         # reviews fed to each LLM prompt\n",
    "N_KEYWORDS          = 8\n",
    "N_PHRASES           = 5\n",
    "MAX_BULLETS         = 7           # issues / positives\n",
    "BMW_BLUE            = \"#0066B1\"\n",
    "\n",
    "STAR_SVG = (\n",
    "    \"<svg width='14' height='14' viewBox='0 0 24 24' \"\n",
    "    \"xmlns='http://www.w3.org/2000/svg' style='vertical-align:-2px'>\"\n",
    "    \"<polygon fill='#FFD700' \"\n",
    "    \"points='12 2 15.09 8.26 22 9.27 17 14.14 \"\n",
    "    \"18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26'/></svg>\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  NLTK – bootstrap stop‑words\n",
    "# -------------------------------------------------------------------\n",
    "for res in (\"stopwords\", \"punkt\"):\n",
    "    try:\n",
    "        nltk.data.find(f\"corpora/{res}\")\n",
    "    except LookupError:\n",
    "        nltk.download(res, quiet=True)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\")) | {\n",
    "    \"bmw\", \"app\", \"car\", \"please\", \"would\", \"also\", \"get\", \"use\", \"using\"\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  OLLAMA RUNNER  (temperature 0 for determinism)\n",
    "# -------------------------------------------------------------------\n",
    "def _subprocess_runner(prompt: str, model: str) -> str:\n",
    "    proc = subprocess.run(\n",
    "        [\"ollama\", \"run\", model, \"-t\", \"0\"],\n",
    "        input=prompt,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        check=False,\n",
    "    )\n",
    "    return proc.stdout\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  STRATIFIED SAMPLING  (mirror sentiment mix)\n",
    "# -------------------------------------------------------------------\n",
    "def _stratified_sample(df: pd.DataFrame, size: int, seed: int = 0) -> List[str]:\n",
    "    dist = df[\"sentiment\"].value_counts(normalize=True)\n",
    "    quota = {s: int(round(dist.get(s, 0) * size)) for s in (\"negative\", \"positive\", \"neutral\")}\n",
    "    diff = size - sum(quota.values())\n",
    "    if diff:\n",
    "        quota[max(dist, key=dist.get, default=\"negative\")] += diff\n",
    "\n",
    "    col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "    texts: List[str] = []\n",
    "\n",
    "    for sentiment, n in quota.items():\n",
    "        if n <= 0:\n",
    "            continue\n",
    "        bucket = df[df[\"sentiment\"] == sentiment]\n",
    "        sample_n = min(n, len(bucket))\n",
    "        texts.extend(bucket.sample(sample_n, random_state=seed)[col].tolist())\n",
    "\n",
    "    # top‑up if any bucket ran short\n",
    "    if len(texts) < size:\n",
    "        short = size - len(texts)\n",
    "        remainder = df.drop(df.index[df[col].isin(texts)]).sample(short, random_state=seed)\n",
    "        texts.extend(remainder[col].tolist())\n",
    "\n",
    "    return texts\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  BULLET‑PARSER\n",
    "# -------------------------------------------------------------------\n",
    "def _parse_bullets(text: str, prefix: str) -> List[str]:\n",
    "    \"\"\"Return list of lines starting with the prefix (‘- ’ or ‘+ ’).\"\"\"\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    bullets = [ln[len(prefix):].strip() for ln in lines if ln.startswith(prefix)]\n",
    "    # fallback to comma‑sep if model ignored prefixes\n",
    "    if not bullets and \",\" in text:\n",
    "        bullets = [part.strip() for part in text.split(\",\") if part.strip()]\n",
    "    return bullets[:MAX_BULLETS]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  DATACLASS\n",
    "# -------------------------------------------------------------------\n",
    "@dataclass\n",
    "class TopicSummary:\n",
    "    summary: str\n",
    "    issues: List[str]\n",
    "    positives: List[str]\n",
    "    avg_rating: float\n",
    "    review_count: int\n",
    "    sentiment_dist: Dict[str, float]\n",
    "    top_keywords: List[str]\n",
    "    top_phrases: List[str]\n",
    "    prompts: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "    @property\n",
    "    def stars(self) -> str:\n",
    "        full, half = int(self.avg_rating), self.avg_rating - int(self.avg_rating) >= 0.5\n",
    "        return STAR_SVG * full + (STAR_SVG if half else \"\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MAIN ENTRY\n",
    "# -------------------------------------------------------------------\n",
    "def create_topic_cards_from_classified(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    ollama_model_name: str = \"gemma3:12b\",\n",
    "    ollama_runner: Callable[[str, str], str] = _subprocess_runner,\n",
    ") -> Dict[str, TopicSummary]:\n",
    "    \"\"\"\n",
    "    Render topic cards & a rating chart; return dict[topic] -> TopicSummary.\n",
    "    Prompts are stored in `TopicSummary.prompts`.\n",
    "    \"\"\"\n",
    "    log = _setup_logger()\n",
    "\n",
    "    # -------- sanity checks -----------------------------------------\n",
    "    if {\"topics\", \"sentiment\"} - set(df.columns):\n",
    "        raise ValueError(\"DataFrame must include 'topics' & 'sentiment'.\")\n",
    "\n",
    "    text_col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "\n",
    "    if \"score\" not in df.columns:\n",
    "        df[\"score\"] = (\n",
    "            df[\"sentiment\"]\n",
    "            .map({\"positive\": 4.5, \"neutral\": 3.0, \"negative\": 1.5})\n",
    "            .fillna(3.0)\n",
    "        )\n",
    "\n",
    "    # -------- pick top topics --------------------------------------\n",
    "    topics_freq = df[\"topics\"].str.get_dummies(sep=\",\").sum()\n",
    "    top_topics = (\n",
    "        topics_freq.sort_values(ascending=False).head(TOP_N_TOPICS).index\n",
    "    )\n",
    "\n",
    "    results: Dict[str, TopicSummary] = {}\n",
    "\n",
    "    for topic in tqdm(top_topics, desc=\"Topics\"):\n",
    "        sub = df[df[\"topics\"].str.contains(fr\"\\b{topic}\\b\", case=False, na=False)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        avg = sub[\"score\"].mean()\n",
    "        mix = sub[\"sentiment\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "        tokens = word_tokenize(\" \".join(sub[text_col].fillna(\"\").str.lower()))\n",
    "        tokens = [t for t in tokens if t.isalpha() and t not in STOPWORDS and len(t) > 2]\n",
    "        keywords = [w for w, _ in Counter(tokens).most_common(N_KEYWORDS)]\n",
    "        bigrams = [f\"{a} {b}\" for a, b in zip(tokens, tokens[1:])]\n",
    "        phrases = [p for p, _ in Counter(bigrams).most_common(N_PHRASES)]\n",
    "\n",
    "        sample_n = min(PROMPT_SAMPLE_SIZE, len(sub))\n",
    "        sample_texts = _stratified_sample(sub, sample_n)\n",
    "        sample_blob = \"\\n\".join(f\"[{i}] {txt}\" for i, txt in enumerate(sample_texts))\n",
    "\n",
    "        ctx_block = (\n",
    "            f\"Average score {avg:.2f} (n={len(sub)}). \"\n",
    "            f\"Sentiment mix: neg {mix.get('negative',0):.0%}, \"\n",
    "            f\"pos {mix.get('positive',0):.0%}, \"\n",
    "            f\"neu {mix.get('neutral',0):.0%}.\\n\"\n",
    "            f\"Top keywords: {', '.join(keywords)}.\\n\"\n",
    "            f\"Top phrases: {', '.join(phrases)}.\"\n",
    "        )\n",
    "\n",
    "        prompts: Dict[str, str] = {}\n",
    "\n",
    "        def build(kind: str) -> str:\n",
    "            \"\"\"Return fully‑formed prompt & store it\"\"\"\n",
    "            header = (\n",
    "                \"You are an analytical assistant. Follow ALL rules:\\n\"\n",
    "                f\"• Focus **only** on the topic '{topic}'.\\n\"\n",
    "                \"• Ignore unrelated features.\\n\"\n",
    "                \"• Use English even if reviews were translated.\\n\"\n",
    "                \"• Be factual, concise (temperature 0).\\n\"\n",
    "            )\n",
    "            if kind == \"summary\":\n",
    "                body = (\n",
    "                    \"Write one concise paragraph (3‑5 sentences) that \"\n",
    "                    \"summarises what users say about this topic, covering \"\n",
    "                    \"both pain points and praise.\"\n",
    "                )\n",
    "            else:\n",
    "                label = \"negative issues\" if kind == \"issues\" else \"positive aspects\"\n",
    "                prefix = \"-\" if kind == \"issues\" else \"+\"\n",
    "                body = (\n",
    "                    f\"List up to {MAX_BULLETS} main {label}. \"\n",
    "                    f\"Each line MUST start with '{prefix} '. \"\n",
    "                    \"Use short noun phrases, no duplication, no periods.\"\n",
    "                )\n",
    "\n",
    "            prompt = (\n",
    "                f\"{header}\\n\\nCONTEXT:\\n{ctx_block}\\n\\nSAMPLES:\\n{sample_blob}\\n\\nTASK:\\n{body}\"\n",
    "            )\n",
    "            prompts[kind] = prompt\n",
    "            return prompt\n",
    "\n",
    "        # ----- call Ollama (three prompts in parallel) ----------------\n",
    "        with ThreadPoolExecutor(max_workers=3) as pool:\n",
    "            futures = {\n",
    "                pool.submit(ollama_runner, build(k), ollama_model_name): k\n",
    "                for k in (\"summary\", \"issues\", \"positives\")\n",
    "            }\n",
    "            raw = {k: f.result().strip() for f, k in futures.items()}\n",
    "\n",
    "        summary_text = raw[\"summary\"]\n",
    "        issues_list  = _parse_bullets(raw[\"issues\"], \"-\")\n",
    "        pos_list     = _parse_bullets(raw[\"positives\"], \"+\")\n",
    "\n",
    "        results[topic] = TopicSummary(\n",
    "            summary=summary_text,\n",
    "            issues=issues_list,\n",
    "            positives=pos_list,\n",
    "            avg_rating=avg,\n",
    "            review_count=len(sub),\n",
    "            sentiment_dist=mix,\n",
    "            top_keywords=keywords,\n",
    "            top_phrases=phrases,\n",
    "            prompts=prompts,\n",
    "        )\n",
    "\n",
    "    # ------------- render & plot -------------------------------------\n",
    "    _render_cards(results)\n",
    "    _plot_chart(results, df)\n",
    "    return {k: v.__dict__ for k, v in results.items()}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – HTML CARDS\n",
    "# -------------------------------------------------------------------\n",
    "def _render_cards(data: Dict[str, TopicSummary]) -> None:\n",
    "    css = textwrap.dedent(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "          :root {{--blue:{blue};--neg:#E53935;--pos:#43A047;--neu:#FFA000;\n",
    "                 --bg:#fff;--text:#1a1a1a;}}\n",
    "          @media (prefers-color-scheme: dark) {{\n",
    "              :root {{--bg:#121212;--text:#e0e0e0;}}\n",
    "          }}\n",
    "          body {{background:var(--bg);color:var(--text);}}\n",
    "\n",
    "/* container */\n",
    "          .cards {{max-width:1200px;margin:0 auto;font-family:'Helvetica Neue',Arial,sans-serif;}}\n",
    "\n",
    "/* card */\n",
    "          .card {{\n",
    "              display:grid;grid-template-columns:220px 1fr;\n",
    "              border:1px solid #bbb;border-radius:8px;margin:18px 0;\n",
    "              overflow:hidden;box-shadow:0 4px 10px rgba(0,0,0,.12);\n",
    "              animation:fadeIn .4s ease;\n",
    "          }}\n",
    "          @keyframes fadeIn {{from {{opacity:0;transform:translateY(8px);}}\n",
    "                              to   {{opacity:1;transform:translateY(0);}}}}\n",
    "          header {{\n",
    "              grid-column:1/-1;background:linear-gradient(135deg,var(--blue) 0%,#0088cc 100%);\n",
    "              color:#fff;padding:12px 18px;font-size:20px;font-weight:600;\n",
    "          }}\n",
    "\n",
    "/* sidebar */\n",
    "          .side {{\n",
    "              background:#f5f7fa;border-right:1px solid #ddd;\n",
    "              padding:14px;display:flex;flex-direction:column;gap:14px;\n",
    "          }}\n",
    "          .stat .num {{font-weight:700;font-size:19px;line-height:1;color:var(--text);}}\n",
    "          .stat .label{{font-size:11px;text-transform:uppercase;font-weight:600;\n",
    "                       letter-spacing:.4px;color:var(--text);}}\n",
    "          .bar {{display:flex;height:10px;border-radius:4px;overflow:hidden;margin-top:4px;}}\n",
    "          .seg {{flex-shrink:0;transition:opacity .2s;}} .seg:hover {{opacity:.75;}}\n",
    "          .neg{{background:var(--neg);}} .pos{{background:var(--pos);}} .neu{{background:var(--neu);}}\n",
    "\n",
    "/* main */\n",
    "          .main {{padding:18px;line-height:1.6;}}\n",
    "          .summary {{\n",
    "              background:rgba(0,102,177,.07);border-left:3px solid var(--blue);\n",
    "              padding:10px;margin-bottom:16px;line-height:1.6;\n",
    "          }}\n",
    "          .cols {{display:flex;flex-wrap:wrap;gap:24px;margin-bottom:16px;}}\n",
    "          h4 {{margin:0 0 6px;color:var(--blue);font-weight:600;}}\n",
    "          ul {{margin:0;padding-left:18px;}}\n",
    "          li {{margin:4px 0;}}\n",
    "\n",
    "/* chips */\n",
    "          .chips {{margin-bottom:10px;}}\n",
    "          .chip {{\n",
    "              display:inline-block;padding:4px 10px;border-radius:20px;\n",
    "              font-size:11px;font-weight:700;margin:2px;cursor:pointer;\n",
    "              transition:opacity .2s;\n",
    "          }}\n",
    "          .chip:hover {{opacity:.8;}}\n",
    "          .kw{{background:#e3f2fd;color:var(--blue);}}\n",
    "          .ph{{background:#e8f5e9;color:#2e7d32;border:1px solid #c8e6c9;}}\n",
    "\n",
    "/* responsive */\n",
    "          @media (max-width:768px){{\n",
    "              .card{{grid-template-columns:1fr}}\n",
    "              .side{{order:2;border:none;border-top:1px solid #ddd;\n",
    "                    flex-direction:row;justify-content:space-around}}\n",
    "          }}\n",
    "        </style>\n",
    "        \"\"\"\n",
    "    ).format(blue=BMW_BLUE)\n",
    "\n",
    "    output: List[str] = [css, \"<div class='cards'>\"]\n",
    "\n",
    "    # sort by review count\n",
    "    for topic, info in sorted(data.items(), key=lambda x: x[1].review_count, reverse=True):\n",
    "        if topic.lower() == \"other\":\n",
    "            continue\n",
    "\n",
    "        bar = \"\".join(_bar_seg(name, frac) for name, frac in info.sentiment_dist.items())\n",
    "        kw_html = \"\".join(f\"<span class='chip kw'>{html.escape(k)}</span>\" for k in info.top_keywords)\n",
    "        ph_html = \"\".join(f\"<span class='chip ph'>{html.escape(p)}</span>\" for p in info.top_phrases)\n",
    "        issues_html = \"\".join(f\"<li>{html.escape(i)}</li>\" for i in info.issues) or \"<li>No major issues</li>\"\n",
    "        pos_html = \"\".join(f\"<li>{html.escape(p)}</li>\" for p in info.positives) or \"<li>No specific positives</li>\"\n",
    "\n",
    "        output.append(\n",
    "            f\"<div class='card'>\"\n",
    "            f\"<header>{html.escape(topic)}</header>\"\n",
    "\n",
    "            f\"<section class='side'>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.review_count}</span><span class='label'>Reviews</span></div>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.avg_rating:.2f}/5 {info.stars}</span>\"\n",
    "            f\"<span class='label'>Average</span></div>\"\n",
    "            f\"<div class='stat'><span class='label'>Sentiment</span><div class='bar'>{bar}</div></div>\"\n",
    "            \"</section>\"\n",
    "\n",
    "            \"<section class='main'>\"\n",
    "            f\"<p class='summary'>{html.escape(info.summary)}</p>\"\n",
    "            \"<div class='cols'>\"\n",
    "            f\"<div><h4>Issues</h4><ul>{issues_html}</ul></div>\"\n",
    "            f\"<div><h4>Positives</h4><ul>{pos_html}</ul></div>\"\n",
    "            \"</div>\"\n",
    "            f\"<div class='chips'><h4>Keywords</h4>{kw_html}</div>\"\n",
    "            f\"<div class='chips'><h4>Phrases</h4>{ph_html}</div>\"\n",
    "            \"</section>\"\n",
    "            \"</div>\"\n",
    "        )\n",
    "\n",
    "    output.append(\"</div>\")\n",
    "    display(HTML(\"\\n\".join(output)))\n",
    "\n",
    "def _bar_seg(name: str, frac: float) -> str:\n",
    "    cls = \"pos\" if name == \"positive\" else \"neg\" if name == \"negative\" else \"neu\"\n",
    "    pct = max(frac * 100, 1)\n",
    "    return f\"<span class='seg {cls}' style='width:{pct}%' title='{name}: {frac:.1%}'></span>\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – MATPLOTLIB CHART\n",
    "# -------------------------------------------------------------------\n",
    "def _plot_chart(data: Dict[str, TopicSummary], df: pd.DataFrame) -> None:\n",
    "    rows = [(t, d.avg_rating, d.review_count) for t, d in data.items() if t.lower() != \"other\"]\n",
    "    if not rows:\n",
    "        return\n",
    "    topics, ratings, counts = zip(*rows)\n",
    "    order = sorted(range(len(topics)), key=lambda i: ratings[i])\n",
    "    topics = [topics[i] for i in order]\n",
    "    ratings = [ratings[i] for i in order]\n",
    "    counts = [counts[i] for i in order]\n",
    "\n",
    "    cmap = mpl.colormaps.get_cmap(\"viridis\").resampled(len(topics))\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    bars = plt.barh(topics, ratings, color=[cmap(i) for i in range(len(topics))])\n",
    "\n",
    "    for bar, cnt, rating in zip(bars, counts, ratings):\n",
    "        x = rating + 0.05 if rating < 2.5 else rating - 0.6\n",
    "        clr = \"black\" if rating < 2.5 else \"white\"\n",
    "        plt.text(x, bar.get_y() + bar.get_height() / 2, f\"n={cnt}\", va=\"center\",\n",
    "                 color=clr, fontweight=\"bold\")\n",
    "\n",
    "    mean = df[\"score\"].mean()\n",
    "    plt.axvline(mean, linestyle=\"--\", linewidth=2, label=f\"Overall {mean:.2f}\")\n",
    "    plt.xticks(range(1, 6), [\"★\" * i for i in range(1, 6)])\n",
    "    plt.xlim(0, 5.2)\n",
    "    plt.xlabel(\"Star Rating\")\n",
    "    plt.ylabel(\"Topic\")\n",
    "    plt.title(\"BMW App – Average Rating by Topic\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MISC HELPERS\n",
    "# -------------------------------------------------------------------\n",
    "def _setup_logger() -> logging.Logger:\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "    return logging.getLogger(\"bmw_topic_cards\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
