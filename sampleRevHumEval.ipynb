{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bmw_app_analysis/results/bmw_reviews_consolidated_20250504_155236.csv...\n",
      "Filtering reviews with at least 5 words...\n",
      "Reviews with 5+ words: 13312 out of 18350\n",
      "\n",
      "Reviews available after filtering by language and length:\n",
      "  German: 3839 reviews\n",
      "  Italian: 920 reviews\n",
      "  Spanish: 670 reviews\n",
      "  French: 1155 reviews\n",
      "Sampled 30 reviews from German\n",
      "Sampled 30 reviews from Italian\n",
      "Sampled 30 reviews from Spanish\n",
      "Sampled 30 reviews from French\n",
      "Saved sampled reviews to bmw_app_analysis/results/bmw_reviews_sampledHE.csv\n",
      "\n",
      "Final sample distribution:\n",
      "  German: 30 reviews\n",
      "  Italian: 30 reviews\n",
      "  Spanish: 30 reviews\n",
      "  French: 30 reviews\n",
      "\n",
      "Example reviews from each language:\n",
      "\n",
      "German example:\n",
      "  Original: Die App kann schon viel, aber warum lassen sich di...\n",
      "  English:  The app can already do a lot, but why can't the wi...\n",
      "\n",
      "Italian example:\n",
      "  Original: Dalla versione 2.11.0, con IDrive 6 e telefono And...\n",
      "  English:  Since version 2.11.0, with iDrive 6 and an Android...\n",
      "\n",
      "Spanish example:\n",
      "  Original: Aplicación penosa, en esta nueva actualización se ...\n",
      "  English:  Miserable app, with this new update they’ve even l...\n",
      "\n",
      "French example:\n",
      "  Original: Application très conviviale et informative ... C'e...\n",
      "  English:  Very user-friendly and informative application... ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def sample_reviews_by_language(input_file='bmw_app_analysis/results/bmw_reviews_consolidated_20250504_155236.csv', \n",
    "                              output_file='bmw_app_analysis/results/bmw_reviews_sampledHE.csv'):\n",
    "    \"\"\"\n",
    "    Sample 30 reviews EACH from German, Italian, Spanish and French languages\n",
    "    with at least 5 words from the BMW reviews dataset.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to the input CSV file\n",
    "        output_file: Path to save the sampled reviews\n",
    "    \"\"\"\n",
    "    # Read the consolidated file\n",
    "    print(f\"Reading {input_file}...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Verify columns exist\n",
    "    required_columns = ['reviewId', 'content', 'language', 'content_english']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"ERROR: Missing required columns: {missing_columns}\")\n",
    "        print(f\"Available columns: {df.columns.tolist()}\")\n",
    "        return None\n",
    "    \n",
    "    # Apply minimum word filter - INCREASED TO 5 WORDS\n",
    "    min_words = 5  # Changed from 3 to 5\n",
    "    print(f\"Filtering reviews with at least {min_words} words...\")\n",
    "    df['word_count'] = df['content'].apply(lambda x: len(re.findall(r'\\b\\w+\\b', str(x))) if isinstance(x, str) else 0)\n",
    "    df_filtered_by_length = df[df['word_count'] >= min_words].copy()\n",
    "    \n",
    "    print(f\"Reviews with {min_words}+ words: {len(df_filtered_by_length)} out of {len(df)}\")\n",
    "    \n",
    "    # Target languages - in desired order\n",
    "    target_languages = [\"German\", \"Italian\", \"Spanish\", \"French\"]\n",
    "    \n",
    "    # Apply language filter\n",
    "    df_filtered = df_filtered_by_length[df_filtered_by_length['language'].isin(target_languages)].copy()\n",
    "    \n",
    "    # Report on available reviews per language\n",
    "    print(\"\\nReviews available after filtering by language and length:\")\n",
    "    for lang in target_languages:\n",
    "        count = len(df_filtered[df_filtered['language'] == lang])\n",
    "        print(f\"  {lang}: {count} reviews\")\n",
    "    \n",
    "    # Sample 30 from each language group (or all available if less than 30)\n",
    "    sampled_reviews = []\n",
    "    target_per_language = 30  # 30 reviews per language\n",
    "    \n",
    "    for lang in target_languages:\n",
    "        lang_df = df_filtered[df_filtered['language'] == lang]\n",
    "        \n",
    "        if len(lang_df) == 0:\n",
    "            print(f\"No reviews found for {lang}\")\n",
    "            continue\n",
    "            \n",
    "        # Sample up to target_per_language reviews, or all if fewer available\n",
    "        sample_size = min(target_per_language, len(lang_df))\n",
    "        sampled = lang_df.sample(sample_size, random_state=42)\n",
    "        sampled_reviews.append(sampled)\n",
    "        print(f\"Sampled {len(sampled)} reviews from {lang}\")\n",
    "    \n",
    "    # Combine all samples\n",
    "    sampled_df = pd.concat(sampled_reviews, ignore_index=True)\n",
    "    \n",
    "    # Create language order mapping for sorting\n",
    "    lang_order = {lang: i for i, lang in enumerate(target_languages)}\n",
    "    \n",
    "    # Select only the required columns and rename content_english to english_content\n",
    "    output_df = sampled_df[['reviewId', 'content', 'language', 'content_english']].copy()\n",
    "    \n",
    "    # Clean up english_content: remove quotes\n",
    "    output_df['content_english'] = output_df['content_english'].astype(str).str.replace('\"', '')\n",
    "    \n",
    "    # Rename the column\n",
    "    output_df = output_df.rename(columns={'content_english': 'english_content'})\n",
    "    \n",
    "    # Sort by language in the specified order\n",
    "    output_df['lang_order'] = output_df['language'].map(lang_order)\n",
    "    output_df = output_df.sort_values('lang_order').drop('lang_order', axis=1).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved sampled reviews to {output_file}\")\n",
    "    \n",
    "    print(\"\\nFinal sample distribution:\")\n",
    "    for lang in target_languages:\n",
    "        count = len(output_df[output_df['language'] == lang])\n",
    "        print(f\"  {lang}: {count} reviews\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# Execute the function\n",
    "if __name__ == \"__main__\":\n",
    "    sampled_reviews = sample_reviews_by_language()\n",
    "    \n",
    "    # Display summary\n",
    "    if sampled_reviews is not None and not sampled_reviews.empty:\n",
    "        # Show a couple examples from each language\n",
    "        print(\"\\nExample reviews from each language:\")\n",
    "        for lang in [\"German\", \"Italian\", \"Spanish\", \"French\"]:\n",
    "            lang_samples = sampled_reviews[sampled_reviews['language'] == lang].head(1)\n",
    "            if not lang_samples.empty:\n",
    "                print(f\"\\n{lang} example:\")\n",
    "                for _, row in lang_samples.iterrows():\n",
    "                    print(f\"  Original: {row['content'][:50]}{'...' if len(row['content']) > 50 else ''}\")\n",
    "                    print(f\"  English:  {row['english_content'][:50]}{'...' if len(row['english_content']) > 50 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmw_topic_cards.py  –  v6  (2025‑05‑02)\n",
    "# ================================================================\n",
    "# • Stratified random sampling (mirrors topic sentiment mix)\n",
    "# • One paragraph summary  +  “‑ ” negative bullets  +  “+ ” positive bullets\n",
    "# • Prompts stored inside TopicSummary.prompts  (audit / debugging)\n",
    "# • No JSON parsing, so Ollama chatter can’t break the pipeline\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import html\n",
    "import logging\n",
    "import subprocess\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  CONFIGURATION\n",
    "# -------------------------------------------------------------------\n",
    "TOP_N_TOPICS        = 15          # how many topics to visualise\n",
    "PROMPT_SAMPLE_SIZE  = 300         # reviews fed to each LLM prompt\n",
    "N_KEYWORDS          = 8\n",
    "N_PHRASES           = 5\n",
    "MAX_BULLETS         = 7           # issues / positives\n",
    "BMW_BLUE            = \"#0066B1\"\n",
    "\n",
    "STAR_SVG = (\n",
    "    \"<svg width='14' height='14' viewBox='0 0 24 24' \"\n",
    "    \"xmlns='http://www.w3.org/2000/svg' style='vertical-align:-2px'>\"\n",
    "    \"<polygon fill='#FFD700' \"\n",
    "    \"points='12 2 15.09 8.26 22 9.27 17 14.14 \"\n",
    "    \"18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26'/></svg>\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  NLTK – bootstrap stop‑words\n",
    "# -------------------------------------------------------------------\n",
    "for res in (\"stopwords\", \"punkt\"):\n",
    "    try:\n",
    "        nltk.data.find(f\"corpora/{res}\")\n",
    "    except LookupError:\n",
    "        nltk.download(res, quiet=True)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\")) | {\n",
    "    \"bmw\", \"app\", \"car\", \"please\", \"would\", \"also\", \"get\", \"use\", \"using\"\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  OLLAMA RUNNER  (temperature 0 for determinism)\n",
    "# -------------------------------------------------------------------\n",
    "def _subprocess_runner(prompt: str, model: str) -> str:\n",
    "    proc = subprocess.run(\n",
    "        [\"ollama\", \"run\", model, \"-t\", \"0\"],\n",
    "        input=prompt,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        check=False,\n",
    "    )\n",
    "    return proc.stdout\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  STRATIFIED SAMPLING  (mirror sentiment mix)\n",
    "# -------------------------------------------------------------------\n",
    "def _stratified_sample(df: pd.DataFrame, size: int, seed: int = 0) -> List[str]:\n",
    "    dist = df[\"sentiment\"].value_counts(normalize=True)\n",
    "    quota = {s: int(round(dist.get(s, 0) * size)) for s in (\"negative\", \"positive\", \"neutral\")}\n",
    "    diff = size - sum(quota.values())\n",
    "    if diff:\n",
    "        quota[max(dist, key=dist.get, default=\"negative\")] += diff\n",
    "\n",
    "    col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "    texts: List[str] = []\n",
    "\n",
    "    for sentiment, n in quota.items():\n",
    "        if n <= 0:\n",
    "            continue\n",
    "        bucket = df[df[\"sentiment\"] == sentiment]\n",
    "        sample_n = min(n, len(bucket))\n",
    "        texts.extend(bucket.sample(sample_n, random_state=seed)[col].tolist())\n",
    "\n",
    "    # top‑up if any bucket ran short\n",
    "    if len(texts) < size:\n",
    "        short = size - len(texts)\n",
    "        remainder = df.drop(df.index[df[col].isin(texts)]).sample(short, random_state=seed)\n",
    "        texts.extend(remainder[col].tolist())\n",
    "\n",
    "    return texts\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  BULLET‑PARSER\n",
    "# -------------------------------------------------------------------\n",
    "def _parse_bullets(text: str, prefix: str) -> List[str]:\n",
    "    \"\"\"Return list of lines starting with the prefix (‘- ’ or ‘+ ’).\"\"\"\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    bullets = [ln[len(prefix):].strip() for ln in lines if ln.startswith(prefix)]\n",
    "    # fallback to comma‑sep if model ignored prefixes\n",
    "    if not bullets and \",\" in text:\n",
    "        bullets = [part.strip() for part in text.split(\",\") if part.strip()]\n",
    "    return bullets[:MAX_BULLETS]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  DATACLASS\n",
    "# -------------------------------------------------------------------\n",
    "@dataclass\n",
    "class TopicSummary:\n",
    "    summary: str\n",
    "    issues: List[str]\n",
    "    positives: List[str]\n",
    "    avg_rating: float\n",
    "    review_count: int\n",
    "    sentiment_dist: Dict[str, float]\n",
    "    top_keywords: List[str]\n",
    "    top_phrases: List[str]\n",
    "    prompts: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "    @property\n",
    "    def stars(self) -> str:\n",
    "        full, half = int(self.avg_rating), self.avg_rating - int(self.avg_rating) >= 0.5\n",
    "        return STAR_SVG * full + (STAR_SVG if half else \"\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MAIN ENTRY\n",
    "# -------------------------------------------------------------------\n",
    "def create_topic_cards_from_classified(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    ollama_model_name: str = \"gemma3:12b\",\n",
    "    ollama_runner: Callable[[str, str], str] = _subprocess_runner,\n",
    ") -> Dict[str, TopicSummary]:\n",
    "    \"\"\"\n",
    "    Render topic cards & a rating chart; return dict[topic] -> TopicSummary.\n",
    "    Prompts are stored in `TopicSummary.prompts`.\n",
    "    \"\"\"\n",
    "    log = _setup_logger()\n",
    "\n",
    "    # -------- sanity checks -----------------------------------------\n",
    "    if {\"topics\", \"sentiment\"} - set(df.columns):\n",
    "        raise ValueError(\"DataFrame must include 'topics' & 'sentiment'.\")\n",
    "\n",
    "    text_col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "\n",
    "    if \"score\" not in df.columns:\n",
    "        df[\"score\"] = (\n",
    "            df[\"sentiment\"]\n",
    "            .map({\"positive\": 4.5, \"neutral\": 3.0, \"negative\": 1.5})\n",
    "            .fillna(3.0)\n",
    "        )\n",
    "\n",
    "    # -------- pick top topics --------------------------------------\n",
    "    topics_freq = df[\"topics\"].str.get_dummies(sep=\",\").sum()\n",
    "    top_topics = (\n",
    "        topics_freq.sort_values(ascending=False).head(TOP_N_TOPICS).index\n",
    "    )\n",
    "\n",
    "    results: Dict[str, TopicSummary] = {}\n",
    "\n",
    "    for topic in tqdm(top_topics, desc=\"Topics\"):\n",
    "        sub = df[df[\"topics\"].str.contains(fr\"\\b{topic}\\b\", case=False, na=False)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        avg = sub[\"score\"].mean()\n",
    "        mix = sub[\"sentiment\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "        tokens = word_tokenize(\" \".join(sub[text_col].fillna(\"\").str.lower()))\n",
    "        tokens = [t for t in tokens if t.isalpha() and t not in STOPWORDS and len(t) > 2]\n",
    "        keywords = [w for w, _ in Counter(tokens).most_common(N_KEYWORDS)]\n",
    "        bigrams = [f\"{a} {b}\" for a, b in zip(tokens, tokens[1:])]\n",
    "        phrases = [p for p, _ in Counter(bigrams).most_common(N_PHRASES)]\n",
    "\n",
    "        sample_n = min(PROMPT_SAMPLE_SIZE, len(sub))\n",
    "        sample_texts = _stratified_sample(sub, sample_n)\n",
    "        sample_blob = \"\\n\".join(f\"[{i}] {txt}\" for i, txt in enumerate(sample_texts))\n",
    "\n",
    "        ctx_block = (\n",
    "            f\"Average score {avg:.2f} (n={len(sub)}). \"\n",
    "            f\"Sentiment mix: neg {mix.get('negative',0):.0%}, \"\n",
    "            f\"pos {mix.get('positive',0):.0%}, \"\n",
    "            f\"neu {mix.get('neutral',0):.0%}.\\n\"\n",
    "            f\"Top keywords: {', '.join(keywords)}.\\n\"\n",
    "            f\"Top phrases: {', '.join(phrases)}.\"\n",
    "        )\n",
    "\n",
    "        prompts: Dict[str, str] = {}\n",
    "\n",
    "        def build(kind: str) -> str:\n",
    "            \"\"\"Return fully‑formed prompt & store it\"\"\"\n",
    "            header = (\n",
    "                \"You are an analytical assistant. Follow ALL rules:\\n\"\n",
    "                f\"• Focus **only** on the topic '{topic}'.\\n\"\n",
    "                \"• Ignore unrelated features.\\n\"\n",
    "                \"• Use English even if reviews were translated.\\n\"\n",
    "                \"• Be factual, concise (temperature 0).\\n\"\n",
    "            )\n",
    "            if kind == \"summary\":\n",
    "                body = (\n",
    "                    \"Write one concise paragraph (3‑5 sentences) that \"\n",
    "                    \"summarises what users say about this topic, covering \"\n",
    "                    \"both pain points and praise.\"\n",
    "                )\n",
    "            else:\n",
    "                label = \"negative issues\" if kind == \"issues\" else \"positive aspects\"\n",
    "                prefix = \"-\" if kind == \"issues\" else \"+\"\n",
    "                body = (\n",
    "                    f\"List up to {MAX_BULLETS} main {label}. \"\n",
    "                    f\"Each line MUST start with '{prefix} '. \"\n",
    "                    \"Use short noun phrases, no duplication, no periods.\"\n",
    "                )\n",
    "\n",
    "            prompt = (\n",
    "                f\"{header}\\n\\nCONTEXT:\\n{ctx_block}\\n\\nSAMPLES:\\n{sample_blob}\\n\\nTASK:\\n{body}\"\n",
    "            )\n",
    "            prompts[kind] = prompt\n",
    "            return prompt\n",
    "\n",
    "        # ----- call Ollama (three prompts in parallel) ----------------\n",
    "        with ThreadPoolExecutor(max_workers=3) as pool:\n",
    "            futures = {\n",
    "                pool.submit(ollama_runner, build(k), ollama_model_name): k\n",
    "                for k in (\"summary\", \"issues\", \"positives\")\n",
    "            }\n",
    "            raw = {k: f.result().strip() for f, k in futures.items()}\n",
    "\n",
    "        summary_text = raw[\"summary\"]\n",
    "        issues_list  = _parse_bullets(raw[\"issues\"], \"-\")\n",
    "        pos_list     = _parse_bullets(raw[\"positives\"], \"+\")\n",
    "\n",
    "        results[topic] = TopicSummary(\n",
    "            summary=summary_text,\n",
    "            issues=issues_list,\n",
    "            positives=pos_list,\n",
    "            avg_rating=avg,\n",
    "            review_count=len(sub),\n",
    "            sentiment_dist=mix,\n",
    "            top_keywords=keywords,\n",
    "            top_phrases=phrases,\n",
    "            prompts=prompts,\n",
    "        )\n",
    "\n",
    "    # ------------- render & plot -------------------------------------\n",
    "    _render_cards(results)\n",
    "    _plot_chart(results, df)\n",
    "    return {k: v.__dict__ for k, v in results.items()}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – HTML CARDS\n",
    "# -------------------------------------------------------------------\n",
    "def _render_cards(data: Dict[str, TopicSummary]) -> None:\n",
    "    css = textwrap.dedent(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "          :root {{--blue:{blue};--neg:#E53935;--pos:#43A047;--neu:#FFA000;\n",
    "                 --bg:#fff;--text:#1a1a1a;}}\n",
    "          @media (prefers-color-scheme: dark) {{\n",
    "              :root {{--bg:#121212;--text:#e0e0e0;}}\n",
    "          }}\n",
    "          body {{background:var(--bg);color:var(--text);}}\n",
    "\n",
    "/* container */\n",
    "          .cards {{max-width:1200px;margin:0 auto;font-family:'Helvetica Neue',Arial,sans-serif;}}\n",
    "\n",
    "/* card */\n",
    "          .card {{\n",
    "              display:grid;grid-template-columns:220px 1fr;\n",
    "              border:1px solid #bbb;border-radius:8px;margin:18px 0;\n",
    "              overflow:hidden;box-shadow:0 4px 10px rgba(0,0,0,.12);\n",
    "              animation:fadeIn .4s ease;\n",
    "          }}\n",
    "          @keyframes fadeIn {{from {{opacity:0;transform:translateY(8px);}}\n",
    "                              to   {{opacity:1;transform:translateY(0);}}}}\n",
    "          header {{\n",
    "              grid-column:1/-1;background:linear-gradient(135deg,var(--blue) 0%,#0088cc 100%);\n",
    "              color:#fff;padding:12px 18px;font-size:20px;font-weight:600;\n",
    "          }}\n",
    "\n",
    "/* sidebar */\n",
    "          .side {{\n",
    "              background:#f5f7fa;border-right:1px solid #ddd;\n",
    "              padding:14px;display:flex;flex-direction:column;gap:14px;\n",
    "          }}\n",
    "          .stat .num {{font-weight:700;font-size:19px;line-height:1;color:var(--text);}}\n",
    "          .stat .label{{font-size:11px;text-transform:uppercase;font-weight:600;\n",
    "                       letter-spacing:.4px;color:var(--text);}}\n",
    "          .bar {{display:flex;height:10px;border-radius:4px;overflow:hidden;margin-top:4px;}}\n",
    "          .seg {{flex-shrink:0;transition:opacity .2s;}} .seg:hover {{opacity:.75;}}\n",
    "          .neg{{background:var(--neg);}} .pos{{background:var(--pos);}} .neu{{background:var(--neu);}}\n",
    "\n",
    "/* main */\n",
    "          .main {{padding:18px;line-height:1.6;}}\n",
    "          .summary {{\n",
    "              background:rgba(0,102,177,.07);border-left:3px solid var(--blue);\n",
    "              padding:10px;margin-bottom:16px;line-height:1.6;\n",
    "          }}\n",
    "          .cols {{display:flex;flex-wrap:wrap;gap:24px;margin-bottom:16px;}}\n",
    "          h4 {{margin:0 0 6px;color:var(--blue);font-weight:600;}}\n",
    "          ul {{margin:0;padding-left:18px;}}\n",
    "          li {{margin:4px 0;}}\n",
    "\n",
    "/* chips */\n",
    "          .chips {{margin-bottom:10px;}}\n",
    "          .chip {{\n",
    "              display:inline-block;padding:4px 10px;border-radius:20px;\n",
    "              font-size:11px;font-weight:700;margin:2px;cursor:pointer;\n",
    "              transition:opacity .2s;\n",
    "          }}\n",
    "          .chip:hover {{opacity:.8;}}\n",
    "          .kw{{background:#e3f2fd;color:var(--blue);}}\n",
    "          .ph{{background:#e8f5e9;color:#2e7d32;border:1px solid #c8e6c9;}}\n",
    "\n",
    "/* responsive */\n",
    "          @media (max-width:768px){{\n",
    "              .card{{grid-template-columns:1fr}}\n",
    "              .side{{order:2;border:none;border-top:1px solid #ddd;\n",
    "                    flex-direction:row;justify-content:space-around}}\n",
    "          }}\n",
    "        </style>\n",
    "        \"\"\"\n",
    "    ).format(blue=BMW_BLUE)\n",
    "\n",
    "    output: List[str] = [css, \"<div class='cards'>\"]\n",
    "\n",
    "    # sort by review count\n",
    "    for topic, info in sorted(data.items(), key=lambda x: x[1].review_count, reverse=True):\n",
    "        if topic.lower() == \"other\":\n",
    "            continue\n",
    "\n",
    "        bar = \"\".join(_bar_seg(name, frac) for name, frac in info.sentiment_dist.items())\n",
    "        kw_html = \"\".join(f\"<span class='chip kw'>{html.escape(k)}</span>\" for k in info.top_keywords)\n",
    "        ph_html = \"\".join(f\"<span class='chip ph'>{html.escape(p)}</span>\" for p in info.top_phrases)\n",
    "        issues_html = \"\".join(f\"<li>{html.escape(i)}</li>\" for i in info.issues) or \"<li>No major issues</li>\"\n",
    "        pos_html = \"\".join(f\"<li>{html.escape(p)}</li>\" for p in info.positives) or \"<li>No specific positives</li>\"\n",
    "\n",
    "        output.append(\n",
    "            f\"<div class='card'>\"\n",
    "            f\"<header>{html.escape(topic)}</header>\"\n",
    "\n",
    "            f\"<section class='side'>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.review_count}</span><span class='label'>Reviews</span></div>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.avg_rating:.2f}/5 {info.stars}</span>\"\n",
    "            f\"<span class='label'>Average</span></div>\"\n",
    "            f\"<div class='stat'><span class='label'>Sentiment</span><div class='bar'>{bar}</div></div>\"\n",
    "            \"</section>\"\n",
    "\n",
    "            \"<section class='main'>\"\n",
    "            f\"<p class='summary'>{html.escape(info.summary)}</p>\"\n",
    "            \"<div class='cols'>\"\n",
    "            f\"<div><h4>Issues</h4><ul>{issues_html}</ul></div>\"\n",
    "            f\"<div><h4>Positives</h4><ul>{pos_html}</ul></div>\"\n",
    "            \"</div>\"\n",
    "            f\"<div class='chips'><h4>Keywords</h4>{kw_html}</div>\"\n",
    "            f\"<div class='chips'><h4>Phrases</h4>{ph_html}</div>\"\n",
    "            \"</section>\"\n",
    "            \"</div>\"\n",
    "        )\n",
    "\n",
    "    output.append(\"</div>\")\n",
    "    display(HTML(\"\\n\".join(output)))\n",
    "\n",
    "def _bar_seg(name: str, frac: float) -> str:\n",
    "    cls = \"pos\" if name == \"positive\" else \"neg\" if name == \"negative\" else \"neu\"\n",
    "    pct = max(frac * 100, 1)\n",
    "    return f\"<span class='seg {cls}' style='width:{pct}%' title='{name}: {frac:.1%}'></span>\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – MATPLOTLIB CHART\n",
    "# -------------------------------------------------------------------\n",
    "def _plot_chart(data: Dict[str, TopicSummary], df: pd.DataFrame) -> None:\n",
    "    rows = [(t, d.avg_rating, d.review_count) for t, d in data.items() if t.lower() != \"other\"]\n",
    "    if not rows:\n",
    "        return\n",
    "    topics, ratings, counts = zip(*rows)\n",
    "    order = sorted(range(len(topics)), key=lambda i: ratings[i])\n",
    "    topics = [topics[i] for i in order]\n",
    "    ratings = [ratings[i] for i in order]\n",
    "    counts = [counts[i] for i in order]\n",
    "\n",
    "    cmap = mpl.colormaps.get_cmap(\"viridis\").resampled(len(topics))\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    bars = plt.barh(topics, ratings, color=[cmap(i) for i in range(len(topics))])\n",
    "\n",
    "    for bar, cnt, rating in zip(bars, counts, ratings):\n",
    "        x = rating + 0.05 if rating < 2.5 else rating - 0.6\n",
    "        clr = \"black\" if rating < 2.5 else \"white\"\n",
    "        plt.text(x, bar.get_y() + bar.get_height() / 2, f\"n={cnt}\", va=\"center\",\n",
    "                 color=clr, fontweight=\"bold\")\n",
    "\n",
    "    mean = df[\"score\"].mean()\n",
    "    plt.axvline(mean, linestyle=\"--\", linewidth=2, label=f\"Overall {mean:.2f}\")\n",
    "    plt.xticks(range(1, 6), [\"★\" * i for i in range(1, 6)])\n",
    "    plt.xlim(0, 5.2)\n",
    "    plt.xlabel(\"Star Rating\")\n",
    "    plt.ylabel(\"Topic\")\n",
    "    plt.title(\"BMW App – Average Rating by Topic\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MISC HELPERS\n",
    "# -------------------------------------------------------------------\n",
    "def _setup_logger() -> logging.Logger:\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "    return logging.getLogger(\"bmw_topic_cards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting simple translation evaluation with gemma3:12b …\n",
      "Reading bmw_app_analysis/translations/bmw_reviews_sampledHE.csv …\n",
      "Detected delimiter ';'\n",
      "Evaluating 120 rows with gemma3:12b …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/120 [00:46<22:29, 11.63s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 349\u001b[0m\n\u001b[1;32m    346\u001b[0m MODEL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma3:12b\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting simple translation evaluation with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m …\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 349\u001b[0m \u001b[43mevaluate_translations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIN_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOUT_FILE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 233\u001b[0m, in \u001b[0;36mevaluate_translations\u001b[0;34m(input_file, output_file, model_name)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m prompt \u001b[38;5;241m=\u001b[39m create_simple_prompt(df\u001b[38;5;241m.\u001b[39mloc[idx])\n\u001b[0;32m--> 233\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ollama\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Parse the response\u001b[39;00m\n\u001b[1;32m    236\u001b[0m result \u001b[38;5;241m=\u001b[39m parse_score_response(response)\n",
      "Cell \u001b[0;32mIn[19], line 56\u001b[0m, in \u001b[0;36mrun_ollama\u001b[0;34m(prompt, model_name, max_retries)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m         proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mollama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reduced timeout for simpler prompt\u001b[39;49;00m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mTimeoutExpired:\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/subprocess.py:2115\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2109\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2110\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2112\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2113\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2115\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2118\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2119\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Evaluate two candidate translations of app reviews by giving a simple \n",
    "numerical score (1-5) to each translation compared to the original.\n",
    "\n",
    "Key features\n",
    "----------------\n",
    "* Simple 1-5 scoring for each translation\n",
    "* Automatic delimiter detection (handles ';', ',', or '\\t')\n",
    "* Early validation that required columns exist\n",
    "* Summary statistics broken down by language\n",
    "\n",
    "Author: <your name>\n",
    "Date: 2025‑05‑04\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import json\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                              Helper functions                               #\n",
    "# --------------------------------------------------------------------------- #\n",
    "def detect_delimiter(file_path: str, sample_bytes: int = 2048) -> str:\n",
    "    \"\"\"Return the most likely delimiter in the CSV file.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sample = f.read(sample_bytes)\n",
    "\n",
    "        # Quick manual checks\n",
    "        if \"\\t\" in sample:\n",
    "            return \"\\t\"\n",
    "        if \";\" in sample:\n",
    "            return \";\"\n",
    "\n",
    "        # Fallback to csv.Sniffer\n",
    "        try:\n",
    "            dialect = csv.Sniffer().sniff(sample)\n",
    "            return dialect.delimiter\n",
    "        except Exception:\n",
    "            return \",\"  # default\n",
    "\n",
    "\n",
    "def run_ollama(prompt: str, model_name: str, max_retries: int = 2) -> str:\n",
    "    \"\"\"Call `ollama run` with retries and a timeout; return raw stdout.\"\"\"\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            proc = subprocess.run(\n",
    "                [\"ollama\", \"run\", model_name],\n",
    "                input=prompt,\n",
    "                text=True,\n",
    "                capture_output=True,\n",
    "                timeout=60,  # Reduced timeout for simpler prompt\n",
    "            )\n",
    "            return proc.stdout.strip()\n",
    "        except subprocess.TimeoutExpired:\n",
    "            if attempt < max_retries:\n",
    "                print(f\"Timeout. Retrying {attempt + 1}/{max_retries} …\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                return \"ERROR: Timeout\"\n",
    "        except Exception as exc:\n",
    "            if attempt < max_retries:\n",
    "                print(f\"{exc}. Retrying {attempt + 1}/{max_retries} …\")\n",
    "                time.sleep(2)\n",
    "            else:\n",
    "                return f\"ERROR: {exc}\"\n",
    "\n",
    "\n",
    "def create_simple_prompt(row: pd.Series) -> str:\n",
    "    \"\"\"Build a simple scoring prompt for a single review row.\"\"\"\n",
    "    return f\"\"\"You are an expert translator evaluating machine translations.\n",
    "\n",
    "SOURCE TEXT ({row['language']}):\n",
    "{row['content']}\n",
    "\n",
    "TRANSLATION A:\n",
    "{row['Translation A']}\n",
    "\n",
    "TRANSLATION B:\n",
    "{row['Translation B']}\n",
    "\n",
    "TASK:\n",
    "Rate each translation on a scale from 1 (poor) to 5 (excellent) based on how well it captures \n",
    "the meaning, tone, and intent of the source text.\n",
    "\n",
    "RESPONSE FORMAT:\n",
    "Respond with ONLY a JSON object with two scores like this:\n",
    "{{\n",
    "  \"score_A\": 3,\n",
    "  \"score_B\": 5\n",
    "}}\n",
    "\n",
    "Use only integers from 1-5. No explanation or additional text.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def parse_score_response(response: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Parse the LLM response containing simple scores.\n",
    "    Returns a dict with scores and winner determination.\n",
    "    \"\"\"\n",
    "    if response.startswith(\"ERROR:\"):\n",
    "        return {\"error\": response, \"score_A\": None, \"score_B\": None, \"winner\": \"Error\"}\n",
    "    \n",
    "    # Try to extract JSON from the response\n",
    "    try:\n",
    "        # Find the JSON object in the response\n",
    "        start_idx = response.find(\"{\")\n",
    "        end_idx = response.rfind(\"}\")\n",
    "        \n",
    "        if start_idx >= 0 and end_idx > start_idx:\n",
    "            json_str = response[start_idx:end_idx+1]\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # Extract scores\n",
    "            score_a = data.get(\"score_A\")\n",
    "            score_b = data.get(\"score_B\")\n",
    "            \n",
    "            # Determine winner based on scores\n",
    "            if score_a is not None and score_b is not None:\n",
    "                if score_a > score_b:\n",
    "                    winner = \"A\"\n",
    "                elif score_b > score_a:\n",
    "                    winner = \"B\"\n",
    "                else:\n",
    "                    winner = \"Tie\"\n",
    "                \n",
    "                return {\"score_A\": score_a, \"score_B\": score_b, \"winner\": winner}\n",
    "            else:\n",
    "                return {\"error\": \"Missing scores in response\", \"winner\": \"Unclear\"}\n",
    "        else:\n",
    "            # No JSON found\n",
    "            return {\"error\": \"No JSON found in response\", \"winner\": \"Unclear\"}\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        # Attempt manual parsing as fallback\n",
    "        try:\n",
    "            lines = response.strip().split('\\n')\n",
    "            score_a = None\n",
    "            score_b = None\n",
    "            \n",
    "            for line in lines:\n",
    "                line = line.lower().strip()\n",
    "                if \"score_a\" in line or \"score a\" in line or \"a:\" in line:\n",
    "                    # Try to extract a number\n",
    "                    nums = [int(s) for s in line if s.isdigit()]\n",
    "                    if nums and 1 <= nums[0] <= 5:\n",
    "                        score_a = nums[0]\n",
    "                \n",
    "                if \"score_b\" in line or \"score b\" in line or \"b:\" in line:\n",
    "                    # Try to extract a number\n",
    "                    nums = [int(s) for s in line if s.isdigit()]\n",
    "                    if nums and 1 <= nums[0] <= 5:\n",
    "                        score_b = nums[0]\n",
    "            \n",
    "            if score_a is not None and score_b is not None:\n",
    "                if score_a > score_b:\n",
    "                    winner = \"A\"\n",
    "                elif score_b > score_a:\n",
    "                    winner = \"B\"\n",
    "                else:\n",
    "                    winner = \"Tie\"\n",
    "                    \n",
    "                return {\"score_A\": score_a, \"score_B\": score_b, \"winner\": winner}\n",
    "            else:\n",
    "                return {\"error\": \"Could not extract scores\", \"winner\": \"Unclear\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Parsing error: {str(e)}\", \"winner\": \"Error\"}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"winner\": \"Error\"}\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                             Main entry‑point                                #\n",
    "# --------------------------------------------------------------------------- #\n",
    "def evaluate_translations(\n",
    "    input_file: str,\n",
    "    output_file: str,\n",
    "    model_name: str = \"llama3:latest\",\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Load review/translation CSV, evaluate each pair with simple scoring, save results.\"\"\"\n",
    "    print(f\"Reading {input_file} …\")\n",
    "    delimiter = detect_delimiter(input_file)\n",
    "    print(f\"Detected delimiter '{delimiter}'\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            input_file,\n",
    "            sep=delimiter,\n",
    "            quotechar='\"',\n",
    "            doublequote=True,\n",
    "            engine=\"python\",  # forgiving\n",
    "        )\n",
    "    except Exception as exc:\n",
    "        print(f\"❌ Could not load CSV: {exc}\")\n",
    "        return None\n",
    "\n",
    "    # Required columns\n",
    "    required = [\"content\", \"language\", \"Translation A\", \"Translation B\"]\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        print(\"❌ Missing required columns:\", missing)\n",
    "        print(\"Available columns:\", df.columns.tolist())\n",
    "        return None\n",
    "\n",
    "    # Add score and judgment columns if not present\n",
    "    if \"score_A\" not in df.columns:\n",
    "        df[\"score_A\"] = pd.NA\n",
    "    if \"score_B\" not in df.columns:\n",
    "        df[\"score_B\"] = pd.NA\n",
    "    if \"judgment\" not in df.columns:\n",
    "        df[\"judgment\"] = pd.NA\n",
    "\n",
    "    # Evaluate rows\n",
    "    print(f\"Evaluating {len(df)} rows with {model_name} …\")\n",
    "    for idx in tqdm(df.index):\n",
    "        # Skip if already evaluated\n",
    "        if pd.notna(df.at[idx, \"score_A\"]) and pd.notna(df.at[idx, \"score_B\"]):\n",
    "            continue\n",
    "\n",
    "        prompt = create_simple_prompt(df.loc[idx])\n",
    "        response = run_ollama(prompt, model_name)\n",
    "\n",
    "        # Parse the response\n",
    "        result = parse_score_response(response)\n",
    "        \n",
    "        # Store the scores and judgment\n",
    "        df.at[idx, \"score_A\"] = result.get(\"score_A\", None)\n",
    "        df.at[idx, \"score_B\"] = result.get(\"score_B\", None)\n",
    "        df.at[idx, \"judgment\"] = result.get(\"winner\", \"Error\")\n",
    "        \n",
    "        # Save error info if there was an error\n",
    "        if \"error\" in result:\n",
    "            df.at[idx, \"error\"] = result[\"error\"]\n",
    "            print(f\"⚠️ Row {idx}: {result['error']}\")\n",
    "\n",
    "    # Final save\n",
    "    try:\n",
    "        df.to_csv(output_file, index=False, quoting=csv.QUOTE_ALL)\n",
    "        print(f\"✅ Results written to {output_file}\")\n",
    "    except Exception as exc:\n",
    "        print(f\"⚠️ CSV save failed ({exc}); trying Excel …\")\n",
    "        try:\n",
    "            df.to_excel(output_file.replace(\".csv\", \".xlsx\"), index=False)\n",
    "            print(\"✅ Saved as Excel instead\")\n",
    "        except Exception as exc2:\n",
    "            print(f\"❌ Could not save results at all: {exc2}\")\n",
    "            return None\n",
    "\n",
    "    # -------------------- UPDATED SUMMARY SECTION --------------------\n",
    "    print(\"\\n====== EVALUATION SUMMARY ======\")\n",
    "    \n",
    "    # Overall summary\n",
    "    print(\"\\n🌐 OVERALL RESULTS:\")\n",
    "    counts = df[\"judgment\"].value_counts(dropna=False)\n",
    "    for label, cnt in counts.items():\n",
    "        pct = cnt / len(df) * 100\n",
    "        print(f\"  {label:8}: {cnt:>4}  ({pct:5.1f} %)\")\n",
    "    \n",
    "    a_avg = df[\"score_A\"].mean()\n",
    "    b_avg = df[\"score_B\"].mean()\n",
    "    diff = a_avg - b_avg\n",
    "    \n",
    "    print(f\"\\n  Average Scores (1-5):\")\n",
    "    print(f\"  Translation A: {a_avg:.2f}\")\n",
    "    print(f\"  Translation B: {b_avg:.2f}\")\n",
    "    print(f\"  Difference (A-B): {diff:+.2f}\")\n",
    "    \n",
    "    # Per-language statistics\n",
    "    print(\"\\n🔍 RESULTS BY LANGUAGE:\")\n",
    "    \n",
    "    # Create a list of languages to process in a specific order\n",
    "    languages = [\"German\", \"Italian\", \"French\", \"Spanish\"]\n",
    "    \n",
    "    # Ensure all expected languages are actually in the dataset\n",
    "    present_languages = df[\"language\"].unique()\n",
    "    print(f\"  Languages in dataset: {', '.join(sorted(present_languages))}\")\n",
    "    \n",
    "    # For each language, calculate stats\n",
    "    for lang in languages:\n",
    "        lang_df = df[df[\"language\"] == lang]\n",
    "        \n",
    "        if len(lang_df) == 0:\n",
    "            print(f\"\\n  ❌ No reviews for {lang}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n  📊 {lang} ({len(lang_df)} reviews):\")\n",
    "        \n",
    "        # Judgment distribution\n",
    "        lang_counts = lang_df[\"judgment\"].value_counts(dropna=False)\n",
    "        for label in [\"A\", \"B\", \"Tie\", \"Error\", \"Unclear\"]:\n",
    "            if label in lang_counts:\n",
    "                cnt = lang_counts[label]\n",
    "                pct = cnt / len(lang_df) * 100\n",
    "                print(f\"    {label:8}: {cnt:>3}  ({pct:5.1f} %)\")\n",
    "        \n",
    "        # Scores\n",
    "        lang_a_avg = lang_df[\"score_A\"].mean()\n",
    "        lang_b_avg = lang_df[\"score_B\"].mean()\n",
    "        lang_diff = lang_a_avg - lang_b_avg\n",
    "        \n",
    "        print(f\"\\n    Scores (1-5):\")\n",
    "        print(f\"    Translation A: {lang_a_avg:.2f}\")\n",
    "        print(f\"    Translation B: {lang_b_avg:.2f}\")\n",
    "        print(f\"    Difference (A-B): {lang_diff:+.2f}\")\n",
    "    \n",
    "    # Distribution of score differences\n",
    "    print(\"\\n📈 SCORE DIFFERENCE DISTRIBUTION:\")\n",
    "    \n",
    "    # Calculate score differences\n",
    "    df[\"score_diff\"] = df[\"score_A\"] - df[\"score_B\"]\n",
    "    \n",
    "    # Group differences into categories\n",
    "    diff_categories = {\n",
    "        \"A much better (≥2)\": (df[\"score_diff\"] >= 2).sum(),\n",
    "        \"A better (1)\": (df[\"score_diff\"] == 1).sum(),\n",
    "        \"Tie (0)\": (df[\"score_diff\"] == 0).sum(),\n",
    "        \"B better (-1)\": (df[\"score_diff\"] == -1).sum(),\n",
    "        \"B much better (≤-2)\": (df[\"score_diff\"] <= -2).sum()\n",
    "    }\n",
    "    \n",
    "    for label, count in diff_categories.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"  {label:20}: {count:>3}  ({pct:5.1f} %)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------- #\n",
    "#                                 CLI hook                                    #\n",
    "# --------------------------------------------------------------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    IN_FILE = \"bmw_app_analysis/translations/bmw_reviews_sampledHE.csv\"\n",
    "    OUT_FILE = \"bmw_app_analysis/translations/bmw_reviews_sampledLLM.csv\"\n",
    "    MODEL = \"gemma3:12b\"\n",
    "\n",
    "    print(f\"Starting simple translation evaluation with {MODEL} …\")\n",
    "    evaluate_translations(IN_FILE, OUT_FILE, MODEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentiNext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
