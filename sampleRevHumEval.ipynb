{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bmw_app_analysis/results/bmw_reviews_consolidated_20250504_155236.csv...\n",
      "Filtering reviews with at least 5 words...\n",
      "Reviews with 5+ words: 13312 out of 18350\n",
      "\n",
      "Reviews available after filtering by language and length:\n",
      "  German: 3839 reviews\n",
      "  Italian: 920 reviews\n",
      "  Spanish: 670 reviews\n",
      "  French: 1155 reviews\n",
      "Sampled 30 reviews from German\n",
      "Sampled 30 reviews from Italian\n",
      "Sampled 30 reviews from Spanish\n",
      "Sampled 30 reviews from French\n",
      "Saved sampled reviews to bmw_app_analysis/results/bmw_reviews_sampledHE.csv\n",
      "\n",
      "Final sample distribution:\n",
      "  German: 30 reviews\n",
      "  Italian: 30 reviews\n",
      "  Spanish: 30 reviews\n",
      "  French: 30 reviews\n",
      "\n",
      "Example reviews from each language:\n",
      "\n",
      "German example:\n",
      "  Original: Die App kann schon viel, aber warum lassen sich di...\n",
      "  English:  The app can already do a lot, but why can't the wi...\n",
      "\n",
      "Italian example:\n",
      "  Original: Dalla versione 2.11.0, con IDrive 6 e telefono And...\n",
      "  English:  Since version 2.11.0, with iDrive 6 and an Android...\n",
      "\n",
      "Spanish example:\n",
      "  Original: Aplicación penosa, en esta nueva actualización se ...\n",
      "  English:  Miserable app, with this new update they’ve even l...\n",
      "\n",
      "French example:\n",
      "  Original: Application très conviviale et informative ... C'e...\n",
      "  English:  Very user-friendly and informative application... ...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def sample_reviews_by_language(input_file='bmw_app_analysis/results/bmw_reviews_consolidated_20250504_155236.csv', \n",
    "                              output_file='bmw_app_analysis/results/bmw_reviews_sampledHE.csv'):\n",
    "    \"\"\"\n",
    "    Sample 30 reviews EACH from German, Italian, Spanish and French languages\n",
    "    with at least 5 words from the BMW reviews dataset.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to the input CSV file\n",
    "        output_file: Path to save the sampled reviews\n",
    "    \"\"\"\n",
    "    # Read the consolidated file\n",
    "    print(f\"Reading {input_file}...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Verify columns exist\n",
    "    required_columns = ['reviewId', 'content', 'language', 'content_english']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"ERROR: Missing required columns: {missing_columns}\")\n",
    "        print(f\"Available columns: {df.columns.tolist()}\")\n",
    "        return None\n",
    "    \n",
    "    # Apply minimum word filter - INCREASED TO 5 WORDS\n",
    "    min_words = 5  # Changed from 3 to 5\n",
    "    print(f\"Filtering reviews with at least {min_words} words...\")\n",
    "    df['word_count'] = df['content'].apply(lambda x: len(re.findall(r'\\b\\w+\\b', str(x))) if isinstance(x, str) else 0)\n",
    "    df_filtered_by_length = df[df['word_count'] >= min_words].copy()\n",
    "    \n",
    "    print(f\"Reviews with {min_words}+ words: {len(df_filtered_by_length)} out of {len(df)}\")\n",
    "    \n",
    "    # Target languages - in desired order\n",
    "    target_languages = [\"German\", \"Italian\", \"Spanish\", \"French\"]\n",
    "    \n",
    "    # Apply language filter\n",
    "    df_filtered = df_filtered_by_length[df_filtered_by_length['language'].isin(target_languages)].copy()\n",
    "    \n",
    "    # Report on available reviews per language\n",
    "    print(\"\\nReviews available after filtering by language and length:\")\n",
    "    for lang in target_languages:\n",
    "        count = len(df_filtered[df_filtered['language'] == lang])\n",
    "        print(f\"  {lang}: {count} reviews\")\n",
    "    \n",
    "    # Sample 30 from each language group (or all available if less than 30)\n",
    "    sampled_reviews = []\n",
    "    target_per_language = 30  # 30 reviews per language\n",
    "    \n",
    "    for lang in target_languages:\n",
    "        lang_df = df_filtered[df_filtered['language'] == lang]\n",
    "        \n",
    "        if len(lang_df) == 0:\n",
    "            print(f\"No reviews found for {lang}\")\n",
    "            continue\n",
    "            \n",
    "        # Sample up to target_per_language reviews, or all if fewer available\n",
    "        sample_size = min(target_per_language, len(lang_df))\n",
    "        sampled = lang_df.sample(sample_size, random_state=42)\n",
    "        sampled_reviews.append(sampled)\n",
    "        print(f\"Sampled {len(sampled)} reviews from {lang}\")\n",
    "    \n",
    "    # Combine all samples\n",
    "    sampled_df = pd.concat(sampled_reviews, ignore_index=True)\n",
    "    \n",
    "    # Create language order mapping for sorting\n",
    "    lang_order = {lang: i for i, lang in enumerate(target_languages)}\n",
    "    \n",
    "    # Select only the required columns and rename content_english to english_content\n",
    "    output_df = sampled_df[['reviewId', 'content', 'language', 'content_english']].copy()\n",
    "    \n",
    "    # Clean up english_content: remove quotes\n",
    "    output_df['content_english'] = output_df['content_english'].astype(str).str.replace('\"', '')\n",
    "    \n",
    "    # Rename the column\n",
    "    output_df = output_df.rename(columns={'content_english': 'english_content'})\n",
    "    \n",
    "    # Sort by language in the specified order\n",
    "    output_df['lang_order'] = output_df['language'].map(lang_order)\n",
    "    output_df = output_df.sort_values('lang_order').drop('lang_order', axis=1).reset_index(drop=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    print(f\"Saved sampled reviews to {output_file}\")\n",
    "    \n",
    "    print(\"\\nFinal sample distribution:\")\n",
    "    for lang in target_languages:\n",
    "        count = len(output_df[output_df['language'] == lang])\n",
    "        print(f\"  {lang}: {count} reviews\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# Execute the function\n",
    "if __name__ == \"__main__\":\n",
    "    sampled_reviews = sample_reviews_by_language()\n",
    "    \n",
    "    # Display summary\n",
    "    if sampled_reviews is not None and not sampled_reviews.empty:\n",
    "        # Show a couple examples from each language\n",
    "        print(\"\\nExample reviews from each language:\")\n",
    "        for lang in [\"German\", \"Italian\", \"Spanish\", \"French\"]:\n",
    "            lang_samples = sampled_reviews[sampled_reviews['language'] == lang].head(1)\n",
    "            if not lang_samples.empty:\n",
    "                print(f\"\\n{lang} example:\")\n",
    "                for _, row in lang_samples.iterrows():\n",
    "                    print(f\"  Original: {row['content'][:50]}{'...' if len(row['content']) > 50 else ''}\")\n",
    "                    print(f\"  English:  {row['english_content'][:50]}{'...' if len(row['english_content']) > 50 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmw_topic_cards.py  –  v6  (2025‑05‑02)\n",
    "# ================================================================\n",
    "# • Stratified random sampling (mirrors topic sentiment mix)\n",
    "# • One paragraph summary  +  “‑ ” negative bullets  +  “+ ” positive bullets\n",
    "# • Prompts stored inside TopicSummary.prompts  (audit / debugging)\n",
    "# • No JSON parsing, so Ollama chatter can’t break the pipeline\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import html\n",
    "import logging\n",
    "import subprocess\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Callable, Dict, List, Optional\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  CONFIGURATION\n",
    "# -------------------------------------------------------------------\n",
    "TOP_N_TOPICS        = 15          # how many topics to visualise\n",
    "PROMPT_SAMPLE_SIZE  = 300         # reviews fed to each LLM prompt\n",
    "N_KEYWORDS          = 8\n",
    "N_PHRASES           = 5\n",
    "MAX_BULLETS         = 7           # issues / positives\n",
    "BMW_BLUE            = \"#0066B1\"\n",
    "\n",
    "STAR_SVG = (\n",
    "    \"<svg width='14' height='14' viewBox='0 0 24 24' \"\n",
    "    \"xmlns='http://www.w3.org/2000/svg' style='vertical-align:-2px'>\"\n",
    "    \"<polygon fill='#FFD700' \"\n",
    "    \"points='12 2 15.09 8.26 22 9.27 17 14.14 \"\n",
    "    \"18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26'/></svg>\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  NLTK – bootstrap stop‑words\n",
    "# -------------------------------------------------------------------\n",
    "for res in (\"stopwords\", \"punkt\"):\n",
    "    try:\n",
    "        nltk.data.find(f\"corpora/{res}\")\n",
    "    except LookupError:\n",
    "        nltk.download(res, quiet=True)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\")) | {\n",
    "    \"bmw\", \"app\", \"car\", \"please\", \"would\", \"also\", \"get\", \"use\", \"using\"\n",
    "}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  OLLAMA RUNNER  (temperature 0 for determinism)\n",
    "# -------------------------------------------------------------------\n",
    "def _subprocess_runner(prompt: str, model: str) -> str:\n",
    "    proc = subprocess.run(\n",
    "        [\"ollama\", \"run\", model, \"-t\", \"0\"],\n",
    "        input=prompt,\n",
    "        text=True,\n",
    "        capture_output=True,\n",
    "        check=False,\n",
    "    )\n",
    "    return proc.stdout\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  STRATIFIED SAMPLING  (mirror sentiment mix)\n",
    "# -------------------------------------------------------------------\n",
    "def _stratified_sample(df: pd.DataFrame, size: int, seed: int = 0) -> List[str]:\n",
    "    dist = df[\"sentiment\"].value_counts(normalize=True)\n",
    "    quota = {s: int(round(dist.get(s, 0) * size)) for s in (\"negative\", \"positive\", \"neutral\")}\n",
    "    diff = size - sum(quota.values())\n",
    "    if diff:\n",
    "        quota[max(dist, key=dist.get, default=\"negative\")] += diff\n",
    "\n",
    "    col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "    texts: List[str] = []\n",
    "\n",
    "    for sentiment, n in quota.items():\n",
    "        if n <= 0:\n",
    "            continue\n",
    "        bucket = df[df[\"sentiment\"] == sentiment]\n",
    "        sample_n = min(n, len(bucket))\n",
    "        texts.extend(bucket.sample(sample_n, random_state=seed)[col].tolist())\n",
    "\n",
    "    # top‑up if any bucket ran short\n",
    "    if len(texts) < size:\n",
    "        short = size - len(texts)\n",
    "        remainder = df.drop(df.index[df[col].isin(texts)]).sample(short, random_state=seed)\n",
    "        texts.extend(remainder[col].tolist())\n",
    "\n",
    "    return texts\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  BULLET‑PARSER\n",
    "# -------------------------------------------------------------------\n",
    "def _parse_bullets(text: str, prefix: str) -> List[str]:\n",
    "    \"\"\"Return list of lines starting with the prefix (‘- ’ or ‘+ ’).\"\"\"\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    bullets = [ln[len(prefix):].strip() for ln in lines if ln.startswith(prefix)]\n",
    "    # fallback to comma‑sep if model ignored prefixes\n",
    "    if not bullets and \",\" in text:\n",
    "        bullets = [part.strip() for part in text.split(\",\") if part.strip()]\n",
    "    return bullets[:MAX_BULLETS]\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  DATACLASS\n",
    "# -------------------------------------------------------------------\n",
    "@dataclass\n",
    "class TopicSummary:\n",
    "    summary: str\n",
    "    issues: List[str]\n",
    "    positives: List[str]\n",
    "    avg_rating: float\n",
    "    review_count: int\n",
    "    sentiment_dist: Dict[str, float]\n",
    "    top_keywords: List[str]\n",
    "    top_phrases: List[str]\n",
    "    prompts: Dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "    @property\n",
    "    def stars(self) -> str:\n",
    "        full, half = int(self.avg_rating), self.avg_rating - int(self.avg_rating) >= 0.5\n",
    "        return STAR_SVG * full + (STAR_SVG if half else \"\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MAIN ENTRY\n",
    "# -------------------------------------------------------------------\n",
    "def create_topic_cards_from_classified(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    ollama_model_name: str = \"gemma3:12b\",\n",
    "    ollama_runner: Callable[[str, str], str] = _subprocess_runner,\n",
    ") -> Dict[str, TopicSummary]:\n",
    "    \"\"\"\n",
    "    Render topic cards & a rating chart; return dict[topic] -> TopicSummary.\n",
    "    Prompts are stored in `TopicSummary.prompts`.\n",
    "    \"\"\"\n",
    "    log = _setup_logger()\n",
    "\n",
    "    # -------- sanity checks -----------------------------------------\n",
    "    if {\"topics\", \"sentiment\"} - set(df.columns):\n",
    "        raise ValueError(\"DataFrame must include 'topics' & 'sentiment'.\")\n",
    "\n",
    "    text_col = \"content_english\" if \"content_english\" in df.columns else \"content\"\n",
    "\n",
    "    if \"score\" not in df.columns:\n",
    "        df[\"score\"] = (\n",
    "            df[\"sentiment\"]\n",
    "            .map({\"positive\": 4.5, \"neutral\": 3.0, \"negative\": 1.5})\n",
    "            .fillna(3.0)\n",
    "        )\n",
    "\n",
    "    # -------- pick top topics --------------------------------------\n",
    "    topics_freq = df[\"topics\"].str.get_dummies(sep=\",\").sum()\n",
    "    top_topics = (\n",
    "        topics_freq.sort_values(ascending=False).head(TOP_N_TOPICS).index\n",
    "    )\n",
    "\n",
    "    results: Dict[str, TopicSummary] = {}\n",
    "\n",
    "    for topic in tqdm(top_topics, desc=\"Topics\"):\n",
    "        sub = df[df[\"topics\"].str.contains(fr\"\\b{topic}\\b\", case=False, na=False)]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "\n",
    "        avg = sub[\"score\"].mean()\n",
    "        mix = sub[\"sentiment\"].value_counts(normalize=True).to_dict()\n",
    "\n",
    "        tokens = word_tokenize(\" \".join(sub[text_col].fillna(\"\").str.lower()))\n",
    "        tokens = [t for t in tokens if t.isalpha() and t not in STOPWORDS and len(t) > 2]\n",
    "        keywords = [w for w, _ in Counter(tokens).most_common(N_KEYWORDS)]\n",
    "        bigrams = [f\"{a} {b}\" for a, b in zip(tokens, tokens[1:])]\n",
    "        phrases = [p for p, _ in Counter(bigrams).most_common(N_PHRASES)]\n",
    "\n",
    "        sample_n = min(PROMPT_SAMPLE_SIZE, len(sub))\n",
    "        sample_texts = _stratified_sample(sub, sample_n)\n",
    "        sample_blob = \"\\n\".join(f\"[{i}] {txt}\" for i, txt in enumerate(sample_texts))\n",
    "\n",
    "        ctx_block = (\n",
    "            f\"Average score {avg:.2f} (n={len(sub)}). \"\n",
    "            f\"Sentiment mix: neg {mix.get('negative',0):.0%}, \"\n",
    "            f\"pos {mix.get('positive',0):.0%}, \"\n",
    "            f\"neu {mix.get('neutral',0):.0%}.\\n\"\n",
    "            f\"Top keywords: {', '.join(keywords)}.\\n\"\n",
    "            f\"Top phrases: {', '.join(phrases)}.\"\n",
    "        )\n",
    "\n",
    "        prompts: Dict[str, str] = {}\n",
    "\n",
    "        def build(kind: str) -> str:\n",
    "            \"\"\"Return fully‑formed prompt & store it\"\"\"\n",
    "            header = (\n",
    "                \"You are an analytical assistant. Follow ALL rules:\\n\"\n",
    "                f\"• Focus **only** on the topic '{topic}'.\\n\"\n",
    "                \"• Ignore unrelated features.\\n\"\n",
    "                \"• Use English even if reviews were translated.\\n\"\n",
    "                \"• Be factual, concise (temperature 0).\\n\"\n",
    "            )\n",
    "            if kind == \"summary\":\n",
    "                body = (\n",
    "                    \"Write one concise paragraph (3‑5 sentences) that \"\n",
    "                    \"summarises what users say about this topic, covering \"\n",
    "                    \"both pain points and praise.\"\n",
    "                )\n",
    "            else:\n",
    "                label = \"negative issues\" if kind == \"issues\" else \"positive aspects\"\n",
    "                prefix = \"-\" if kind == \"issues\" else \"+\"\n",
    "                body = (\n",
    "                    f\"List up to {MAX_BULLETS} main {label}. \"\n",
    "                    f\"Each line MUST start with '{prefix} '. \"\n",
    "                    \"Use short noun phrases, no duplication, no periods.\"\n",
    "                )\n",
    "\n",
    "            prompt = (\n",
    "                f\"{header}\\n\\nCONTEXT:\\n{ctx_block}\\n\\nSAMPLES:\\n{sample_blob}\\n\\nTASK:\\n{body}\"\n",
    "            )\n",
    "            prompts[kind] = prompt\n",
    "            return prompt\n",
    "\n",
    "        # ----- call Ollama (three prompts in parallel) ----------------\n",
    "        with ThreadPoolExecutor(max_workers=3) as pool:\n",
    "            futures = {\n",
    "                pool.submit(ollama_runner, build(k), ollama_model_name): k\n",
    "                for k in (\"summary\", \"issues\", \"positives\")\n",
    "            }\n",
    "            raw = {k: f.result().strip() for f, k in futures.items()}\n",
    "\n",
    "        summary_text = raw[\"summary\"]\n",
    "        issues_list  = _parse_bullets(raw[\"issues\"], \"-\")\n",
    "        pos_list     = _parse_bullets(raw[\"positives\"], \"+\")\n",
    "\n",
    "        results[topic] = TopicSummary(\n",
    "            summary=summary_text,\n",
    "            issues=issues_list,\n",
    "            positives=pos_list,\n",
    "            avg_rating=avg,\n",
    "            review_count=len(sub),\n",
    "            sentiment_dist=mix,\n",
    "            top_keywords=keywords,\n",
    "            top_phrases=phrases,\n",
    "            prompts=prompts,\n",
    "        )\n",
    "\n",
    "    # ------------- render & plot -------------------------------------\n",
    "    _render_cards(results)\n",
    "    _plot_chart(results, df)\n",
    "    return {k: v.__dict__ for k, v in results.items()}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – HTML CARDS\n",
    "# -------------------------------------------------------------------\n",
    "def _render_cards(data: Dict[str, TopicSummary]) -> None:\n",
    "    css = textwrap.dedent(\n",
    "        \"\"\"\n",
    "        <style>\n",
    "          :root {{--blue:{blue};--neg:#E53935;--pos:#43A047;--neu:#FFA000;\n",
    "                 --bg:#fff;--text:#1a1a1a;}}\n",
    "          @media (prefers-color-scheme: dark) {{\n",
    "              :root {{--bg:#121212;--text:#e0e0e0;}}\n",
    "          }}\n",
    "          body {{background:var(--bg);color:var(--text);}}\n",
    "\n",
    "/* container */\n",
    "          .cards {{max-width:1200px;margin:0 auto;font-family:'Helvetica Neue',Arial,sans-serif;}}\n",
    "\n",
    "/* card */\n",
    "          .card {{\n",
    "              display:grid;grid-template-columns:220px 1fr;\n",
    "              border:1px solid #bbb;border-radius:8px;margin:18px 0;\n",
    "              overflow:hidden;box-shadow:0 4px 10px rgba(0,0,0,.12);\n",
    "              animation:fadeIn .4s ease;\n",
    "          }}\n",
    "          @keyframes fadeIn {{from {{opacity:0;transform:translateY(8px);}}\n",
    "                              to   {{opacity:1;transform:translateY(0);}}}}\n",
    "          header {{\n",
    "              grid-column:1/-1;background:linear-gradient(135deg,var(--blue) 0%,#0088cc 100%);\n",
    "              color:#fff;padding:12px 18px;font-size:20px;font-weight:600;\n",
    "          }}\n",
    "\n",
    "/* sidebar */\n",
    "          .side {{\n",
    "              background:#f5f7fa;border-right:1px solid #ddd;\n",
    "              padding:14px;display:flex;flex-direction:column;gap:14px;\n",
    "          }}\n",
    "          .stat .num {{font-weight:700;font-size:19px;line-height:1;color:var(--text);}}\n",
    "          .stat .label{{font-size:11px;text-transform:uppercase;font-weight:600;\n",
    "                       letter-spacing:.4px;color:var(--text);}}\n",
    "          .bar {{display:flex;height:10px;border-radius:4px;overflow:hidden;margin-top:4px;}}\n",
    "          .seg {{flex-shrink:0;transition:opacity .2s;}} .seg:hover {{opacity:.75;}}\n",
    "          .neg{{background:var(--neg);}} .pos{{background:var(--pos);}} .neu{{background:var(--neu);}}\n",
    "\n",
    "/* main */\n",
    "          .main {{padding:18px;line-height:1.6;}}\n",
    "          .summary {{\n",
    "              background:rgba(0,102,177,.07);border-left:3px solid var(--blue);\n",
    "              padding:10px;margin-bottom:16px;line-height:1.6;\n",
    "          }}\n",
    "          .cols {{display:flex;flex-wrap:wrap;gap:24px;margin-bottom:16px;}}\n",
    "          h4 {{margin:0 0 6px;color:var(--blue);font-weight:600;}}\n",
    "          ul {{margin:0;padding-left:18px;}}\n",
    "          li {{margin:4px 0;}}\n",
    "\n",
    "/* chips */\n",
    "          .chips {{margin-bottom:10px;}}\n",
    "          .chip {{\n",
    "              display:inline-block;padding:4px 10px;border-radius:20px;\n",
    "              font-size:11px;font-weight:700;margin:2px;cursor:pointer;\n",
    "              transition:opacity .2s;\n",
    "          }}\n",
    "          .chip:hover {{opacity:.8;}}\n",
    "          .kw{{background:#e3f2fd;color:var(--blue);}}\n",
    "          .ph{{background:#e8f5e9;color:#2e7d32;border:1px solid #c8e6c9;}}\n",
    "\n",
    "/* responsive */\n",
    "          @media (max-width:768px){{\n",
    "              .card{{grid-template-columns:1fr}}\n",
    "              .side{{order:2;border:none;border-top:1px solid #ddd;\n",
    "                    flex-direction:row;justify-content:space-around}}\n",
    "          }}\n",
    "        </style>\n",
    "        \"\"\"\n",
    "    ).format(blue=BMW_BLUE)\n",
    "\n",
    "    output: List[str] = [css, \"<div class='cards'>\"]\n",
    "\n",
    "    # sort by review count\n",
    "    for topic, info in sorted(data.items(), key=lambda x: x[1].review_count, reverse=True):\n",
    "        if topic.lower() == \"other\":\n",
    "            continue\n",
    "\n",
    "        bar = \"\".join(_bar_seg(name, frac) for name, frac in info.sentiment_dist.items())\n",
    "        kw_html = \"\".join(f\"<span class='chip kw'>{html.escape(k)}</span>\" for k in info.top_keywords)\n",
    "        ph_html = \"\".join(f\"<span class='chip ph'>{html.escape(p)}</span>\" for p in info.top_phrases)\n",
    "        issues_html = \"\".join(f\"<li>{html.escape(i)}</li>\" for i in info.issues) or \"<li>No major issues</li>\"\n",
    "        pos_html = \"\".join(f\"<li>{html.escape(p)}</li>\" for p in info.positives) or \"<li>No specific positives</li>\"\n",
    "\n",
    "        output.append(\n",
    "            f\"<div class='card'>\"\n",
    "            f\"<header>{html.escape(topic)}</header>\"\n",
    "\n",
    "            f\"<section class='side'>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.review_count}</span><span class='label'>Reviews</span></div>\"\n",
    "            f\"<div class='stat'><span class='num'>{info.avg_rating:.2f}/5 {info.stars}</span>\"\n",
    "            f\"<span class='label'>Average</span></div>\"\n",
    "            f\"<div class='stat'><span class='label'>Sentiment</span><div class='bar'>{bar}</div></div>\"\n",
    "            \"</section>\"\n",
    "\n",
    "            \"<section class='main'>\"\n",
    "            f\"<p class='summary'>{html.escape(info.summary)}</p>\"\n",
    "            \"<div class='cols'>\"\n",
    "            f\"<div><h4>Issues</h4><ul>{issues_html}</ul></div>\"\n",
    "            f\"<div><h4>Positives</h4><ul>{pos_html}</ul></div>\"\n",
    "            \"</div>\"\n",
    "            f\"<div class='chips'><h4>Keywords</h4>{kw_html}</div>\"\n",
    "            f\"<div class='chips'><h4>Phrases</h4>{ph_html}</div>\"\n",
    "            \"</section>\"\n",
    "            \"</div>\"\n",
    "        )\n",
    "\n",
    "    output.append(\"</div>\")\n",
    "    display(HTML(\"\\n\".join(output)))\n",
    "\n",
    "def _bar_seg(name: str, frac: float) -> str:\n",
    "    cls = \"pos\" if name == \"positive\" else \"neg\" if name == \"negative\" else \"neu\"\n",
    "    pct = max(frac * 100, 1)\n",
    "    return f\"<span class='seg {cls}' style='width:{pct}%' title='{name}: {frac:.1%}'></span>\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  VISUAL HELPER – MATPLOTLIB CHART\n",
    "# -------------------------------------------------------------------\n",
    "def _plot_chart(data: Dict[str, TopicSummary], df: pd.DataFrame) -> None:\n",
    "    rows = [(t, d.avg_rating, d.review_count) for t, d in data.items() if t.lower() != \"other\"]\n",
    "    if not rows:\n",
    "        return\n",
    "    topics, ratings, counts = zip(*rows)\n",
    "    order = sorted(range(len(topics)), key=lambda i: ratings[i])\n",
    "    topics = [topics[i] for i in order]\n",
    "    ratings = [ratings[i] for i in order]\n",
    "    counts = [counts[i] for i in order]\n",
    "\n",
    "    cmap = mpl.colormaps.get_cmap(\"viridis\").resampled(len(topics))\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    bars = plt.barh(topics, ratings, color=[cmap(i) for i in range(len(topics))])\n",
    "\n",
    "    for bar, cnt, rating in zip(bars, counts, ratings):\n",
    "        x = rating + 0.05 if rating < 2.5 else rating - 0.6\n",
    "        clr = \"black\" if rating < 2.5 else \"white\"\n",
    "        plt.text(x, bar.get_y() + bar.get_height() / 2, f\"n={cnt}\", va=\"center\",\n",
    "                 color=clr, fontweight=\"bold\")\n",
    "\n",
    "    mean = df[\"score\"].mean()\n",
    "    plt.axvline(mean, linestyle=\"--\", linewidth=2, label=f\"Overall {mean:.2f}\")\n",
    "    plt.xticks(range(1, 6), [\"★\" * i for i in range(1, 6)])\n",
    "    plt.xlim(0, 5.2)\n",
    "    plt.xlabel(\"Star Rating\")\n",
    "    plt.ylabel(\"Topic\")\n",
    "    plt.title(\"BMW App – Average Rating by Topic\")\n",
    "    plt.legend()\n",
    "    plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#  MISC HELPERS\n",
    "# -------------------------------------------------------------------\n",
    "def _setup_logger() -> logging.Logger:\n",
    "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "    return logging.getLogger(\"bmw_topic_cards\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation with qwen3:14b...\n",
      "Loaded 120 records\n",
      "\n",
      "Evaluating translations:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/120 [00:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 206\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 206\u001b[0m     \u001b[43mevaluate_translations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbmw_app_analysis/translations/bmw_reviews_sampledHE.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbmw_app_analysis/translations/bmw_reviews_evaluated_1to5.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mqwen3:14b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 137\u001b[0m, in \u001b[0;36mevaluate_translations\u001b[0;34m(input_file, output_file, model, max_retries, timeout)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Get scores\u001b[39;00m\n\u001b[1;32m    136\u001b[0m score_a \u001b[38;5;241m=\u001b[39m evaluate_single(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTranslation A\u001b[39m\u001b[38;5;124m'\u001b[39m], lang, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m score_b \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTranslation B\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Determine winner\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(score_a, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(score_b, \u001b[38;5;28mint\u001b[39m):\n",
      "Cell \u001b[0;32mIn[12], line 101\u001b[0m, in \u001b[0;36mevaluate_translations.<locals>.evaluate_single\u001b[0;34m(original, translation, language, label)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttp://localhost:11434/api/generate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    108\u001b[0m             response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/site-packages/requests/api.py:119\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    108\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/site-packages/requests/sessions.py:530\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    525\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m'\u001b[39m: allow_redirects,\n\u001b[1;32m    528\u001b[0m }\n\u001b[1;32m    529\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 530\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/site-packages/requests/sessions.py:643\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    642\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    646\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/site-packages/requests/adapters.py:439\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 439\u001b[0m         resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(conn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxy_pool\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/site-packages/urllib3/connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/SentiNext/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Evaluate translations of app reviews by scoring on a scale of 1-5.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "\n",
    "def evaluate_translations(input_file, output_file, model='llama3.1:8b', max_retries=2, timeout=60):\n",
    "    print(f\"Starting evaluation with {model}...\")\n",
    "    \n",
    "    # Quick API test\n",
    "    try:\n",
    "        response = requests.get(\"http://localhost:11434/api/tags\")\n",
    "        if response.status_code != 200:\n",
    "            print(f\"⚠️ Ollama API error: {response.status_code}\")\n",
    "            return\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Ollama not running: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Load CSV\n",
    "    try:\n",
    "        df = pd.read_csv(input_file, sep=';')\n",
    "        print(f\"Loaded {len(df)} records\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            df = pd.read_csv(input_file, sep=None, engine='python')\n",
    "            print(f\"Loaded {len(df)} records with auto-detection\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Failed to load CSV: {e}\")\n",
    "            return\n",
    "    \n",
    "    # Initialize columns\n",
    "    df['Score_A'] = None\n",
    "    df['Score_B'] = None\n",
    "    df['Winner'] = None\n",
    "    \n",
    "    def get_score(text):\n",
    "        \"\"\"Extract numeric score from response, ignoring thinking sections\"\"\"\n",
    "        # Remove thinking sections\n",
    "        while \"<think>\" in text and \"</think>\" in text:\n",
    "            think_start = text.find(\"<think>\")\n",
    "            think_end = text.find(\"</think>\", think_start) + len(\"</think>\")\n",
    "            if think_start >= 0 and think_end > 0:\n",
    "                text = text[:think_start] + text[think_end:]\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Alternative regex approach if the above doesn't work\n",
    "        text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "        \n",
    "        # Clean up the remaining text\n",
    "        text = text.strip()\n",
    "        \n",
    "        # Look for the score (prioritize the last digit as the final answer)\n",
    "        if text:\n",
    "            # First check if the response ends with a digit\n",
    "            if text[-1] in \"12345\":\n",
    "                return int(text[-1])\n",
    "            \n",
    "            # Then check from the end backward\n",
    "            for i in range(len(text)-1, -1, -1):\n",
    "                if text[i] in \"12345\":\n",
    "                    return int(text[i])\n",
    "            \n",
    "            # Finally, check the whole text\n",
    "            for char in text:\n",
    "                if char in \"12345\":\n",
    "                    return int(char)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def evaluate_single(original, translation, language, label):\n",
    "        prompt = f\"\"\"Evaluate this translation from {language} to English:\n",
    "\n",
    "Original ({language}): {original}\n",
    "Translation: {translation}\n",
    "\n",
    "Rate on a scale of 1-5 based on these criteria:\n",
    "1: VERY POOR - Completely incorrect or incomprehensible translation\n",
    "2: POOR - Major meaning errors or serious mistranslations\n",
    "3: FAIR - Conveys basic meaning but has notable accuracy or fluency issues\n",
    "4: GOOD - Mostly accurate with only minor issues in wording or naturalness\n",
    "5: EXCELLENT - Perfect translation that captures meaning, tone, and reads naturally\n",
    "\n",
    "IMPORTANT: Use the FULL RANGE of scores (1-5). Don't hesitate to give 1s for poor translations or 5s for excellent ones.\n",
    "\n",
    "Focus on: accuracy, preservation of tone, natural English expression, and completeness.\n",
    "\n",
    "Your response must be ONLY a single digit: 1, 2, 3, 4, or 5.\"\"\"\n",
    "\n",
    "        for attempt in range(max_retries + 1):\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    \"http://localhost:11434/api/generate\",\n",
    "                    json={\"model\": model, \"prompt\": prompt, \"stream\": False},\n",
    "                    timeout=timeout\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    response_text = response.json().get('response', '').strip()\n",
    "                    score = get_score(response_text)\n",
    "                    \n",
    "                    if score:\n",
    "                        return score\n",
    "                    else:\n",
    "                        print(f\"⚠️ Couldn't extract score from: '{response_text[:30]}...'\")\n",
    "                \n",
    "                if attempt < max_retries:\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "                if attempt < max_retries:\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    return \"ERROR\"\n",
    "                    \n",
    "        return \"ERROR\"\n",
    "    \n",
    "    # Process reviews\n",
    "    errors = 0\n",
    "    print(\"\\nEvaluating translations:\")\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Progress\"):\n",
    "        lang = row['language']\n",
    "        \n",
    "        # Get scores\n",
    "        score_a = evaluate_single(row['content'], row['Translation A'], lang, \"A\")\n",
    "        score_b = evaluate_single(row['content'], row['Translation B'], lang, \"B\")\n",
    "        \n",
    "        # Determine winner\n",
    "        if isinstance(score_a, int) and isinstance(score_b, int):\n",
    "            if score_a > score_b:\n",
    "                winner = \"A\"\n",
    "            elif score_b > score_a:\n",
    "                winner = \"B\"\n",
    "            else:\n",
    "                winner = \"Tie\"\n",
    "        else:\n",
    "            winner = \"Error\"\n",
    "            errors += 1\n",
    "            \n",
    "        # Store results\n",
    "        df.at[idx, 'Score_A'] = score_a\n",
    "        df.at[idx, 'Score_B'] = score_b\n",
    "        df.at[idx, 'Winner'] = winner\n",
    "        \n",
    "        # Show just last row result in one line\n",
    "        tqdm.write(f\"Row {idx+1}: {lang} - A({score_a}) vs B({score_b}) → {winner}\")\n",
    "        \n",
    "        # Save progress\n",
    "        df.to_csv(output_file, index=False, sep=';')\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n=== RESULTS ===\")\n",
    "    \n",
    "    valid_df = df[df['Winner'] != 'Error'].copy()\n",
    "    if len(valid_df) > 0:\n",
    "        # Convert scores to numeric for calculations\n",
    "        valid_df['Score_A'] = pd.to_numeric(valid_df['Score_A'], errors='coerce')\n",
    "        valid_df['Score_B'] = pd.to_numeric(valid_df['Score_B'], errors='coerce')\n",
    "        \n",
    "        # Overall statistics\n",
    "        a_wins = (valid_df['Winner'] == 'A').sum()\n",
    "        b_wins = (valid_df['Winner'] == 'B').sum()\n",
    "        ties = (valid_df['Winner'] == 'Tie').sum()\n",
    "        avg_score_a = valid_df['Score_A'].mean()\n",
    "        avg_score_b = valid_df['Score_B'].mean()\n",
    "        \n",
    "        print(f\"Overall (n={len(valid_df)}):\")\n",
    "        print(f\"- Win rate: A: {a_wins} ({a_wins/len(valid_df)*100:.1f}%), \" +\n",
    "              f\"B: {b_wins} ({b_wins/len(valid_df)*100:.1f}%), \" +\n",
    "              f\"Ties: {ties} ({ties/len(valid_df)*100:.1f}%)\")\n",
    "        print(f\"- Average scores: A: {avg_score_a:.2f}, B: {avg_score_b:.2f}, Difference: {avg_score_a-avg_score_b:.2f}\")\n",
    "        \n",
    "        # Results by language\n",
    "        print(\"\\nBy language:\")\n",
    "        for lang in df['language'].unique():\n",
    "            lang_df = valid_df[valid_df['language'] == lang]\n",
    "            if len(lang_df) > 0:\n",
    "                a_lang = (lang_df['Winner'] == 'A').sum()\n",
    "                b_lang = (lang_df['Winner'] == 'B').sum()\n",
    "                t_lang = (lang_df['Winner'] == 'Tie').sum()\n",
    "                \n",
    "                lang_avg_a = lang_df['Score_A'].mean()\n",
    "                lang_avg_b = lang_df['Score_B'].mean()\n",
    "                \n",
    "                print(f\"{lang} (n={len(lang_df)}):\")\n",
    "                print(f\"- Win rate: A: {a_lang} ({a_lang/len(lang_df)*100:.1f}%), \" +\n",
    "                      f\"B: {b_lang} ({b_lang/len(lang_df)*100:.1f}%), \" +\n",
    "                      f\"Ties: {t_lang} ({t_lang/len(lang_df)*100:.1f}%)\")\n",
    "                print(f\"- Average scores: A: {lang_avg_a:.2f}, B: {lang_avg_b:.2f}, Diff: {lang_avg_a-lang_avg_b:.2f}\")\n",
    "    \n",
    "    print(f\"\\nComplete! Results saved to {output_file}\")\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_translations(\n",
    "        input_file=\"bmw_app_analysis/translations/bmw_reviews_sampledHE.csv\",\n",
    "        output_file=\"bmw_app_analysis/translations/bmw_reviews_evaluated_1to5.csv\",\n",
    "        model=\"qwen3:14b\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SentiNext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
